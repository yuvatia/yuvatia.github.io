export const frontmatter = {
    title: "Graph Theory",
    date: "2024-06-10",
    summary: "An elementary discussion of graph theory along with practical results",
    // wip: true
}

# Motivation

A chessboard is an $8 \times 8$ grid of squares. A knight is a chess piece that moves in an L-shape, two squares in one direction and one square in a perpendicular direction. The knight's tour problem is an old mathematical problem, with written records dating back to the [9th century AD](https://en.wikipedia.org/wiki/Rudrata#Solving_Knight's_Tour_Problem), which is stated as follows: given an empty chessboard and a knight placed on one of the squares, construct a sequence of moves such that the knight visits every square exactly once. This sequence is called a knight's tour. Here's one such tour:

![Knight's tour](https://upload.wikimedia.org/wikipedia/commons/d/da/Knight%27s_tour_anim_2.gif)

When contemplating the problem, one quickly realizes that the shape of the chessboard is of no consequence. Instead, the problem is entirely about the connectivity of the squares (and the shape of the squares themselves are also irrelevant), which determines the allowed moves the knight can take. Consider, for example, a $3 \times 3$ chessboard:

TODO
![3x3 chessboard]()

Let us denote the squares of the chessboard by a set of letters and numbers, as such:

$$
\begin{array}{c|c|c}
A3 & B3 & C3 \\
\hline
A2 & B2 & C2 \\
\hline
A1 & B1 & C1
\end{array}
$$

Consider a knight place at each one of the vertices. The knight can only move in an L-shape, thus the allowed moves are:

1. $A1 \to B3$
2. $A1 \to C2$
3. $B1 \to A3$
4. $B1 \to C3$
5. $C1 \to B3$ 
6. $C1 \to A2$
7. $A2 \to C3$
8. $C2 \to A3$
9. All of the above in the opposite direction.

Notice how we modeled the problem in terms of a set of identifiers and a set of connections between them. Also note how the direction of the connections is irrelevant, as the knight can move in either direction. We can represent this visually as such:

TODO chess 3by3 graph

From this representation it is easy to see that we can get from every square to every other square including the starting square, except for B2 which cannot be reached, thus there is no knight's tour in a 3 by 3 grid, but the allowed moves form a cycle through all the squares but B2. Note that this is just one way to draw this structure. Convince yourself that this is a different representation of the same graph:

TODO chess 3by3 graph 2

This representation - using identifiers and connections - is called a graph, but instead of "identifiers" we use the term "vertices" or "nodes" and instead of "connections" we use the term "edges". By converting the problem to a graph problem, we were able to discard all irrelevant information and focus on the more general problem.

Let's move our attention towards another, seemingly unrelated problem. Koningberg is a medieval city in Prussia, now known as Kaliningrad, Russia. The city was set on both sides of a river, with two large islands separated from the two portions of the mainland by the river. Seven bridges connected the islands to the mainland and to each other, as illustrated below:

![Konigsberg bridges](https://upload.wikimedia.org/wikipedia/commons/5/5d/Konigsberg_bridges.png)

As the story goes, the citizens of the city were quite fond of walking, and would come up with the challenge of walking around the city such that each bridge is crossed exactly once. This problem is known as the seven bridges of Konigsberg problem. Much like the Knight's tour problem, thinking of this problem quickly reveals that the shape of the city and the pieces of land is irrelevant, but rather only the connectivity between the different regions of the city, which can be abstracted as follows:

TODO konigsberg as graph

It was Leonard Euler who came up with this equivalent strcuture for the problem, and with a proof that no such path exists. The paper in which he proved it is considered to be the first paper in the field of graph theory. In the paper, Euler developed an analytic framework which would lay the grounds for what we call graph theory today.

# Set Theory - A Quick Recap

A **set** is a collection of distinct objects. Consider all numbers from 0 to 5 - they are all distinct, and thus we can defined a set containing them. In set notation, we write

$$
S = \{0, 1, 2, 3, 4, 5\}
$$

Where $S$ is the same. Instead of explicitly specifying the objects of the set, we can define a set using a membership test. An equivalent definition of $S$ using a membership tests is

$$
S=\{a \in \mathbb{Z} | a \in [0, 5]\}
$$

For bravity, throughout this article we will use a notation borrowed from Python's list slicing operator, which we define as such

$$
[a:b] = \{x \in \mathbb{Z} | a \leq x \leq b\}, [:b] = [0:b]
$$ 

Thus we can write the set $S$ as $S={a | a \in [0:5]}$ or simply as $S=[0:5]=[:5]$.

We define the **cardinality** of a set as the number of elements it contains, and denote it by $|S|$. In our example, $|S|=6$. A set with cardinality 0 is called the **empty set**, denoted by $\emptyset = \{\}$.

A set $R$ is a **subset** of a set $S$ if all the elements of $R$ are in $S$, we denote this by $R \subseteq S$. Equivalently, we sometimes say that $S$ is a **superset** of $R$. Two sets are said to be equal if they both contain exactly the same elements, which is true iff $S \subseteq R$ and $R \subseteq S$. We denote this equivalence by $S=R$. By definition, the empty set is included in every set, thus it is a subset of every set.

Since a set is itself an object, we can define a set of sets. For example, for our sets $S, R$, we can define a set $U$ s.t. $U=\{S, R\}$. Note that $|U|=2$ if $S \neq R$, and $1$ otherwise. We can also define sets of sets using membership tests, for example

$$
S=\{\text{all sets that contain the number 2}\}
$$

We define the following binary operations on two sets $A, B$ (binary in the sense that they operate on two operands):
1. **Union**, denoted by $\cup$, is the set of all elements that are in either $A$ or $B$ or both. Note that a union is *symmetric*.
$$
A \cup B = \{x | x \in A \text{ or } x \in B\}
$$ 
2. **Intersection**, denoted by $\cap$, is the set of all elements that are in both $A$ and $B$. Intersections are *symmetric*.
$$
A \cap B = \{x | x \in A \text{ and } x \in B\}
$$
3. **Difference**, denoted by $A \setminus B$, is the set of all elements that are in $A$ but not in $B$. Note that set difference is *not* symmetric, i.e $A \setminus B \neq B \setminus A$.
$$
A \setminus B = \{x | x \in A \text{ and } x \notin B\}
$$
4. **Complement** of $A$ with respect to $B$ is denoted by $\overline{A}$ and is the set of all elements that are in $B$ but not in $A$.
$$
\overline{A} = B \setminus A
$$
5. **Symmetric difference**, denoted by $A \oplus B$, is the set of all elements that are in either $A$ or $B$ but not in both. As the name suggest, it is symmetric. We can write a symmetric difference in terms of set differences and set unions, as
$$
A \oplus B = (A \setminus B) \cup (B \setminus A)
$$
6. The **cartesian product** of two sets, denoted by $A \times B$, is the set of all ordered pairs $(a, b)$ where $a \in A$ and $b \in B$. For example, if $A=\{1, 2\}$ and $B=\{a, b\}$, then $A \times B = \{(1, a), (1, b), (2, a), (2, b)\}$. The cartesian product is not symmetric, i.e. $A \times B \neq B \times A$.
$$
A \times B = \{(a, b) | a \in A \text{ and } b \in B\}
$$

A **powerset** $P_{S}$ of a set $S$ is the set of all subsets of $S$. Since the empty set is a subset of every set, a powerset always contains the empty set, thus we have 1 as a lower bound on the cardinality of the powerset. For example, given $S=\{0, 1, 2\}$, we have

$$
P_{S}=\{\emptyset\ , \{0 \}, \{1 \}, \{ 2 \}, \{ 0, 1 \}, \{ 0, 2 \}, \{ 1, 2 \}, \{ 0, 1, 2 \}  \}
$$

Alternatively, we can define a subset of $P_{S}$ such that all the sets of the subset have the same cardinality. We denote this by $\binom{S}{n}$, where $n$ is the cardinality of the sets in the subset. For example, given $S=\{0, 1, 2\}$, we have $\binom{S}{n}=\{\{0, 1\}, \{0, 2\}, \{1, 2\}\}$.

Observe that in our example, $|P_{S}|=8=2^{3}=2^{|S|}$. This is true in general, and we can prove this by induction on the number of elements in $S$. 

First, if $|S|=0$, we have $P_{S}=\{ \emptyset \}$ and since every number but zero to the power of zero is defined to be 1, we get $|P_{S}|=2^{0}$ and the statement holds. Similarly, for $|S|=1$ we have only two possible subsets - the empty set and $S$ itself, thus we have $|P_{S}|=2$, which is $2^{1}$. Now, we assume that it holds up to $|S|=n$, and denote its powerset $P_{n}$. By adding an element $s$ to $S$, we get a new set $S_{n+1}$. Denote its powerset as $P_{n+1}$. A subset of $S_{n+1}$ either includes $s$ or it does not. Consider the following sets:

$$
\begin{gathered}
P'_{n+1} = \{P' \in P_{n+1} | v \notin P' \} \\
P''_{n+1} = \{P'' \in P_{n+1} | v \in P'' \}
\end{gathered}
$$

Clearly, $P'_{n+1} \cup P''_{n+1} = P_{n+1}$. Now, consider a function $f: P'_{n+1} \to P''_{n+1}, p' \mapsto p''$ defined as:

$$
f(p') = p' \cup \{s\}
$$

Clearly the image of $f$ is $P''_{n+1}$, and clearly we have an inverse in $f^{-1}=p'' \setminus \{s\}$, thus $f$ is a bijection, which means that the cardinality of the image of $f$ is the same as that of the preimage, which in this case is the entire domain $P'_{n+1}$, thus we get

$$
|P''_{n+1}|=|P'_{n+1}|
$$

Now, observe that every member of $P_{n}$ is a subset of $S$ which itself is a subset of $S_{n+1}$, thus $P_{n}$ is a subset of $P_{n+1}$. Furthermore, if a subset of $S_{n+1}$ does not contain $v$ then clearly it is also a subset of $S$ which makes it a member of $P_{n}$, but this exactly how we defined $P'_{n+1}$, thus we have $P'_{n+1}=P_{n}$, so we get

$$
|P''_{n+1}|=|P_{n}| \underset{\text{induction hypothesis}}{=} 2^{n}
$$

Which means

$$
|P_{n+1}|=|P'_{n+1}|+|P''_{n+1}|=2|P_{n}|=2^{n+1}
$$

Proving the lemma.

Notice that in our proof, we defined a bijection from $P'_{n+1}$ to $P''_{n+1}$. This bijection implies a strong relation between the sets, even though they do not contain exactly the same elements. Perhaps a more obvious and more motivating example is the following sets

$$
\begin{array}{cc}
A=\{a, b, c, d \} & B =\{1, 2, 3, 4 \}
\end{array}
$$

Clearly $A$ and $B$ seem identical up to the choice of elements, but by definition of set equality they are not the same. However, we can define a function $f: A \to B$ and a function $g: B \to A$ such that $f \circ g: B \to B$ is the identity on $B$, and similarly $g \circ f: A \to A$ is the identity on $A$. We call such construction an **isomorphism** between sets.

Two sets are **isomorphic** iff there exists functions $f: A \to B$, $g: B \to A$ such that $f \circ g$ is the identity on $B$ and $g \circ f$ is the identity on $A$. We denote this by $A \cong B$. Many properties of sets are preserved under an isomorphism, which makes them a powerful tool. One property which we've already seen to be preserved is the cardinality of the sets.

## Set Relations

A **binary relation** $R$ on two sets $A, B$ is a subset of the cartesian product $A \times B$. For example, given the set of natural numbers $\mathbb{N}$, we can define a binary relation $a \gt b$ as follows in terms of a membership test:

$$
R = (\mathbb{N}, \gt) = \{(a, b) | a, b \in \mathbb{N}, a \gt b\}
$$

Thus another way to think of binary relations is as a function which takes an element of $A$ and an element of $B$ and returns a boolean result. Note that in our example, $(3, 0)$ is in the relation but $(0, 3)$ is not, which aligns with our usual notation for a comparison between two numbers: $3 \gt 0$ but $0 \ngtr 3$.

We denote two elements related by a binary relation by the tilde symbol:
$$
a \overset{R}{\sim} b \vcentcolon= (a, b) \in R
$$

In our example, we have $3 \overset{\gt}{\sim}0$.

A binary relation may have the following properties:

1. **Reflexive**: A relation on a set $A$ is reflexive iff $\forall a \in A, a \sim a$. For example, the identity relation which is the subset of $\{(a, a) | \forall a \in A \}$ is reflexive.
2. **Symmetric**: A relation on $A\times B$ is symmetric iff $\forall a \in A, b \in B$ s.t. $a \sim b$, we have $b \sim a$. For example, the equality relation is symmetric ($a=b$ necessiates $b=a$).
3. **Antisymmetric**: A relation is anti-symmetric iff $\forall a \in A, b \in B$ s.t. $a \sim b$ and $b \sim a$, we have $a=b$. For example, the subset relation is anti-symmetric - if $A \subseteq B$ and $B \subseteq A$ then $A=B$.
4. **Transitive**: A relation is transitive iff $a \sim b$ and $b \sim c$ implies $a \sim c$. For example, **public inheritance** in C++ is transitive - if $A$ publicly inherits from $B$ and $B$ publicly inherits from $C$, then $A$ publicly inherits from $C$.
5. **Complete**: A relation is complete iff $\forall a \in A, b \in B$ we have $a \sim b$ or $b \sim a$. For example, the relation $\geq$ is complete on $\mathbb{N}$, however the relation $\gt$ is not complete since if we take $(\mathbb{N}, \gt)$, clearly $\forall n \in \mathbb{N}, n \ngtr n$.

An **equivalence relation** is a binary relation which is *reflexive*, *symmetric* and *transitive*. It is easy to show that our classic notion of equivalance between numbers and algebraic expressions is an equivalance relation. An isomorphism between sets is also an equivalance relation: consider two sets $A, B$, clearly $A \cong A$ since we can compose the identity function with itself to get a bijective mapping $A \to A$, thus it is reflexive. Furthermore, since the construction of the isomorphism is symmetric, if we have $A \cong B$ we can simply reverse the order of the functions to get $B \cong A$, thus it is symmetric. Finally, if $A \cong B$ and $B \cong C$, then clearly we can compose functions from $A \to B$, $B \to A$ and functions from $B \to C$, $C \to B$ s.t. $A \cong C$, thus it is transitive. Thus an isomorphism is an equivalance relation.

A **partial order** is a binary relation which is *reflexive*, *anti-symmetric* and *transitive*. For example, the classic notion of "greater than or equals" for real numbers is a partial order: $\forall a \in R$ we have $a \leq a$ so it is reflexive, if $a \leq b$ and $b \leq a$ then $a=b$ so it is anti-symmetric, and $a \leq b$ and $b \leq c$ implies $a \leq c$ so it is transitive.

# Graph Basics

Consider the examples presented in the beginning of the article. We modeled the problem as a set of elements and connectivity between them. The elements are a set and the connectivity is a symmetric (since the order in which the elements were connected is of no concern to us in the problems we discussed) binary relation on the elements of the set. 

A **graph** is a structure which consists of such elements and binary relations between them. We call the elements *vertices* or *nodes*, denoted by $V$, and the relations *edges*, denoted by $E$. Since a binary relation of a set with itself is a subset of the cartesian product of the set with itself, we can define the edges as a set of sets which consist of two vertices, thus we define a graph by two sets $V, E$ s.t. $E \subseteq \binom{V}{2}$. We denote a graph as $G=(V, E)$. When discussing multiple graphs, we denote the vertices of $G$ as $V(G)$ and the edges of $G$ as $E(G)$ to prevent ambiguity. A graph with no edges is called the **empty graph**. Each vertex $v$ s.t. $\forall e \in E, v \notin e$ is called an **isolated vertex**.

If $E$ is a symmetric relation, then its members are unordered and we say that travel is allowed in both direction, thus $\{v_{1}, v_{2}\} \in E$ means that we go from $v_{1}$ to $v_{2}$ and vice versa. In this case, we say that $G=(V, E)$ is an **undirected graph**. In our previous discussion, the graphs were undirected. For now, we will only discuss undirected graphs.

If the sets are ordered, we say that travel is allowed only in one direction, thus $(v_{1}, v_{2}) \in E$ means that we go from $v_{1}$ to $v_{2}$ but not the other way around. In this case, we say that $G=(V, E)$ is a **directed graph**, and when drawing the edges we use arrows to indicate the direction of travel.

We say that two vertices are *adjacent* or *neighbors* if they are connected by an edge, i.e. two vertices $v_{1}, v_{2} \in V$ are adjacent iff $\{v_{1}, v_{2}\} \in E$. A vertex $v$ and an edge $e$ are *incident* iff $v \in e$.

A **loop** is an edge $e=\{v, v\} | v \in V$.

A **parallel edge** is an edge $e \in E$ such that $\exists e' \in E, e \neq e'$ and $e = e'$. Put it words, two edges are said to be parallel if they connect the same two vertices.

A **simple graph** is one with no loops nor parallel edges. Later we will mostly discuss simple undirected graphs.

The **degree** of a vertex $v$ in a graph is the number of edges incident with $v$. When counting the degree of a vertex, each loop incident with it is counted twice, with the rational being that each end of the loop is coming out of $v$, thus the two ends can be thought of as parallel edges connecting $v$ to a non-existing *loop vertex*. In the 3 by 3 knight's tour problem graph, each vertex has a degree of 2, except for $B2$ which is an *isolated vertex* and has a degree of 0. The degree of $v \in V$ is usually denoted $\text{deg}(v)$, or $\text{deg}_{G}(v)$ to disambiguate the graph with respect to which the degree is being calculated. The minimum vertex degree in a graph is denoted by $\delta(G)$, and the maximum degree is denoted by $\Delta(G)$.

The ordering of all the degrees of the vertices in descending order is called a **degree sequence**. Degree sequences which represent valid graphs are called **graphical**.

An important result related to degree sequences is the **handshake lemma**. The lemma states that in any graph, the sum of the degrees of all the vertices is equal to twice the number of edges

$$
\sum_{v \in V} \text{deg}(v) = 2|E|
$$

This result is also known as the *degree sum formula*. Convince yourself that this is true by considering that each edge is incident with two vertices, thus contributing 2 to the sum of degrees, thus the sum of degrees must be twice the number of edges. This also motivates counting the degree of a loop as 2. A proper proof by induction can be formulated as follows - consider a graph with 0 edges, clearly all vertex degrees are 0 and the formula holds. When $|E|=1$, clearly both endpoints of $e$ have degree 1, thus the sum of degrees is $2$, and the formula holds. Now we assume that it is true for some $|E|=n$, and consider the case of $|E|=n+1$. By introducing a new edge to the graph, we have necessarily increased the sum of degrees by two, thus we have a new sum that is $2n+2=2(n+1)=2|E|$, completing our proof.

An immediate result of the handshake lemma, sometimes referred to as the handshake lemma itself, is that the number of vertices of odd degree in a graph is always even. This is because the sum of degrees is always even, and if we have an odd number of odd degree vertices, then the sum of degrees would be odd, which contradicts the handshake lemma. We sometimes call a vertex with an odd degree an **odd vertex**. The handshake lemma and its results provide us with a way of testing if a degree sequence is graphical.

## Fundamental Graphs

It is beneficial to discuss a few elementary example of graphs that maintain certain properties to get a better feel for graphs. As we will soon see, these basic examples can be used to characterize the properties of more general graphs.

First, consider a graph with $n$ vertices $V=[0:n-1]$ and all possible edges between them, meaning that the relation is not only symmetric but also complete, i.e. $E=\binom{V}{2}$. We call this graph the **complete graph** on $n$ vertices, denoted by $K_{n}$, or a **clique** if it is found as a subgraph. The degree of each vertex in a complete graph is $n-1$, since each vertex is connected to every other vertex. We can write $K_{n}$ is set notation as

$$
K_{n} = (V, E) = ([:n-1], \binom{V}{2})
$$

Below is a drawing of $K_{5}$

TODO K5

While a drawing may be more intuitive, note that a drawing of a graph is not unique, so special cares needs to be taken when using drawings to reason about graphs and derive theorems and algorithms. As an example, consider the following two drawings, both are drawings of $K_{4}$ yet are different

TODO K4 two ways

We will define drawings formally in a later section.

The number of edges in a complete graph is given by the binomial coefficient $\binom{n}{2} = \frac{n(n-1)}{2}$.

Another important graph is the **path graph**. A path graph is a graph with $m$ edges and $m+1$ vertices $V=[:m]$ s.t. each vertex but the first and the last is connected to the vertex before and after it via an edge, thus we have $\text{deg}(v)=2$ if $v \neq 0, m$ and $\text{deg}(v)=1$ if $v=0, m$. We denote the graph path on $m$ edges as $P_{m}$. We can think of a path graph as the path of a bus - each vertex is a bus stop and each edge is a road connecting two bus stops. In set notation, we write

$$
P_{m} = (V, E) = ([:m], \{\{i, i+1\} | i \in [:m-1]\})
$$

A **cycle graph** is a path graph where the first and last vertex are connected. A cycle graph with $n$ vertices is denoted by $C_{n}$. In set notaton, we have

$$
C_{n} = (V, E) = ([:n-1], \{\{i, i+1 \mod (n-1) \} | i \in [:n-2] \})
$$

In a cycle graph, we have $\lambda v = \Lambda v = 2$. This folllows quickly from the set notation of $C_{n}$: since each vertex belongs to two edges, then the degree of all vertices in a cycle graph is 2.

A **star graph** is a graph with $m$ edges and $m+1$ vertices such that one vertex is connected to all other vertices, thus it has degree $m$ and the rest have degree $1$. In set notation, we write

$$
P_{m} = (V, E) = ([:m], \{\{m, i\} | i \in [:m-1]\})
$$

Below is a drawing of $S_{6}$

TODO Star S6

A graph is **bipartite** if its vertices $V$ can be partitioned into two disjoint sets $U, W$ such that no edge connects a vertex from $U$ to a vertex in $W$: $E \subseteq U \times W$. A bipartite graph is sometimes denoted as $G=(U \cup W, E)$ to illustrate that the vertices are distinct sets. For example, in the following drawing we have a bipartite graph with $U=\{a, b, c\}$ and $W=\{d, e\}$:

TODO bipartite graph

A simple graph is **complete bipartite** if it is bipartite and $E=U \times W$. The cannonical family of complete bipartite graphs is denoted by $K_{n, m}$ where $n, m$ are the cardinalities of $U, W$ and we have $U=[:n-1]$ and $W=[n:m-n-1]$. Note that the order doesn't matter - $K_{2, 3}=K_{3, 2}$. Below is a drawing of $K_{3, 2}$

TODO K3, 2

# Relations on Graphs

Consider two graphs $G, H$. We wish to extend the binary relations between sets which we have introduced earlier to graphs.

We say that the two graphs are **equal** iff the sets of vertices and edges are equal

$$
G=H \iff V(G)=V(H) \land E(G)=E(H)
$$

A graph $H$ is a **subgraph** of $G$ if $V(H) \subseteq V(G)$ and $E(H) \subseteq E(G)$. We denote this by $H \subseteq G$. Note that we can't take any arbitrary subset of $E(G)$ - for $H$ to be a graph we must have $E(H) \subseteq \binom{V(H)}{2}$, thus we can only take edges which are incident with the vertices in $V(H)$.

A subgraph is constructed as a sequence of operations which can be split to two categories:
1. *Edge deletion*: given a graph $V(G), V(E)$, we can take any subset $H(E) \subseteq V(E)$ and create a new graph $H=V(G), H(E)$. Since $V(H)=V(G)$, we have $H(E) \subset \binom{V(H)}{2}$, thus $H$ is a graph. Such graph is called a **spanning subgraph**.
2. *Vertex deletion*: given a graph $V(G), V(E)$, we can remove a vertex $v$ and all the edges incident with it to get a new graph $H=(V(G) \setminus \{v\}, E(G) \setminus \{e | v \in e\})$. Observe that this graph also meets the condition for a graph. We call such graph an **induced subgraph**. The graph created by removing all vertices not adjacent to a vertex $v$ is called the **neighborhood** of $v$.

Any subgraph of $G$ can be constructed using a sequence of edge deletions and vertex deletions. This is trivial to prove using the transitive property of the subset relation and the definition of a graph.

Two graphs $G, H$ are **isomorphic** iff there exists a bijection $f: V(G) \to V(H)$ such that $\{u, v \} \in E(G) \iff \{f(u), f(v)\} \in E(H)$. We denote this by $G \cong H$. An isomorphism between graphs preserves the abstract structure of a graph, i.e. the relations between vertices, and thus two graphs being isomorphic is essentially the same as the two graphs being equal, and in the case of unlabeled graphs (i.e. graphs where we don't explictly label the members of $V$), both definitions are in fact the same. 

As an example, consider the graphs $G=(\{A, B, C\}, \binom{V(G)}{2})$ and $C_{3}$. Clearly $V(G) \neq V(C_{3})$ thus $G \neq C_{3}$, however given the bijective map $f$ which maps $A, B, C$ to $0, 1, 2$ respectively, it is trivial to show that $f$ is an isomorphism, thus we have $G \cong C_{3}$ under $f$. Note that an isomorphism isn't unique - consider the map $h$ which takes $B, C, A$ to $0, 1, 2$, clearly $h(B) \neq f(B)$ thus $h \neq f$, however it is easy to show that $h$ is also an isomorphism between the graphs.

Consider the following graph $G$:

TODO graph with vertices A, B, C which contains $C_{3}$

Clearly, the graph $H=(\{A, B, C\}, \{\{A, B\}, \{B, C\}, \{C, A\}\})$ is a subgraph of $G$, thus we have $H \subseteq G$. Observe that $E(H)=\binom{V(H)}{2}$, thus we have $H \cong C_{3}$, and we also have $H \subseteq G$, so we have $C_{3}$ isomorphic to a subgraph of $G$. Since an isomorphism often captures all the properties of a graph we care about, we often abuse the notation of a subgraph and write $C_{3} \subseteq G$ to mean that $C_{3}$ is isomorphic to a subgraph of $G$.

Recall that we defined set isomorphism as the composition of two functions on the sets. We would like to construct an equivalent definition for graph isomorphism, that is equivalent to the more natural definition of an isomorphism which we presented above. We will do this by introducing a new definition - a *homomorphism*.

A *homomorphism* between two graphs $G, H$ is a pair of functions $f_{V}, f_{E}$ such that
1. $f_{V}: V(G) \to V(H)$
2. $f_{E}: E(G) \to E(H)$
3. $\forall \{u, v \} \in E(G), f_{E}(\{u, v \}) = \{f_{V}(v), f_{V}(u)\}$

We denote a homomorphism by $f: G \to H, f=(f_{V}, f_{E})$. Observe that the third requirement means that $f_{E}$ is uniquely determined by $f_{V}$ to be $f_{E}(\{u, v\})=\{f_{V}(u), f_{V}(v)\}$.

Unlike an isomorphism, a homomorphism needn't be bijective. For example, consider the graphs $K_{2}$ and $C_{4}$. Clearly we cannot construct a bijection $f_{V}: V(K_{2}) \to V(C_{4})$ since $|V(C_{4})| \gt |V(K_{2})|$, however consider the following function:

$$
\begin{gathered}
f_{V}: V(C_{4}) \to V(K_{2})\\
f_{V}(v) = \begin{cases} 0 & \text{v is even} \\ 1 & \text{v is odd} \end{cases} \\ \\
\end{gathered}
$$

Observe that by our set notation definition of $C_{4}$, it consists of edges of the form $\{i, i+1 \mod 4\}$. If $i$ is odd, then $i+1$ is even and $i+1 \mod 4$ is even, similarly if $i$ is even then $i+1 \mod 4$ is odd, thus in terms of parity, all edges of $C_{4}$ are of the form $\{ \text{even}, \text{odd} \}$ (disregarding the order since it is an unordered set), thus we get $f_{E} = \{f_{V}(\text{even}), f_{V}(\text{odd})\} = \{0, 1\} \in E(K_{2})$, thus we have a homomorphism $f: C_{4} \to K_{2}$. To convince yourself that $C_{4}$ and $K_{2}$ are isomorphic, consider the following: $K_{2}$ connects two vertices, which can be thought of as two distinct groups (remember that a set can also be a set of sets). In $C_{4}$, we have edges between $0$ and $1$, $1$ and $2$, $2$ and $3$, and $3$ and $0$, notice that there are no edges between $0$ and $2$ or between $1$ and $3$, thus $C_{4}$ is bipartite. In a bipartite graph, we think of the vertices of the graphs as the union of two distinct sets, and the only allowed edges are those that are in the cartesian product of the sets, i.e. those that connect the two sets. By mapping the distinct vertices sets to distinct vertices, we can capture this property of the graph by a single edge conencting the vertices. This is a more intuitive interpretation of a homomorphism. 

In fact, we can show that **a graph is bipartite iff it is homomorphic to $K_{2}$**. Consider a graph $G$. If $G$ is bipartite, then we have $V(G)=U \cup W$ s.t. $U \cap W = \emptyset$. Consider the function $f_{V}: V(G) \to V(K_{2})$ defined as follows

$$
f_{V}(v) = \begin{cases}
0 & v \in U \\
1 & v \in W
\end{cases}
$$

Consider an edge $e=\{u, w\} \in E(G)$. By definition of a bipartite set we have $u \in U$ and $w \in W$, so we have $f_{E}(e)=\{0, 1 \}$ which is an edge in $K_{2}$, thus completing the first part of the proof.

Next, consider a graph $G$ homomorphic to $K_{2}$, thus there exists functions $f_{E}$ and $f_{V}$ s.t. $f_{E}(\{u, w\})=\{f_{V}(u), f_{V}(w)\}=\{0, 1\}$ (since that is the only edge of $K_{2}$). If $G$ is the empty graph, then it's vacously true that $G$ is bipartite. Next, denote $U$ to be the preimage of $0$, and $W$ to be the preimage of $1$. To prove that $G$ is bipartite, we need to show that no edge exists between two vertices of $U$ or two vertices of $W$. The proof is symmetric for both cases so w.l.o.g we will prove it for $U$. Let $u_{1}, u_{2}$ be two vertices of $U$, not necessarily distinct (to allow for loops as well), such that $e=\{u_{1}, u_{2}\} \in V(G)$. Since $G$ is homomorphic to $K_{2}$, $f_{E}(e) \in E(K_{2})$, however $f_{E}(e)=\{0, 0 \}$ which is clearly $\notin E(K_{2})$, which is a contradiction. Thus no inner-group edges are in $G$, thus $G$ is bipartite with vertices sets $U, W$. A related result is that every cycle graph with an odd number of vertices is bipartite, and every cycle graph with an even number of vertices is not bipartite. This result can be shown by making some slight modifications to our proof that $C_{4}$ is homomorphic to $K_{2}$, and showing that adding a vertex to the cycle breaks the homomorphism.

Using graph homomorphism, we can provide an equivalent definition to graph isomoprhism: two graphs $G, H$ are *isomorphic* iff there exists a homomorphism $f: G \to H$ and $g: H \to G$ s.t. $f \circ g = I_{G}$ and $g \circ f = I_{H}$, where $I$ is the identity and the identity on a graph $G$ and a composition of homomorphisms is defined as a pair of functions which are the composition of each function of each homomorphism, i.e $f \circ g = (f_{V} \circ g_{V}, f_{E} \circ g_{E})$. It can be shown that this definition is equivalent to the one we presented earlier.

With this basic set of tools, we can already identify some **graph invariants**, i.e. properties of a graph which are preserved under an isomoprhism. We shall provide an initial least here, and extend it as we present more definitions.

First, the cardinalities of $V$ and $E$ are preserved under an isomoprhism. This is trivial to show with the first definition of an isomorphism - for $f: V_{G} \to V_{H}$ to be a bijection, the image and the preimage should be of the same cardinality.

Consider a vertex $v \in V_{G}$. Under an isomoprhism, we have a one-to-one relation $\{v, v'\} \mapsto \{f(v), f(v')\}$, where $v'$ is a neighbor of $v$, thus the *degree* of $v$ is preserved under an isomorphism, which means that *degree sequences* are also preserved.

Another property of a graph is the state of being bipartite (or not). Recall that we have shown that a graph is bipartite iff it is homomorphic to $K_{2}$. Let $G$ be isomorphic to $H$, then there exists a homomorphism $f: G \to H$. Let $H$ be bipartite, thus it is homoromphic to $K_{2}$ under $g: H \to K_{2}$. It is easy to show that a homomorphism is transitive, and thus we have $g \circ f: G \to K_{2}$, thus $G$ is bipartite. The converse is also true - we can prove this by contradiction using the same argument.

One last property is the notion of a a graph $G$ being isomorphic to a subgraph of $H$. Let $K \cong G$. Since an isomorphism is an equivalence relation, it is transitive, thus we have $K$ also isomorphic to a subgraph of $H$.

In summary, we have the following properties preserved under an isomorphism:
1. The cardinality of $V$ and $E$.
2. The degree of vertices and the degree sequence of the graph.
3. The bipartite state of the graph.
4. The property of being isomorphic to a subgraph of another graph.

As we gather more tools and properties to describe graphs, we will check whether or not they are graph invariants. Much to our delight, we will see that almost all relevant properties are invariant.

# Graph Coloring

Consider the following problem - you are planning a seating arrangment for a wedding. However, not all guests can sit next to each other due to bad blood and other reasons. This problem can also be modeled as a graph problem, by taking the guests as vertices and mapping the "seatability" of pairs of guests as edges - if two guests cannot sit next to each other, we add an edge. This is somewhat counter-intuitive since when drawing a graph, we draw edges as connections between vertices, and in this case we are drawing edges to represent a conflict, i.e. a lack of connection. However, if we think back to our definition of a graph and of edges of a graph as a binary relation, this should make sense - we are simply defining a binary relation between the guests.

Consider a simple case - assume you have 4 guests numbered $[1:4]$ s.t. $1$ and $3$ can't sit next to $2$ or $4$, modeled as a graph in the following drawing:

TODO wedding plannar

One viable sitting arrangment would be one that partitions the guests into different tables, such that each table has no conflicts. In our example, it is obvious that we need two tables - one for persons $1$ and $3$, and one for persons $2$ and $4$. This is denoted in the graph by the colors assigned to each vertex - each color maps to a different table. Note how adjacent vertices have different colors. This is called a *graph coloring*.

Let us define graph coloring properly. A **graph coloring** of a graph $G$ is a mapping $c_{V}: V(G) \to V(C)$, where $V(C)$ is a set of *colors*, such that $\forall e=\{u, v\} \in E(G), c_{V}(u) \neq c_{V}(v)$, i.e. adjacent vertices are assigned different colors. Such coloring is also called a *proper coloring*. For simplicity, we will denote $V(C)$ by $[:k-1]$ if $|V(C)|=k$. In our example, we have $k=2$. We say that a graph is **k-colorable** if a coloring with $k$ colors exists. We see that the graph in our example is $2$-colorable.

Observe that our example is a coloring of a graph isomorphic to $C_{4}$, which is bipartite and homomorphic to $K_{2}$. Since a coloring is a partitioning of vertices into distinct sets, we can think of a coloring as an extension of a bipartite graph to $k$ different sets.

We have seen that a graph is bipartite iff it is homomorphic to $K_{2}$. Since we reason about graph coloring as an extension of the notion of a bipartite graph, it is reasonable to ask - given a graph coloring with $n$ colors, can we view the coloring as a homomorphism with $K_{n}$? The answer is yes, and in fact a stronger statement is true: **A graph $G$ is n-colorable iff there exists a homomorphism $c: G \to K_{n}$, with $c$ being the coloring.**

For the first direction, consider a graph $G$ which is $n$-colorable, then there exists a function $c_{V}: V(G) \to [:n-1]$ such that $\forall \{u, v \} \in E(G), c(u) \neq c(v)$. Consider the function $c_{E}: \{u , v \} \in E(G) \mapsto \{c(u), c(v)\}$. Clearly $c(u), c(v) \in V(K_{n})$ and since $\{c(u), c(v) \} \in \binom{V(K_{n})}{2}$, we have $c_{E}: E(G) \to E(K_{n})$, thus we have $c=(c_{V}, c_{E}): G \to K_{n}$ a homomorphism.

For the other direction, let $c: G \to K_{n}$. Assume by contradiction that $c_{V}$ is not a coloring, thus $\exists \{u, v\} \in E(G), c_{V}(u)=c_{V}(v)$, which means that both vertices are mapped to the same edge. Since $c$ is a homomorphism, then $c_{E}(\{u, v\})=\{c_{V}(u), c_{V}(v)\} \in E(K_{n})$. However, if $c_{V}(u)=c_{V}(v)$, then the edge $\{u, v \}$ is not mapped to an edge, thus $c_{E}$ is not a map from $E(G)$ to $E(K_{n})$, which contradicts $c$ being a homomorphism. Thus by contradiction we have $c_{V}$ is a coloring.

The **chromatic number** of a graph is the minimum number of colors needed to achieve a proper coloring of the graph, denoted by $\chi(G)$. Since we require that adjacent vertices will get different colors, we have a lower bound $\chi(G) \geq \Delta(G)$. Since a bipartite graph is homomorphic to $K_{2}$, we have $\chi(G)=2$ for every bipartite graph. The chromatic number is a graph invariant, and this can be proved directly from the fact that a graph coloring is a homomorphism to $K_{n}$, thus if $G \cong H$ and $\chi(G)=n$ then there exists $f: G \to K_{n}$ and since $G \cong H$ under some $f$ we can compose $c \circ f$ to get a homomorphism $H \to K_{n}$, thus $\chi(G) = \chi(H)$.

# Walks

In the bridges of Konigsberg problem, we are looking for a way to take a walk around the city such that we cross each bridge once. When modeling the problem as a graph, the graph becomes a map of the different regions of the city, which are connected by edges representing the bridges that we can physically walk across, and a solution would be one where we "go for a walk" on the graph. This motivates the definition of a **walk** in a graph.


A **walk** in $G$ is an ordered sequence of $n$ edges $(e_{1}, e_{2}, \dots, e_{n}) \in E(G)$ and on ordered sequence of $n+1$ vertices $(v_{0}, v_{1}, \dots, v_{n})$, such that $e_{i}=\{v_{i-1}, v_{i}\}$. In a simple graph, we disallow parallel edges, thus a walk in a simple graph is strictly defined by its sequence of vertices $(v_{0}, v_{1}, \dots, v_{n} )$ s.t $\{v_{i}, v_{i+1} \} \in E(G) | i \in [:n-1]$. Consider the following graph

TODO graph with walk a - b - c - d - c - E

The sequence $(b, c, d, c, e)$ is a walk on the graph. We can convince ourself that this is true visually by tracking the path on the graph with our finger such that the finger is only allowed to move along the edges of the graph, as long as we do not need to lift our finger to move to the next vertex in the walk, the walk is valid. Note that in our walk, we repeat the edge $\{c, d\}$ and the vertex $c$ twice - this is allowed in a walk. We soon introduce more strict definitions based off a walk in which this will not be allowed, and there the vertices and edges of a walk will be proper sets.

We will use the definition of a walk to define other properties of a graph. Whenever we define a property, we would like to check if it is a graph invariant. We have seen that proving that a property is a graph invariance is easy if it follows from a homomorphism, thus we would like to provide an equivalent definition for a walk via a homomorphism.

We have already seen a family of graphs which exhibits a walk - the path graph. Indeed, we can define a walk as homomorphism to the cannonical path graph. Consider a walk $w$ on a graph $G$ with vertex sequence $v_{w}$ such that $|v_{w}|=m+1$ and edge seequnce $e_{w}$ such that $|e_{w}|=m$, and the cannonical path graph $P_{m}$. Recall our definition for $P_{m}$: 

$$
P_{m} = (V, E) = ([:m], \{\{i, i+1\} | i \in [:m-1]\})
$$

We define $w: P_{m} \to G = (w_{V}, w_{E})$ as follows

$$
\begin{gathered}
w_{V}: V(P_{m}) \to V(G), i \mapsto v, \\
w_{V}(i) = v_{{w}_{i}} \\\\

w_{E}: E(P_{m}) \to E(G), \{i, i+1\} \mapsto e, \\
w_{E}(\{i, i+1\}) = \{v_{{w}_{i}}, v_{{w}_{i+1}}\} = e_{w_{i}}
\end{gathered}
$$

Clearly, $w$ is a homomorphism from $P_{m}$ to $G$, thus a walk is a homomorphism from $P_{m}$ to $G$. One can easily verify that the converse is also true - if $w: P_{m} \to G$ is a homomorphism, then the image of $w$ is a walk on $G$. In our example, the homomorphism takes the vertices $\{0, 1, 2, 3, 4 \}$ of $P_{5}$ to $(b, c, d, c, e)$, while taking the edges to edges in $G$. Note that the edges $\{1, 2 \}$ and $\{2, 3 \}$ both get taken to the edge $\{c, d \}$, thus the mapping is not injective.

A **trail** is a walk with no repeated edges, i.e. the image of $w_{E}$ is a set, i.e. $w_{E}$ is injective. A **path** is a walk with no repeated vertices, i.e. $w$ is injective.  A **closed walk** is a walk that starts and ends at the same vertex, i.e. $v_{0}=v_{n}$. A **tour** is a closed walk with no repeating edges, i.e. $w_{E}$ is injective. A **cycle** is a closed path, i.e. a closed walk where $w$ is injective. A graph with no cycles is called **acyclic**.

Since we already defined a fundamental family of graphs that have this cycle property - the cannonical cycle graphs $C_{k}$ - it makes sense to define a closed walk on $n$ vertices on $G$ as a homomorphism $w: C_{n} \to G$ by mapping every vertex of $C_{n}$ to the corresponding vertex of the walk, i.e. $i \mapsto v_{w_{i}}$. Using this definition, it is easy to show that having a cycle is a graph invariant - if $G \cong H$ and $G$ has a cycle, then there exists a homomorphism $f: C_{K} \to G$ and a homomorphism $g: G \to H$, so we can construct a homomorphism $g \circ f: C_{K} \to H$, thus $G$ is also homomorphic to $C_{K}$, thus $G$ also has a cycle. If $H$ has a cycle, then we follow the same proof to compound a homomorphism $C_{k} \to H$ and $H \to G$.

# Connectivity

Edges are connections between adjacent vertices. If we wish to travel between two vertices in a graph, we go for a walk. Given two vertices $u, v \in V$, we define a $(u,v)$-walk as a walk starting at $u$ and ending at $v$. Generally, there is not always a $(u, v)$-walk between any two vertices in a graph. As a trivial example, if $G$ has an isolated vertex and we take it as $v$, clearly no $(u, v)$-walk exists.

A graph $G$ is **connected** iff $\forall u, v \in V(G), \exists w: P_{K} \to G$ such that $w$ is a $(u, v)$-walk. Informally, a graph is connected if we can get from any vertex to any other vertex by means of traveling along the edges of the graph. A graph is **disconnected** if it is not connected.

Let $H \cong G$ under $f$, and let $G$ be connected. We wish to prove that being connected is a graph invariant. To do that, we need to show that $\forall u, v \in V(H)$, there exists a $(u,v)$-walk in $H$. Consider $f_{V}(u), f_{V}(v) \in V(G)$. Since $G$ is connected, there exists a walk between these vertices in $G$, i.e. we have a homomorphism $w: P_{K} \to G$ s.t. $w_{V}(0)=f_{V}(u)$ and $w_{V}(K)=f_{V}(v)$. $f$ is an isomorphism we have $f^{-1}: G \to H$ s.t. $f^{-1}\circ f = I_{H}$. By composition, we have $f^{-1} \circ w: P_{K} \to H$ a walk in $H$, with $(f^{-1} \circ w)_{V}(0)= f^{-1}_{V}f_{V}(u)=u$, and similarly we have $(f^{-1} \circ w)_{V}(K)=v$, thus $f^{-1}\circ w$ is a $(u-v)$-walk in $H$, and since we didn't limit our choice of $u, v$, we have $H$ connected. Proving the opposite direction follows a symmetrical argument, but this time we compose a walk $f \circ w: P_{K} \to G$.

Consider the following graph:

TODO graph with two connected components 1, 2, 3 and 4, 5, 6

Identify that the subsets of the graph induced by the vertices $\{1, 2, 3 \}$ and their incident edges, and the graph induced by $\{4, 5, 6\}$ and their incident edges. Observe that they are connected and that no edge incident with any vertex of either subgraph exists outside of the subgraph. We call these **components**, or **connected components**. A connected component is a maximal connected subgraph. In graph theory, when we say that something is "maximal" or "minimal" followed by a property, we mean that it is the largest or smallest such subgraph that maintains the property. In this case, when we say that a connected component is a maximal connected subgraph, we mean that a union of a connected component and any other edge or vertex from the larger graph will result in a disconnected subgraph, disconnecting the component. This idea can be illustrated in our example by considering any subgraph induced by $\{1, 2, 3\}$ and any of $\{4, 5, 6\}$ - since they belong to two distinct connected components of the same graph, no edge can connect them and so we say they are maximal connected. On the other hand, consider the subgraph induced by $\{1, 2\}$ - clearly it is connected, but it is not maximal - we can add $3$ and the edges incident with it and it will still be connected, thus it is not a connected component of the graph. In set notation, we can define a connected component $H$ as a connected subgraph of $G$ such that:

$$
\forall u, v \in V(H), \nexists e \in E(G) \setminus E(H) \text{ s.t. } u, v \in e
$$

Since we take the empty graph to be connected, we can say that a graph is always the union of its connected components. Let us prove this: consider a vertex $v \in V(G)$. If $v$ belongs to a connected component $C \subset G$, then it does not belong to any other connected component of $G$, otherwise the $C$ wouldn't be maximal connected and thus not a component. Similarly, if an edge of $v$ is not in $C$, then there exists some vertex $v'$ which is connected to $v$ and thus we can extend $C$ by including $v'$ and it will still be a connected subgraph, contradicting the assumption that $C$ is maximal connected, thus all edges of $v$ are in $C$, and by extension the neighborhood of $v$ is in $C$. If $v$ does not belong to a connected component, then it must have degree zero, and thus must be the empty graph, which by definition is a connected component. Thus, any vertex of $G$ either belongs to a single connected component $C$ which has at least one edge, or it belongs to the empty graph. Taking the union of all these connected components gives us all the vertices of $G$ along with all their edges, thus we have proven that a graph is the union of its connected components.

A connected graph has a single connected component, otherwise it must be disconnected since any two connected components are disconnected.

Consider the graphs $C_{3}$ and $P_{5}$

TODO C_{3}, P_{5}

Clearly both graphs are connected, however we can observe that by removing one vertex (and the edges incident with it) in $P_{5}$ which is not $0$ or $4$ (i.e. not a vertex with degree 0), $P_{5}$ becomes disconnected. However, it seems impossible to make $C_{3}$ disconnected by removing a single vertex. We are interested in studying this property in which some graphs are "more connected" than others. We call this property *k-coonectivity*.

A graph $G=(V, E)$ is *k-connected* if $|V| \gt k$ and the induced subgraph of $G$ by deleting any set of vertices $S \in V(G)$ such that $|S| \lt k$ is connected. Note that a graph that is $k$-connected is also $k-1$ connected, $k-2$-connected, etc, e.g. a 3-connected graph is also a 2-connected graph and a 1-connected graph. A graph is **well-connected** if it is k-connected with $k \gt 1$.

Consider the cannonical path graph $P_{k}$. If we remove a vertex $i \neq 0, k$, then we also remove an the edges $\{i, i+1 \}$ and $\{i-1, i\}$. Assume by contradiction that $G=P_{k} \setminus i$ is connected, then there exists a $(i-1, i+1)$-walk on $G$. Since all the edges of $G$ take the form $\{t, t+1\}$ then there is no edge from $i+1$ to $i-1$ that passes through any vertex $v \gt i+1$. Similarly for the same reason, for $i-1$ to connet to $i+1$ it must pass through a vertex $v \gt i-1$. Thus we have two options for the path: either the path is simply $(i-1, i+1)$, but since this isn't an edge in $P_{k}$ is is also not an edge in $G$ so it's impossible, or the path is $(i-1, i, i+1)$, however since $i$ is removed from $G$ clearly the path is not valid, thus we have $G$ disconnected since we found a set of vertices for which there is no walk, thus any cannonical path graph $P_{k}$ is 1-connected.

Consider a cannonical cycle graph $C_{n}$ and some $v \in V(C_{n})$. Recall that $v$ is denoted by a number in $[:n-1]$, thus $v$ is either $0$, $n-1$ or $v \in [1:n-2]$. If $v=0$, then we remove the edge $\{0, 1\}$ and $\{ n-1, 0\}$, thus the edges of $G=C_{n} \setminus 0$ are given by $\{i, i+1 \}$ where $i \geq 1$ (note that we no longer need the mod since we remove the edge connecting the first and last vertex), and the vertices are $[1:n-1]$. By mapping each vertex $i \in G$ to $i-1 \in P_{n-2}$, we constuct an isomorphism (this requires proof but is trivial to verify) $G \cong P_{n-2}$. A similar argument follows for the case where $v=n-1$. For the case where $v \in [1:n-2]$, we observe that the vertices $[:v-1]$ and $[v+1:n-1]$ are in $G=C_{n} \setminus v$, and consider the following mapping:

$$
\begin{gathered}
f_{V}: V(G) \to V(P_{n-2}), \\
f_{V}(i) = \begin{cases}
i-(v+1) & i \gt v \\
i+(v+1) & i \lt v \\
\end{cases}
\end{gathered}
$$

This maps $[v+1:n-1]$ to $[0:n-v-2]$ and $[:v-1]$ to $[n-v-1:n-2]$, thus $f_{V}$ is bijective. Next, consider an edge in $P_{n-2}$, which is given by $\{i, i+1\}$. There are 3 cases:

1. Both vertices are mapped according to the first case: $f^{-1}_{V}(i)$ is of the form $v \lt i+v+1 \lt n$ and $f^{-1}_{V}(i+1)$ is of the form $v \lt i+v+2 \lt n$ in $V(G)$, then we match the edge to the set $\{i+v+1, i+v+2\}$ and since the vertices are of the form $\{i, (i+1) \mod n\}$ and neither is $v$, the set is an edge in $G$.
2. Both vertices are mapped according to the second case: $f^{-1}_{V}(i)$ is of the form $0 \leq i-v-1 \lt v$ and $f^{-1}_{V}(i+1)$ is of the form $0 \leq i-v \lt v$ in $V(G)$, then we match the edge to the set $\{i-v-1, i-v\}$ and since the vertices are of the form $\{i, (i+1) \mod n\}$ and neither is $v$, the set is an edge in $G$.
3. $i$ is mapped according to the first case and $i+1$ is mapped according to the second case. This is only possible if $\{f^{-1}_{V}(i), f^{-1}_{V}(i+1) \} = \{n-1, 0\}, which is also of the form $\{i, (i+1) \mod n\}$ with $i, i+1 \neq v$, thus it is an edge in $G$.

In total, we paired all edges of the graph distinctly, thus we have $G \cong P_{n-2}$. To summarize, we have shown that $C_{n} \setminus v \cong P_{n-2}$ $\forall v \in V(C_{n})$, and since $P_{n-2}$ is 1-connected, this means that $C_{n}$ is 2-connected. Note that we use the fact that k-connectivity is a graph invariant, which we have not proven. 

Another important result is that if $G$ is $k$-connected, then $\delta G \geq k$. This can easily be proven as follows: let $v$ be a vertex with $\text{deg}(v)=\delta G$. Assume by contradiction that $\delta G \lt k$, thus $v$ is adjacent to at most $k-1$ vertices. By definition of $k$-connectivity, we can remove any $k-1$ vertices and the graph will still be connected. We shall remove all vertices adjacent to $v$, removing $k-1$ vertices. By definition of $k$-connectivity, $G$ is still connected, however now we have $v$ isolated with degree 0, and thus $\forall u \in V(G), u \neq v, \nexists (u, v)$-walk, which contradicts $G$ being connected, thus we have $\delta G \geq k$. It is important to note that this the converse is not true. Consider for example the following graph with $\delta G \gt 2$:

TODO cut vertex example 1-2-3-1-4-5-6-7-5, with 4 being a cut-vertex

Clearly removing vertex $4$ disconnects the graph, thus the graph is 1-connected. If there exists a single vertex which disconnects a graph, we all it a **cut vertex**. In the general case where $G$ is $k$-connected we will need at least $k$ vertices. A set of vertices which disconnects a graph is called a **separating set** or a **cut set**.

An **edge subdivision** of an edge $e$ in a graph $G=(V, E)$ is the graph $H=(V \cup w, (E \setminus e) \cup \{e', e''\})$, where $w$ is a new object (i.e. not in $V$) and $e', e''$ are defined as $\{e'_{0}, w\}, \{w, e'_{1}\}$. An edge subdivision is the act of taking an edge $e$ and replacing it with two new edges connected via new vertex. For example, the graph $P_{3}$ is a subdivision of the edge $\{0, 1\}$ of $P_{2}$. Another way to think of an edge subdivision is that it replaces an edge $\{a, b \}$ with a new $(a, b)$-walk of length 2.

The inverse of an edge subdivision is a **smoothing**. In a smoothing, we take a vertex $v$ such that $\text{deg}(v)=2$, connect its two neighbors via a new edge and then delete $v$ and its edges. A **graph subdivision** is the result of a sequence of edge subdivisions to a graph.

One property of edge subdvisions which relates to $k$-connectivity is that an edge subdivision of a 2-connected graph is 2-connected. Let $G$ be a 2-connected graph and let $e=\{a, b \} \in E(G)$. Let $H$ be the edge subdivision of $e$ and let $w$ be the added vertex incident with $a$ and $b$. $H$ is 2-connected if it remains connected when 1 vertex is removed from it. Let $s \in V(H)$ and let $H'=H \setminus s$, i.e. the induced subgraph of $H$ by deleting $s$. Let $u, v \in V(H')$. There are two cases:

1. $s \neq w$, in which case $u, v$ are either both in $V(G)$, or one of the vertices is $w$. In the former, consider a $G'=G \setminus s$. Since $G$ is 2-connected, there exists a walk in $(u, v)$-walk in $G'$. The only edge in $G'$ not in $H'$ is $\{a, b\}$, so we map any $\{a, b \}$ occurence in the walk to the added $(a, b)$-walk (which passes through $w$), thus for every $(u, v)$-walk in $G'$ we can match a $(u, v)$-walk in $H'$. If one of the edges is $w$, w.l.o.g $u$, then we consider a $(u, a)$-walk in $G'$, which is (via the mapping we described) a $(u, a)$-walk in $H'$, and then add to the edge $\{a, w\}$ to the edge sequence, thus forming a $(u, v)$-walk in $H'$.
2. $s = w$. Since $G$ is 2-connected, $\text{deg}(b) \geq 2$, thus $b$ has at least one neigbor $c \neq a$ and an edge $\{b, c \}$. Similarly, $G'=G \setminus b$ is connected, so there exists an $(a, c)$-walk in $G$ which does not pass through the edge $e$, to which we can add $\{b, c \}$ to get an $(a, b)$ walk not through $\{a, b \}$. Observe that in this case, $V(G)=V(H')$, thus for all $u, v \in V(H')$ we can find a $(u, v)$-walk in $G$, and replace every occurence of $\{a, b\}$ in the walk with the $(a, b)$-walk we described, thus we have a $(u, v)$-walk in $H'$.

And in total, we have $W'$ is connected, thus $W$ is 2-connected, thus an edge subdivision of a 2-connected graph is 2-connected.

In $(2)$, we actually proved another useful lemma: if $G$ is 2-connected, then every edge in $E(G)$ is part of a cycle. We provided a constructive proof in which we showed that in a 2-connected graph, for a given edge $e$ with $a, b \in e$, we can always find an $(a, b)$-walk which does not pass through $e$, and then add $e$ to the walk to get a cycle. 

## Megner's theorem

In the previous section, we showed that in a 2-connected graph, which is a graph with a cut set of cardinality 2, there exists 2 distinct paths between every pair of vertices. This can be generalized to any $k$-connected graph: in a finite graph $G$ that is $k$-connected, there exists $k$ internally disjoint paths between any pair of vertics $u, v \in V$, where paths are *disjoint* if they share no vertices, and *internally disjoint* if they share no vertices except for the endpoints. This result is known as [Megner's theorem](https://en.wikipedia.org/wiki/Menger%27s_theorem), which is a special case of the [Max-flow min-cut theorem](https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem). We will provide it directly here.

Let $A, B \subseteq V(G)$ sets (not necessarily disjoint) of vertices of $G$. An $AB$-separator is a set of verticse $S \subseteq V$ such that $G \setminus S$ contains no $AB$-path (an $AB$-path here is a natural extension of a path between two vertices, and defined as a path between a vertex of $A$ and a vertex of $B$ which has no internal vertices in $A$ nor $B$). An $AB$-connector is a set of disjoint $AB$-paths, i.e. paths statring at a vertex of $A$ to a vertex of $B$ such that they have no vertex in common. We allow single-vertex paths in this definition, for example if $u, v \in V$ are isolated, then by choosing $A=B=\{u, v\}$ we have an $S=A$ with an $AB$-connector being the single-vertex paths $\{u\}, $\{v\}$. We will use the following lemma:

**Lemma**: In a graph $G$, the minimum size of an $AB$-separator is equal to the maximum size of an $AB$-connector (or the number of disjoint $AB$-paths).

From this lemma, we prove Megner's theorem as follows: in a $k$-connected graph, we need to remove at least $k$ vertices for the graph to be disconnected, thus the minimum size of an $AB$-separator is $k$ if $|A|, |B| \geq k$ (otherwise we can't match $k$ pairs of vertices). Consider any two vertices $a, b \in V(G)$. By a previous result, we have $\lambda G \geq k$, thus $a$ and $b$ have $k$ neighbors each. Denote the set of neighbors $A$ and $B$ respectively. By the lemma, we have $k$ distinct $AB$-paths. For each path, take the end in $A$ and connect it to $a$ via the edge connecting it to $a$ (since $A$ is the neighbors of $a$ such edge exists), similarly connect the other end to $b$, thus constructing an $(a, b)$-path. This $(a, b)$-path is internally disjoint, and we have $k$ of those, proving the theorem.

As for the lemma, we will prove it by induction on $|E(G)|$ for any two sets $A, B \subseteq V(G)$. If $|E(G)|=0$, then we have no edges and only single-vertex paths, thus the number of disjoint paths is $|A \cap B|$ and a minimum separator is $S=A \cap B$ thus the maximum size of an $AB$-connector is the minimum size of an $AB$-separator. Otherwise, let $e=\{u, v\} \in E(G)$, and let $k$ be the size of the minium $AB$-separtor of $G$. Consider the graph $G'=G \setminus e$, and denote a minimum $AB$-separator in $G'$ as $S$. If $|S|=k$, then by the induction hypothesis we have a maximum $AB$-connector with size $k$, which is also an $AB$ connector in $G$ and we are done. If $|S| neq k$, then consider the set $S'=S \cup \{u\}$ (or $S \cup \{v \}$, the endpoint of $e$ which we pick is irrelevant). Clearly, $|S'|=|S|+1$, and clearly by removing $S'$ from $G$ we disconnect $A$ and $B$ since we remove $e$ as well as an $AB$-separtor in $G \setminus e$ thus $S'$ is an $AB$-separator in $G$, which means that $|S'|=k$, thus $|S|=k-1$. Next, consider a minimal $AS$-separator in $G$, denoted $T$. Clearly $T$ is also an $AB$-separator (but not necessarily minimal) since without $T$ no vertex of $A$ can reach $S$ and thus no vertex of $A$ can reach $B$, thus $|T| \geq k$. Consider the subgraph induced by $A, T, S$, clearly it is a subgraph of $T$ with at least one edge removed (the edge $e$), thus we can apply the hypothesis and have $k$ disjoint $AS$-paths. A symmetric arguments prove that there are $k$ disjoint $SB$-paths. Since $|S|=k$, each path is incident with a single vertex of $k$, thus for any $s \in S$ we have an $AS$-path and an $SB$-path, so for each such vertex we concatenate the paths to achieve an $AB$-path. In total, we have $k$ of those, thus completing our proof by induction.

The proof is illustated in the following sketch:

TODO sketch of lemma

# Trees

A **forest** is a graph with no cycles (acyclic) (thus it is simple). A **tree** is a connected forest. A **spanning tree** is a spanning subgraph that is also a tree. A **leaf** is a vertex of degree 1. Trees have nice properties which are useful in algorithms, and as we will see every connected graph has a spanning tree, which makes them quite useful in algorithms which use graphs. Below we prove some properties of trees.

Any graph $G$ that satisfies any of these conditions is a tree:
1. $G$ is connected and acyclic.
2. $G$ is connected and any non-leaf is a cut vertex.
3. $G$ is connected and removing any edge disconnects $G$.
4. $\forall u, v \in V(G)$, there exists a unique $(u, v)$-path.
5. $G$ is acyclic and adding an edge to $G$ forms a cycle.
6. $G$ is connected with $n$ vertices and $n-1$ edges.

We will show that $(1)$ implies $(2)$, which implies $(3)$, etc., until finally we show that $(6)$ implies $(1)$, thus completing the chain.

$(1) \to (2)$: Assume not, then let $v \in V(G)$ be a non-leaf, thus we have $\text{deg}(v) \gt 1$, so it has at least 2 distinct neighbors (we assume the graph is simple) $a, b \in V(G) \setminus \{v\}$. Consider $G'=G \setminus \{v\}$, we assume that $v$ is not a cut-vertex thus since $G$ is connected $G'$ is also connected and there exists an $(a, b)$-path $P$ in $G'$ which is also a path in $G$. Since $a, b$ are adjacent to $v$ in $G$, then the sequence of vertices $\{b, v, a \}$ is a path in the simple graph $G$, but then we can concatenate $\{b, v, a \}$ to $P$ and get an $(a, a)$-path, which is a cycle, but $G$ is a tree thus has no cycles, thus $v$ is not a cut-vertex. If $v$ were a leaf, then this "proof" would fail since it only has 1 neighbor.

$(2) \to (3)$: Assume not, then let $e=\{u, v\} \in E(G)$ be an edge such that $G \setminus e$ is connected, then clearly there exists a $u, v$ path that does not pass through $e$, but then we can concatenate $e$ to the path and get a cycle. However, $(2)$ implies that $G$ is acyclic, thus we have a contradiction, thus $G \setminus e$ is disconnected, thus removing any edge disconnects $G$. In fact, in $G$ were a tree, then removing an edge would result in a forest which consists of two trees (since it would introduce no new cycles and split one connected graph into two distinct connected components).

$(3) \to (4)$: Since $G$ is connected, the existence of a path between any pair of vertices is guaranteed, so we shall show that it is unique. Assume not, then there exists $u, v \in V$ such that they have two distinct paths between them $P_{1}$ and $P_{2}$. By concatenating $P_{1}$ and $P_{2}^{-1}$ we get a cycle $C$. Consider an edge $e \in E(C)$. Remove the edge from $G$, and denote the resulting subgraph as $G'$. We wish to prove that $G'$ is connected, thus contradicting $(3)$ which states that removing any edge disconnects $G$, thus proving that a $(u, v)$-path is unique. Let $a, b \in V$, and consider an $(a, b)$-path $P_{ab}$ in $G$. If $P_{ab}$ does not use $e$, then clearly it is also an $(a, b)$-path in $G'$. If it does use $e$, then denote $k_{1}, k_{2}$ the vertices incident with $e$, clearly they are in $C$. Consider the cycle graph $C$, since it is a cycle it is 2-connected and we can find a $k_{1}, k_{2}$ path in $C \setminus \{e \}$, denote it $P_{k_{1}k_{2}}$. Since $P_{k_{1}k_{2}}$ is a path in $C \setminus \{e\}$, it is also a path in $G'$, and we can replace the edge $e$ in $P_{ab}$ with $P_{k_{1}k_{2}}$ and find an $(a, b)$-path in $G'$. In both cases we are able to find a path for any pair of vertices of $G'$, thus $G'$ is connected, and by the argument presented earlier we have a contradiction and thus the $(u, v)$-path is unique.

TODO illustartion of transitivty of connectedness, if uv from a cycle then we can remove any edge and G would still be connected

$(4) \to (5)$: Assume $G$ is cyclic, then for some $v$ there exists a $(v, v)$-path, where we disallow single-vertex paths, then there exists at least one vertex in the path $u \neq v$, such that the cycle is of the form $\{v, \dots, u, \dots, v\}$. Take $\P_{1}=\{v, \dots, u \}$ and $P_{2}=\{u, \dots, v \}$ such that the concatenation of $P_{1}$ and $P_{2}$ results in the cycle. Clearly, $P_{1}$ and $P_{2}$ are part of a path and thus are not equal, thus we have two distinct $(u, v)$-paths, contradicting $(4)$, thus $G$ must by acyclic. Next, consider a new edge $e$ between two vertices $u, v \in V(G)$ and the graph $G + e$. By adding the edge, we add a $(u, v)$-path which was not in $G$, denote it $P_{1}$. However, since by $(4)$ we have a path between every two vertices in $G$, we have a $(u, v)$-path in $G$, denote it $P_{2}$. If we reverse $P_{1}$ we get a $(v, u)$-path, and if we concatenate $P_{2}$ to it we get a $(v, v)$-path, which is a cycle, thus proving $(5)$.

$(5) \to (6)$: First, we show that $G$ is connected. If $G$ is disconnected, then we can take two edges $u, v$ such that there is no $(u, v)$-path in $G$ and connect them by an edge and construct a unique $(u, v)$-path. However, by $(5)$, this should result in a cycle, but if we have a cycle then we can consider the subgraph of the cycle and it should be 2-connected by a previous result, but by Megner's theorem this means we have 2 distinct $(u, v)$ paths, contradicting $G$ being disconnected, so we have $G$ is connected. Next, we show that $|E|=|V|-1$ by induction on the number of vertices. If $G$ has 1 vertex, then it is connected and has no edges (since we disallow loops) thus we have $|E|=|V|-1=0$. Assume the statement holds for $|V|=n-1$ for some $n$, and add a new vertex $v$. Clearly for $G'=G \cup \{v\}$ to be connected we need at least 1 edge that connects to $v$, so we have $|E'| \geq |E| + 1 \geq n-1$. However, adding any other edge forms a cycle by $(5)$, thus we have $|E|=n-1$.

$(6) \to (1)$: For $G$ to be connected, every vertex must have at least be at least of degree 1, otherwise it is not incident with any edge and thus has no path to any other vertex, thus we have $|E| \geq |V|-1$ with $|E|=|V|-1$ being the minimal amount of edges to make $G$ connected. If we remove any edge from the graph then clearly we have $|E'| \lt |V|-1$ which is the minimal amount of edges to make $G$ connected, thus $G$ is disconnected, thus $G$ is not 2-connected, thus $G$ is acyclic by a previous result, thus $G$ satisfies $(1)$.

Every tree $G$ with $|V| \gt 1$ has at least 2 leaves. We can prove this by the handshake lemma, using condition $(6)$: by the handshake lemma, we have that the sum of degrees in the graph is $2|E|=2(n-1)=2n-2$. Clearly if $\lambda G = 2$ then we have that the sum of degree is at least $2n$, which is greater than the actual sum we calculated, thus $\lambda G = 1$. If $G$ has only one leave, then similarly we have a lower bound of $2n-1$. The smallest number of leafs which satisfies this is 2, thus every tree with more than 1 vertex has at least 2 leaves.

Recall the definition of a spanning tree: a spanning tree of $G$ is a subgraph of $G$ that is also a tree. A powerful result related to spanning trees is that *every connected graph has a spanning tree*. We prove this by construction: let $G$ be a connected graph. If $G$ has no cycles, then by definition $G$ is a tree and a spanning subgraph of itself. If $G$ has a cycle, then we remove an edge from the cycle and by a previous result $G$ will remain connected. This can be repeated until the resulting graph is a tree, and since we haven't removed any vertices it is a spanning tree of $G$. Thus every connected graph has a spanning tree.

This result leads to a result which is useful in proofs by induction: let $G=(V, E)$ be a graph, and let $H=(V, \emptyset)$ be the empty graph of $V$. We can construct $G$ from $H$ incrementally by adding edges. Each edge is either going to connect 2 components, or it is going to introduce a cycle (if the connected component is already a spanning tree).

In computer science, most tree data structures represent trees as *rooted trees*. A **rooted tree** is a tree where one vertex has been designated the root. The choice of a root is arbitray (i.e. we can re-root a tree without changing the graph). Let $r$ be the root of the tree, and let $v$ be any other vertex. As we have seen, there exists a unique $(r, v)$-path. Consider a sequence $(a, b)$ of two consecutive vertices in this path. We call $a$ the **parent** of $b$ if it is adjecent to it and appears in an $(r, b)$ path directly before $b$. We call $b$ a **child** of $a$. A **descendant** of $a$ is a vertex $v$ such that $a$ is in $(r, v)$. The **depth** of a vertex $v$ is the length of the unique $(r, v)$-path. The **height** of a rooted tree is the maximum depth of any vertex. We may denote a rooted tree of a tree $T$ rooted at $r$ using set notation, as

$$
T_{r} = (V_{T}, \{v, \text{parent}_{s}(v)\} | \forall v \in V_{T} \setminus \{r\})
$$

A rooted tree provides a notion of direction to an undirected graph - from the root to the leaves, from parents to children. Consider a vertex $v$ in a rooted tree $T_{r}$. By definition it is a member of the vertices sequence of a the path from the root to its descendants, thus it is a cut vertex that splits its descendants from the rest of the tree, thus every vertex of a rooted tree is also the root of a subtree which consists of itself and all its descendants. This is the core idea behind (depth-first search)[https://en.wikipedia.org/wiki/Depth-first_search].

**Theorem**: If a tree $T$ has 3 leaves, then it is a subdivision of the star graph $S_{3}$.

**Proof**: Let $P$ be a maximal path of $T$. Both its ends must not have any neighbor not in the path so they must be of degree 1 (since $T$ is acyclic) so they are leaves. Let $c$ be the third leaf of $T$. Pick a vertex $v$ in $P$. Since $T$ is a tree, then a $(c, v)$-path is guaranteed to exist and be unique. If that path and $P$ are internally disjoint, then the paths from $v$ to the two ends of $P$ and the path to $c$ are all internally disjoint, so we have $v$ with degree 3 connected to three internally disjoint paths with internal degree 2 which can be constructed via a sequence of edge subdivisions. If $(c, v)$ and $P$ are not internally disjoint, then their union must be a subpath of each path, otherwise we would be able to form a cycle. The cycle starts at $v$ since $v$ is a shared vertex of both paths, and ends at another shared vertex $w$, but now $(c, w)$ and $P$ are internally disjoint, so by the same argument $w$ is connected to all leaves via internally disjoint paths so $T$ is a subdivision of $S_{3}$ (with $w$ being the center instead of $v$).

The theorem does not generalize to 4 leaves. Consider the following tree which has 4 leaves, yet is not a subdivision of $S_{4}$ (it has no "central" vertex, i.e. no vertex such that its path to the leaves are internally disjoint)

TODO tree with 4 leaves is not a star counterexample

We can however state a weaker result in the case of a tree with 4 leaves:

**Theorem**: If a tree $T$ has 4 leaves, then it is either a subdivision of $S_{4}$ or a subdivision of the following graph

TODO tree with 4 leaves and no central vertex a -- b -- c; d -- e -- f; c -- e;

**Proof**: We start the same as before by taking a maximal path $P$ and then finding a vertex on that path such that it is connected to 3 leaves of the tree via internally disjoint paths and we denote this vertex $v$. Since $T$ is a tree there must also be a path from $T$ to the fourth leaf of the tree. This path cannot have any internal vertices both in $P$ and in the path from $v$ to the third leaf because then we would have a cycle, so either the path starts at $P$ or the path to the third leaf and then branches off to a new path, or the path does not have any internal vertex in any existing path. In the latter case, identify that we have a central vertex $v$ such that it is connected to all leafs via 4 internally disjoint path so it is a subdivision of $S_{4}$. In the former, w.l.o.g assume that the path starts at $P$ until it branches off. By a similar argument to the 3 leafs case the path must not intersect with $P$ again to avoid a cycle. Denote the last shared vertex of $P$ and the path to the fourth leaf as $w$. Observe that the path $(v, w)$ lies entirely on $P$, so it is a subdivision of the edge $\{v, w\}$. Similarly, observe that each of $v$ and $w$ is connected via a path to two leafs, and that all of these paths are internally disjoint, so these are also subdivisions of edges, so $T$ must be a subdivision of the second graph we described (which has two $P_{3}$ subgraphs whose middle vertices are connected by an edge).

TODO sketch of the proof. use curve since we don't care about vertices.

**Theorem**: If $T$ is a tree and $\Delta T=k$, then $T$ has at least $k$ leaves.

**Proof**: Assume not, then $T$ has $m$ leaves such that $m \lt k$. Take a vertex $v$ with degree $k$. It is connected to each leaf via a unique path. Since $m \lt k$, we have at least 1 edge of $v$ that is not a part of any of the paths, denote the other end of the edge $w$. $w$ is connected to each leaf via a unique path since $T$ is a tree, but now we can take that path and follow the edge through $v$ and then follow along the path from $v$ to that leaf, which is still a path since $\{v, w\}$ was not a part of the path from $v$ to the leaf by our assumption that $m \lt k$, but now we have a cycle, which is a contraction, so $T$ must have at least $k$ leaves.

# Bridges of Konigsberg Revisited

Now that we have accumulated some knowledge on graphs, we can revisit the bridges of konigsberg. Recall the graph representation of the problem (as a drawing):

TODO Konigsberg

Or, in set notation

$$
\begin{gathered}
G = (V, E) \\
V = \{1, 2, 3, 4 \} \\
E = \{\{1, 2\}, \{1, 2 \}, \{3, 2\}, \{3, 2\}, \{1, 4\}, \{2, 4\}, \{3, 4\} \}
\end{gathered}
$$

Note that $E$ is a multiset, thus $G$ is not a simple graph. However, we can convert every graph to a simple graph by the following method: For each set of parallel edges, subdivide all but one, until no parallel edges remain. Here we consider a loop as a pair of parallel edges. The resulting graph $G'$ is a simple graph. In Python, we can construct $G'$ as follows:

```python
def simplify(g: Graph):
    seen = set()
    to_subdivide = []
    for edge in g.edges:
        if edge in seen or edge.is_loop():
            to_subdivide.append(edge)
        else:
            seen.add(edge)
    
    for edge in to_subdivide:
        g.subdivide(edge)
```

TODO konigsberg simple

Let $W'$ be a walk in $G'$, then let $P'$ be a $(u, v)$-walk in $G'$ with $u, v \in V(G)$, then we can map $W'$ to a $(u, v)$-walk in $G$ as follows: let $W'=(V', E')$, and let $W=(V' \cup V(G), \emptyset)$. We build $P$ incrementally by edges, as follows: walk over $V(W')$. Since $W'$ is a walk on a simple graph, each pair of consecutive vertices in $V(W')$ matches an edge in $E(W')$. Let $e$ be a temporary set that is initially the empty set. When we see a vertex $v' \in V(W')$ that is also $\in V(W)$, we add it to $e$, otherwise we ignore it. When $|e|=2$, we add it to $E(W')$ and empty it. This algorithm is equivalent to a smoothing of the subdivision, thus it guarantees to map the subdivided walks to edges in $E(P)$.

```python
def map_walk(g: Graph, w: Graph):
    """
    g is the original graph, and w is a walk subgraph in g' (i.e. g after simplification)
    """
    w_out = Graph(vertices=g.vertices.union(w.vertices), edges=[])
    e = []

    for v in w.vertices:
        if v in g.vertices:
            e.append(v)
        if len(e) == 2:
            w_out.add_edge(e)
            e.clear()

    return w_out
```

The inverse is also true - every $(u, v)$-walk in $G$ can be mapped to a $(u, v)$-walk in $G'$ by replacing edges which were subdivided with the path of length 2 they were subdivided into. Thus, we can solve the problem in $G'$ instead of $G$. Recall that the problem was to walk across every bridge exactly once. In graph theory terms, this is equivalent to finding a trail $t$ such that $E(t)=E(P)$. We call such trail an *Euler walk*. 

# Euler Walk

An *Euler walk* of a graph $G$ is a trail in which every edge of $G$ is used exactly once. A *closed Euler walk*, also called *Eulerian circuit*, is a tour which is also an Euler walk. We can neatly define Euler walks in terms of homomorphisms: recall that a walk is a homomorphism $w: P_{n} \to G$, and a trail as a walk such that $w_{E}$ is injective. An Euler walk is a homomorphism $w: P_{n} \to G$ such that $w_{E}$ is bijective. Similarly, a closed Euler walk is a homomorphism $w: C_{n} \to G$ such that $w_{E}$ is bijective, which is a special case of a tour which has $W_{E}$ injective.

Using the definition of Euler walks in terms of a homomorphism, it is easy to show that Euler walks are a graph invariant. The proof follows the same template we have seen before for properties which can be defined in terms of a homomorphism, so it is left out.

In his original paper, Euler proved the the bridges of Konigsberg do not admit an Euler walk. To prove this, he showed that they do not meet the conditions for the existence of an Euler walk. Euler proved the following theorem:

**Theorem**: If a graph $G$ doesn't have exactly 0 or 2 odd degree vertices, and not all vertices with nonzero degree belong to the same connected component, then it does not admit an Euler walk.

The second part of the theorem is trivial: let $w$ be a walk, thus it can't connect disconnected components, thus the walk is only on a single connected component. Let $G$ be a graph with more than one connected component, and let $w$ be an Euler walk on $G$. By definition of an Euler walk, $w$ uses every edge of $G$, but since $w$ is a walk it only involves edges from one connected component, thus for $w$ to be an Euler walk, $G$ must have all its edges in a single component.

The first part is more involved, but also trivial: let $v$ be a vertex in $V(w)$ such that it is the starting vertex of an Euler walk. If $|V(w)|=1$, then $v$ has degree 0 since $E(G)$ consists of all the edges in $G$, and we have $G$ is the empty graph with 0 vertices of odd degree (we consider degree 0 to be even). If $|V(w)=2|$, then there are two vertices with the same degree which is either even or odd (depending on the number of parallel edges), and again the theorem holds. If $|V(w) \geq 3|$, then consider the internal walk, i.e. the part of the walk without the first and last edge. Clearly, every vertex visited must be entered and exited, and since each entry and exit requires an edge, and since this is an Euler walk, each visit of an internal vertex uses 2 distinct edges incident with it. However, for the boundary vertices, i.e. the first and last vertex, we have that they are only exited (for the starting vertex) or entered (for the ending vertex), thus a visit of a boundary vertex requires 1 edge incident with it. Assume that $v$ has even degree. Since it is the starting vertex, we require 1 edge to move from it to the second vertex, thus we have an odd number of edges remaining that need to be visited for the walk to be Eulerian, so we must also visit it at the end of the walk, thus any other vertex may only be internal to the walk, and since each visit requires 2 edges, all other vertices must also be of even degree, thus we have 0 vertices of odd degrees. If $v$ has odd degree, then the visit at the start of the walk leaves it with an even number of edges that need to be used, thus it may only be used internally, but we still need one vertex to visit at the end of the walk and that visit requires 1 edge, thus we need to have exactly 1 more vertex of odd degree, thus we have 2 vertices of odd degree. Thus, if a graph does not have exactly 0 or 2 odd degree vertices, it does not admit an Euler walk. This also directly proves a corollary:

**Corollary**: If a graph with al edges in one connected component does not have exactly 0 odd degree vertices, it does not admit a closed Euler walk.

The converse is also true, as proven by Hierholzer about 100 years after Euler's paper. Hierholzer provides a constructive proof which describes an algorithm for finding Euler walks, proving that if a graph has exactly 0 or 2 odd degree vertices, it admits an Euler walk, thus we can rephrase the theorem as:

**Theorem**: A graph that has all its edges in a single connected component admits an Euler walk if and only if it has exactly 0 or 2 odd degree vertices. A graph with all its edges in a single connected component admits a closed Euler walk if and only if it has exactly 0 odd degree vertices.

We will provide the algorithm for finding Eulerian circuits first, then expand it to find Euler walks as well. We look at the connected component $G$ and assume that all vertices of $G$ are of even degree. Pick a starting vertex $v$, and maintain a copy of $G$, denoted $G'$. Every time we visit an edge of $G'$, we remove it. Clearly when $E(G')=\emptyset$, we will have an Euler walk. We go for a walk on $G'$. Pick an edge incident with $v$ (one guarantees to exist because we assume $v$ has even degree ad $G$ is connected), and denote the other end of the edge $w$. Advance to $w$, and remove $e$ from $G'$. We now have $\text{deg}_{G'}(w)=\text{deg}_{G}(w)-1$ and $\text{deg}_{G'}(v)=\text{deg}_{G}(v)-1$, so they are both of odd degree. Now, pick an edge (in $G'$!) incident with $w$, and move to the other end of the edge then remove it from $G'$. Now we have $\text{deg}_{G'}(w)=\text{deg}_{G}(w)-2$, so it is even again. We can repeat this until we eventually get back to $v$. It is guaranteed that we will not get stuck because whenever we enter an internal vertex that is not $v$, since the degree of the vetex in the original graph is even and we only use it as an internal vertex, we will have at least one edge to exit it, and since the only vertex we use an odd number of edges of is $v$, we will eventually return to it. When the walk is over, we will have found an Eulerian circuit of a subgraph of $G$, which we can denote by $G \setminus G'$, but it is not guaranteed that we will have visited all edges of $G$, and since we ended up deducing an even number of edges from each vertex in the circuit, the degree of all vertices in $G'$ is still even, so we can repeat the tour starting with another vertex, and again the tour is guaranteed to terminate at the starting vertex by the same argument. Since $G$ is connected, then there must exist an edge of some vertex in $G \setminus G'$ which connects it to a vertex outside of $V(G) \setminus V(G')$ (otherwise $G \setminus G'$ will be a connected component, contradicting that $G$ is connected thus has only one connected component), so we pick such vertex and start a new tour until we get stuck, then concatnate the replace the vertex in the first tour with the second tour, thus sewing together an extended tour. We repeat this process until we $E(G')=\emptyset$. By the arguments provided above, this guarantees to terminate, thus proving the theorem and the correction of the algorithm.

If $G$ has exactly 2 odd degree vertices, then we can introduce a new vertex and connect it to both odd vertices via 2 edges, thus all vertices including the new one will be of even degree, and we can use the algorithm to find an Eulerian circuit in $G \cup (\{w\}, \{\text{edded edges}\})$. Next, to find an Euler walk in $G$, we simply need to remove the added vertex. This preserves the connectedness of the walk, because a circuit is homomorphic to a cycle and thus is 2-connected, so we can remove one vertex and still have a connected graph.

# Drawing a Graph

Next, we wish to rigorously define drawings of a graph. We have already seen quite a few of those, and we have seen how a good drawing of a graph can provide a lot of insight which is not obvious by simply looking at a set representation of a graph. For example, it is easy to determine if a graph is connecteed or not, and if a graph has cycles, simply by looking at a drawing. However, there are many different ways in which a graph can be drawn, some more useful than others. Also, as is often the case in math, drawing may provide false intuition, so we need to be careful when drawing conclusions about a graph from a drawing. It is of interest to us to study the properties of drawings of graphs, what they can teach us about a graph, and how they interact with graph isomorphism. Since in drawings of a graph we don't necessarily care about, for example, whether an edge is straight or not, we need a framework which is less strict than classical geometry. As it turns out, the correct framework for studying drawings of graphs is topology. As a motivating example, consider the following drawings. All of them are drawings of the same graph, yet they are all very different visually:

TODO different drawings of the same graph

In the next section, we will define some basic concepts from topology at a very shallow level, so then apply those concepts on graphs.

## Basic Topology

A **topology** on a set $X$ is a collection of subsets of $X$ which are called **open sets** which satisfy the following properties:
1. The empty set and $X$ itself are open.
2. Any union of open subsets of $X$ is an open subset of $X$.
3. Any finite intersection of open subsets of $X$ is an open subset of $X$.

We call the set of open subsets a $X$ the topology on $X$. A subset of $X$ is a **closed set** if its complement with respect to $X$ is an open set.

A **topological space** is a set whose members are called *points* and a topology. An example of a topological space is the generalized Euclidean space $\mathbb{R}^{n}$, which will be the topological space we use throughout our discussion. In $\mathbb{R}^{n}$, a set $X$ is *open* iff it is a union or finite intersection of open balls, where an open ball is the set of points  $\{x | ||x-c|| \lt r \}$ for some $r \in \mathbb{R}^{n}$ and $\forall c \in \mathbb{R}^{n}, c \gt 0$.

A *function* in a topological space is a mapping $f: X \to Y$ where $X$, $Y$ are sets. A function is *continuous* if the preimage of an open set is open, i.e. if $\forall S \subseteq Y, f^{-1}(S) \subseteq X$ is an open set. Note that this definition is analogous to the definition of continuity in analysis: consider a function $f$, the epsilon-delta definition of continuity is

$$
\forall \epsilon \gt 0, \exists \delta \gt 0, \forall x \in X, |x-c| \lt \delta \implies |f(x)-f(c)| \lt \epsilon
$$

Observe that both the image $f(x)-f(c)$ and the preimage $x-c$ are open balls and thus are open sets.

Below is a collection of classical results on continous functions in a topological space, stated without proof (but one can easily prove these results from first principles in an analogous manner to the proofs of these results presented in analysis courses):
1. The identity function is continuous.
2. A composition of continuous functions is continuous.
3. Constant functions are continous.
4. Linear and affine functions are continous.
5. If $f$ is a continous bijection, then $f^{-1}$ exists and is also a continous bijection.

In topological spaces, we require that morphisms be governed by continous functions, thus the definition of a topological isomorphism between two topological spaces $X$ and $Y$, called a **homeomorphism**, is defined as a pair of continous functions $f: X \to Y$ and $g: Y \to X$ s.t. $g \circ f$ is the identity on $X$ and $f \circ g$ is the identity on $Y$:

$$
X \cong Y \iff \exists f: X \to Y, g: Y \to X \text{ s.t.} f \circ g = \text{id}_{Y}, g \circ f = \text{id}_{X}
$$

As an example, consider the following drawing of a circle inside a square. We can map the circle to the square via a projection by drawing a line from the center of the circle through some point on the circumference of the circle, this line intersects the square at a single point. We can do this for every point in the circle. Similarly, we can construct a function from the square to the circle by connecting a line from any point on the square to the center of the circle and mapping it to the intersection of the line with the circle. This is a *projection*, as we have discussed in detail in the discussion on projective geometry. We state without proof that these functions are inverses of each other and are continous (this is easy to verify - work out the closed-form expression of each function and check that we get the identity functions by composing them, and verify that they are a composition of continous functions and thus continous), thus a square and a circle are homeomorphic in the topological sense.

TODO circle and square with projection

A notorious example of a homeomorphism is that between a donut and a coffee cup, this is due to the existence of continous functions which map a donut to a coffee cup and vice versa.

## Geometric Realization

A **geometric realization** is a mapping of a graph $G$ to a topological space $G \to \mathbb{R}^{n}$, where $|V|=n$. In a geometric realization, vertices are taken to points representing basis vectors and edges are taken to straight lines between the points. For some ordering of $V$, we assign an index for each vertex and denote the vertex with index $i$ as $v_{i}$. Let $b_{i}$ be the $i$-th basis vector of the chosen basis of $\mathbb{R}^{n}$, then we map $v_{i}$ to $b_{i}$, thus the coordinate vector of $v_{i}$ is $\vec{v}$ s.t. $v_{k}= \begin{cases} 0 & k \neq i \\ 1 & k = 1 \end{cases}$, and we map the edges $\{v_{i}, v_{j} \}$ to the set of points that make up the line segments $\overline{b_{i}b_{j}}$ to construct the geometric realization of $G$:

$$
\text{geom}(G) = \underbrace{\big( \bigcup_{i \in [:n]}b_{i} \big)}_{V\text{ as points}} \bigcup \underbrace{\big( \bigcup_{i, j \in E}\overline{b_{i}b_{j}} \big)}_{E \text{ as lines}}
$$

Using a line segmenent parameterization, we can also write

$$
\text{geom}(G) = \bigcup_{i, j \in E} \{tb_{i} + (1-t)b_{j} | t \in [0, 1] \}
$$

A geometric realization exists in a topological space, and it is a graph invariant up to a homeomorphism. To prove this, we need to show that $G \cong H$ implies $\text{geom}(G) \cong \text{geom}(H)$. Let $f: G \to H$ be a homomorphism. If $V(G)$ and $V(H)$ are finite, we can express the image of $f_{V}$ via matrix multiplication using a permutation matrix:

$$
M \in \mathbb{R}^{|V(G)| \times |V(H)|}, M_{ij} = \begin{cases} 1 & f_{V}(v_{i}) = v_{j} \\ 0 & \text{otherwise} \end{cases} \\
$$

Consider a member $x \in \text{geom}(G)$. We have $x=b_{i} + t(b_{j}-b_{i})$ for some $i, j, t \in E$. Consider the function $f^{*}$ on $\text{geom}(G)$, defined as

$$
f^{*}(x) = Mx
$$

$f^{*}$ is linear and thus continous. Expanding on $f^{*}$, we have

$$
Mx = M(tb_{i} + (1-t)b_{j}) = tMb_{i} + (1-t)Mb_{j} = (*)
$$

Clearly $Mb_{i}$ maps a basis vector corresponding to $v_{i}$ in $\text{geom}(G)$ to a basis vector $b'_{i}$ corresponding with $v'_{i}$ in $\text{geom}(H)$, so we have

$$
(*) = tb'_{i}+(1-t)b'_{j} \in \text{geom}(H)
$$

So $f^{*}$ is a map from $\text{geom}(G)$ to $\text{geom}(H)$ which maps every point in the geometric realization of $G$ to a point in the geometric realization of $H$, thus it is a (topological) homomorphism. This is true for any homomorphism $f: G \to H$. We denote this mapping as the geometrical realization of the homomorphism $f$ - $\text{geom}(f)$. A couple of useful facts about $\text{geom}(f)$ are that, if $f$ is the identiy on $G$, we have $M=I$ and $f^{*}(x)=Ix=x$, so we have

$$
\text{geom}(\text{id}_{G}) = \text{id}_{\text{geom}(G)}
$$

Also, given two homomorphisms $f: G \to H$ and $g: H \to G$, we have the image of $f$ represented by some matrix $A_{n \times m}$ and the image of $g$ represented by some matrix $B_{m \times n}$, so the composition of the geometric realizations is given by

$$
\text{geom}(f \circ g) = A(Bx)=(AB)x = \text{geom}(f) \circ \text{geom}(g)
$$

If $G \cong H$, then we have $g \circ f = \text{id}_{G}$ and $f \circ g = \text{id}_{H}$, so we have

$$
\begin{gathered}
\text{geom}(g) \circ \text{geom}(f) = \text{geom}(g \circ f) = \text{geom}(id_{G})=\text{id}_{\text{geom}(G)} \\
\text{geom}(f) \circ \text{geom}(g) = \text{geom}(f \circ g) = \text{geom}(id_{H})=\text{id}_{\text{geom}(H)}
\end{gathered}
$$

Thus we have a homeomorphism $\text{geom}(G) \cong \text{geom}(H)$ via $\text{geom}(f)$ and $\text{geom}(g)$, meaning that the geometric realization is a graph invariant up to a homeomorphism. The inverse, however, is *not* true - $G \cong H$ does not imply $\text{geom}(G) \cong \text{geom}(H)$. As an example, take the path graphs $P_{2}$ and $P_{3}$, which do not have the same number of vertices thus are clearly not isomorphic, however their geometric realizations are homeomorphic - consider $\text{geom}(P_{2})$ which consists of a single line segment $\overline{b_{0}b_{1}}$, we have $\text{geom}(P_{2})=tb_{0}+(1-t)b_{1}$ for $t \in [0, 1]$. Consider the midway point $t=\frac{1}{2}$, and the line segments $\mathcal{l}_{1}: t \in [0, \frac{1}{2}]$ and $\mathcal{l}_{2}: t \in [\frac{1}{2}, 1]$. $\text{geom}(P_{3})$ consists of two lines $\overline{b'_{0}b'_{1}}, \overline{b'_{1}b'_{2}}$. We can construct a bijective linear maps $f_{1}: \mathcal{l}_{1} \to \overline{b'_{0}b'_{1}}$ and  $f_{2}: \mathcal{l}_{2} \to \overline{b'_{1}b'_{2}}$ by mapping the endpoints of the line segments to the endpoints of the line segments in $\text{geom}(P_{3})$, note that this takes the midpoint to $b'_{1}$ and $b_{0} \to b'_{0}$, $b_{1} \to b'_{1}$. Consider the map $f(t) = \begin{cases} f_{1}(2t) & t \in [0, \frac{1}{2}] \\ f_{2}(2t-1) & t \in [\frac{1}{2}, 1] \end{cases}$, clearly $f_{1}(1)=f_{2}(0)$ so $f$ is well-defined in $t=\frac{1}{2}$ and is continous bijective since it consists of piecewise continous bijective functions that are continous in the intersection point, thus $f$ is a homeomorphism, thus $\text{geom}(P_{2}) \cong \text{geom}(P_{3})$ via $f$.

Since the geometric realization of a graph lives in high-dimensional space, it is hard to visualize. We wish to bring it down to a lower dimenisonal space to make it easier to grasp. To do this, we will use a similar method to the one we used to prove that a square and a circle are homeomorphic - we will project the $n$ dimensional realization to lower dimensional space.

## Embeddings

In all the graph drawings we have examined so far, we took the vertices to points and the edges to curves. Now that we have a rigorous notion of a geometric realization of a graph in $|V|$-dimensional space, we can provide a more rigid definition for a drawing of a graph. A **drawing** of $G$ is a continous map $f$ from $\text{geom}(G)$ to $\mathbb{R}^{d}$. A **planar drawing** is a drawing with $d=2$. An **embedding** is an injective drawing, i.e. every point in the geometric realization of $G$ is taken to a single point in the drawing, which means that no two points in $\text{geom}(G)$ are taken to the same point, which means that the drawing has no crossing edges. A **planar embedding** is an embedding with $d=2$. 

Any graph can be embedded in 3-dimensional space by picking a set of $n$ points to serve as the vertices such that no 4 of them are coplanar, and thus no pair of lines through points in the set are coplanar, then using a linear map to map the geometric realization of the vertices to the points. The map is linear so it is continous, and clearly no edges can cross because the edges are taken to line segment between the points which cannot cross due to no 4 points being coplanar. However, not all graphs admit a planar embedding. A graph which admits a planar embedding is called *planar*.

If $f$ is a embedding of $G$, then the image of $f: \text{geom}(G) \to \mathbb{R}^{d}$, denoted $\text{Im}(f)$, is homeomorphic to $\text{geom}(G)$. To prove this, consider $f'$ to be the corestriction of $f$ to $\text{Im}(f)$ (instead of $\mathbb{R}^{d}$), thus $f'$ is surjective. Since $f'$ is a corestriction of an embedding, and an embedding is injective, we have $f'$ injective and surjective, thus it is a bijection. We presented as a fact that if $f$ is bijective and continous, then there exists an inverse function $f^{-1}$ that is also a continous bijection (this is a generalization of the inverse function theorem from analysis), so we have $f \circ f^{-1}=\text{id}_{\text{Im}(f)}$ and $f^{-1} \circ f = \text{id}_{\text{geom}(G)}$, thus $\text{Im}(f) \cong \text{geom}(G)$.

*Corollary*: If $f$ and $g$ are two functions $ \text{geom}(G) \to \mathbb{R}^{d}$ such that $\text{Im}(f)$ and $\text{Im}(g)$ embeddings of $G$ then we have $\text{Im}(f) \cong \text{Im}(g)$. This is because homeomorphism is a transitive property, since the composition of continous bijective functions is also continous.

These two results mean that all topological information about a graph is preserved in all its embeddings. In fact, we have already seen a topological characteristic of a graph - whether it is connected or not, and the amount of connected components it has. All embeddings below are embeddings of the same graph (can you detect which?), meaning they are homeomorphic:

TODO homeomorphic embeddings

## Topological Minors

Recall the definition of a graph subdivision: $H$ is a subdivision of $G$ if $H$ can be constructed by $G$ by a sequence of (0 or more) edge subdivisions. We have seen that $\text{geom}(P_{2}) \cong \text{geom}(P_{3})$, and clearly we can construct $P_{3}$ from $P_{2}$ via an edge subdivision (up to an isomorphism). We wish to study the relation between a homeomorphism and graph subdivision.

Consider a graph $G$ and an edge $e \in G$. Let $H$ be the graph formed by the subdivision of $e$. We define the following map $f: \text{geom}(G) \to \text{geom}(H)$:

$$
f(x) = \begin{cases}
x & x \notin \text{Im}(\text{geom}_{G}(e)) \\
h(x) & x \in \text{Im}(\text{geom}_{G}(e)) 
\end{cases}
$$

with $h: \text{geom}(G) \to \text{geom}(H)$ restricted to $\text{geom}_{G}(e)$ and the codomain restricted to $\text{Im}(\text{geom}_{H}(\{e', e'' \}))$ where $e', e''$ are the edges resulting from the subdivision of $e$, such that $x$ is expressed using a line segment parameterization $x(t)$. We have already constructed such function $h$ when showing that the geometric realizations of $P_{2}$ and $P_{3}$ are homeomorphic, and we have seen that $h$ is continous bijective. Clearly $f$ is bijective thus it is a homeomorphism, thus $H$ is homeomorphic to $G$ under $f$. Let $H$ be a graph subdivision (not necessarily induced by a single subdivision) of $G$. Assume by induction that the $\text{geom}(G) \cong \text{geom}(H)$ holds up to $n$ subdivisions, then subdivide $H$ again to form $H'$. By our argument, we have that the geometric realizations of $H'$ and $H$ and homeomorphic, however we also have that the geometric realizations of $H$ and $G$ are homeomorphic, thus by the transtive property of homeomorphisms, we have that the geometric realizations of $H'$ and $G$ are homeomorphic, proving the following result:

**Theorem**: If $H$ is a graph subdivision of $G$, then $\text{geom}(H) \cong \text{geom}(G)$.

Consider the case where $\text{geom}(G) \cong \text{geom}(H)$, can we say anything about the relation between the graphs in terms of a subdivision?

Consider that the homeomorphism must take line segments (representing edges) to line segments, and points to points, however the orientation of the lines needn't be preserved, which is why we can take two line segements which do not belong to the same line and map them to two line segments which do belong to the same line, and vice versa (this is basically what we did to show that a subdivision of a graph is homeomorphic to the geometric realization of the graph). Consider a vertex of $G$, which under the homomorphism is taken to a point in the geometric realization of $H$, while maintaining incidence relations, note however that it doesn't necessarily go to a geometric realization of a vertex of $H$ - if a point is incident with exactly two line segments, we can take it to a point on a line segment which the two line segments are mapped to, as we did when constructing the homeomorphism $\text{geom}(P_{2}) \to \text{geom}(P_{3})$, thus if $\text{deg}_{G}(v) = 2$ and $\text{geom}_{G}(v)$ is incident with 2 edges not on the same line, it is not guaranteed that $f(\text{geom}_{G}(v))$ is incident with 2 edges not on the same line. However, consider a vertex of any other degree $k$, then since incidence relations are preserved, the point it is mapped to must also be incident with $k$ line segments. If $k=0$, then the homomorphism takes $\text{geom}_{G}(v)$ to a geometric realization of a vertex of $H$ which is also of degree 0 since the only way a point can be incident with 0 line segments is if it is a geometric realization of an isolated vertex in the graph. Similarly, if $k=1$, it must be mapped to an edge of a line segment which is also only possible if $\text{deg}_{H}(v)=\text{deg}_{G}(v)=1$. For $k=2$, we have shown that this is not the case (in non-formal terms, if $k=2$ the vertex can either be mapped to a vertex of degree 2, a set of vertices of degree 2 via a sequence of subdivisions, or to a point along an edge and thus "removed" via a smoothing which is the inverse of a subdivision). If $k \gt 2$, then the only way for it to be incident with more than 2 edges is if it is a realization of a vertex of $H$ incident with $k$ line segments not all co-incident, because otherwise it can't be an end of all those line segments simultanously. This can be proven by the following geometric argument: let $L=\{\mathcal{l_{1}, \dots, l_{k}}\}$ be the set of all line segments that have $p$ as one end in $\text{geom}(G)$. Let $\{\mathcal{l'_{1}, \dots, l'_{k}}\}$ be the images of these lines in $\text{geom}(H)$ under the homeomorphism $f$. Since incidence relations are preserved, $f(p)$ must be an end of all three line segments. Assume that $f(p)$ is not the geometric realization of a vertex of $H$, then it is the geometric realization of an edge $e$ such that $f(p) \in \text{geom}_{H}(e)$, with $f(p)$ not an end of the line segment, however this would mean that $\text{geom}_{H}(e) \notin f(L)$, which means that $f(p)$ is incident with $k+1$ edges, but since $f$ is a homeomorphism $f(p)$ and $p$ should be incident with the same number of lines, thus we have a contradiction, which means that if $k \gt 2$, then the homeomorphism takes $v$ to a realization of a vertex of $H$ with degree $k$. To summarize, we have:

**Theorem**: If $G$ and $H$ are graphs such that $f: \text{geom}(G) \cong \text{geom}(H)$, and $U=\{v \in V(G) | \text{deg}(v) = k, k \neq 2 \}$, then $f$ maps $\text{geom}_{G}(U)$ to a set of points $\text{geom}_{H}(U')$ such that $U' \subseteq V(H)$ are vertices of $H$ such that $\deg_{H}(u' \in U') = \deg_{G}(u \in U)$ for all matching $u, u'$.

**Corollary**: If $G$ and $H$ are graphs such that $f: \text{geom}(G) \cong \text{geom}(H)$, and $v$ is a vertex of degree 2, then $f$ takes the geometric realization of $v$ to the image of a path (possibly empty) of vertices of degree 2.

From these, we draw a stronger conclusion: let $\text{geom}(G) \cong \text{geom}(H)$, then there exists a graph $K$ that is a subdivision of $G$ and $H$ up to an isomorphism.

To prove this, recall the theorem we just presented - for all vertices of $G$ with degree not 2, the homeomorphism between the geometric realizations forces a correspondence to vertices of $H$ with the same degree, and for all vertices of $G$ with degree 2 it forces a correspondence to paths of (internal) vertices of degree 2, such that the vertices at the beginning and the end of the path are corresponding vertices between $G$ and $H$ due to the homeomorphism and to them having degree other than 2, thus we can find such corresponding paths between the graphs by considering the starting and ending vertex. Take $G$ as a starting graph. For each pair of corresponding paths, take the maximum number of vertices, then subdivide the corresponding path in $G$ until it has that number of vertices. The result is a subdivision of $G$. Similarly, starting from $H$, do the same. The result is a subdivision of $H$. But now both subdivisions are isomorphic, proving the theorem.

A graph is a **topological minor** of $H$ if $H$ contains a subgraph isomorphic to a subdivision of $G$, as illustated below

TODO topological minor illustration subdivide then include

Topological minors are a powerful tool in characterizing graphs with certain properties, via the method of forbidden graphs, which is a method of defining a family of graphs by another family of graphs that it must not contain as subgraphs. For example, a forest is defined as an acyclic graph, which is the same as saying that a forest is a graph that does not have a cycle graph as a subgraph. Topological minors are extremely useful in this method since they essentially condense a family of subdivisions into a single "root" graph, so instead of defining a class of graphs by an infinite number of graphs, we can define a class of graphs using a finite number of graphs and their topological minors. For example, we can show that a graph is a forest iff it contains no topological minor of $C_{3}$: any cycle graph $C_{k}$ with $k \geq 3$ is a closed path of vertices with degree 2, thus any cycle $C_{k \gt 3}$ is a subdivision of $C_{3}$ (which is the smallest simple cycle), so it has $C_{3}$ as a topological minor. A graph is cyclic iff it has a subgraph isomorphic to $C_{k}$, but any cycle has $C_{3}$ as a topological minor, so a graph is cyclic iff it has a $C_{3}$ as a topological minor.

# Linear Drawings

When drawing a graph, we map the geometric realization of a graph to $\mathbb{R}^{d}$ via a continous map which takes line segments of the geometric realization to curves in $\mathbb{R}^{d}$. We are often interested in drawing that take line segments of $\text{geom}(G)$ to line segments in $\mathbb{R}^{d}$. Such drawings are called **linear drawings**. This can be achieved via a *linear map* $f: \text{geom}(G) \to R^{d}, f(x)=Mx$ for some $M \in \mathbb{R}^{d \times n}$. If $f$ is injective, then $f$ is a **linear embedding**. $M$ takes every basis vector of $\mathbb{R}^{n}$, which is used as the coordinates of a vertex in $\text{geom}(G)$, to a point in the embedding, so we can write $M$ explictly as a matrix whose columns are the coordinates of the points $p_{0}, p_{1}, \dots, p_{n-1}$ expressed with respect to a basis of $\mathbb{R}^{d}$, this yields $n \times d$ constraints, which means that $M$ is well defined:

$$
M = 
\begin{pmatrix}
\vert & \vert & \vert & \vert \\
[p_{0}] & [p_{1}] & \dots & [p_{n-1}] \\
\vert & \vert & \vert & \vert
\end{pmatrix}
$$

The notion of a linear drawing lets us define geometric objects such as a polygon in topological terms.

A **simple polygon** is the image of a linear *embedding* of a cycle $C_{n}$ on the plane. Let $P: \text{geom}(C_{n}) \to \mathbb{R}^{2}$ be injective, then we define $\text{Im}(P)$ to be the simple polygon. Convince yourself that this is consistent with other definitions of a simple polygon: a simple polygon is a polygon with no crossings or holes. If we think of the polygon as an embedding of a graph, then the edges of the polygon correspond to the edges of a graph, furthermore the edges of the polygon form a cycle, and since the polygon has no holes only one cycle is formed, so it is the drawing of a cycle, and since the edges of a polygon are straight it is a linear drawing, and since the polygon has no edge crossings the drawing is injective so it is an embedding, and since a polygon resides on a plane it is a planar embedding. We will use *simple polygon* and *polygon* interchangeably.

A **polygonal path** is the image of a linear embedding of a path $P_{m}$ on the plane. Let $L: \text{geom}(P_{m}) \to \mathbb{R}^{2}$ be injective, then we define $\text{Im}(L)$ to be a polygonal path. Two points $a, b$ in a topological space are **path-connected** if there exists a polygonal path from $\text{Im}(a)$ to $\text{Im}(b)$ under the embedding, and it is an equivalence relation - if $a, b$ are path-connected then $b, a$ are path connected since travel is allowed in both directions so it is symmetric, $a$ is connected to itself via a path that consists only of the image of $a$ so it is reflexive, and if $a, b$ and $b, c$ are path connected then we can concatenate the paths and get $a, c$ path-connected via a path. We call the equivalence class formed by this equivalence relation *path-connected components*. Observe that a polygonal path corresponds to a path in the graph (since a path is homomorphic to $P_{m}$), and that a path-connected component corresponds to a connected component in the graph.

The [Jordan curve theorem](https://en.wikipedia.org/wiki/Jordan_curve_theorem), which we will use but not prove, states the following: a Jordan curve $C$ is a homeomorphism of the circle in $R^{2}$. Consider $\mathbb{R}^{2} \setminus C$, the theorem states that it consists of exactly two path-connected components, one of which is bounded (called the *interior*) and the other unbounded (called the *exterior*), with $C$ being the boundary of each component. A *boundary* in topology is a set such that any open ball around any point of the boundary is not entirely in the interior or the exterior. Proof of the Jordan curve theorem tend to use the following lemma, which we will also use (sometimes implictly): in a neighborhood of a point that lies on a curve we can always find two paths along the curve on different sides of the curve.

TODO Jordan curve theorem illustration

A **face** of a linear embedding of a graph $G$ is a path-connected component of $R^{2} \setminus \text{Im}(f_{G})$ where $f_{G}$ is a linear embedding of $G$. By the Jordan curve theorem (JCT), every simple polygon divides the plane to two path-connected components, thus every simple polygon divides the plane to two faces - the inner face (which is the image of the [convex combination](https://en.wikipedia.org/wiki/Convex_combination) of the ends of the edges, i.e. the vertices of the polygon, with the edges removed, thus it is bounded) and the outer face, which is unbounded. To illustarte this idea, consider the following embedding of a graph $G=(V(C_{4}), E(C_{4}) \cup \{0, 2 \})$

TODO embedding of C4 with edge from 0 to 2, square with one diagonal

Observe that the embedding consists of two simple polygons with a shared edge and no crossings, so by the Jordan curve theorem we have that the first polygon splits the plane to two faces, the inner face and the outer face, with the second polygon laying entirely on the outer face of the first polygon (in this embedding). Now, again by the JCT on the other polygon, it divides the outer face of the face polygon to an inner and outer face, so in total we have 3 faces, as illustrated below

TODO 3 faces of the embedding

However, we can show a more powerful result here by using the JCT and the fact that this is an embedding: consider $G$ as described. $G$ contains exactly 2 subgraphs of isomorphic $C_{3}$ - $G_{1}$ with vertices $\{0, 1, 2 \}$ and $G_{2}$ with vertices $\{2, 3, 0 \}$. For $\text{Im}(f_{G})$ to be an embedding, $\text{Im}(f_{G_{1}})$ and $\text{Im}(f_{G_{2}})$ must have no edge crossings. Since $\text{Im}(f_{G_{1}})$ is a polygon, it separates $\mathbb{R}^{2}$ to two faces. Let $p$ be a point in the embedding of $G_{2}$. If $p$ is on the boundary of the embedding of $G_{1}$, then it is incident with an edge of $G_{1}$, but since this is an embedding the edges must not cross, so either $p$ is a shared vertex of $G_{1}$ and $G_{2}$ or it belongs to an embedding of a shared edge of $G_{1}$ and $G_{2}$, otherwise it is either on the inner face or the outer face of the embedding of $G_{1}$. Consider two points $p_{1}, p_{2}$ in the embedding of $G_{2}$. Assume that $p_{1}$ and $p_{2}$ are on different faces of $G_{1}$, but since they are points on the polygon they must be path connected, but from the JCT the two faces are disconnected and may only be connected via the boundary, so the path must cross the boundary, but this means that we have a crossing, contradicting the assumption that this is an embedding, so for any two points in the embedding of $G_{1}$ they must be on the same face of the embedding $G_{2}$ or on the polygon (boundary) $G_{2}$, which means that $G_{2}$ lies entirely outside one of the faces of $G_{1}$. Now, by the JCT, the embedding of $G_{2}$ splits the face on which it lies to 2 faces, so it either splits the inner face of $G_{2}$ to 2 faces, or the outer face of $G_{2}$ to 2 faces, but regardless we will always have 3 faces. 

This proof can be generalized to show that in an embedding of a 4 vertex graph that has a subgraph isomorphic to $C_{3}$, the image of any such subgraph under the embedding is a face, so we say that this result is a topological invariant of linear embeddings of the graph - any linear embedding of such graph with have its number of faces equal to the number of $C_{3}$ subgraphs it contains plus 1, if such an embedding exists. A related result can also be proven in the same method - let $G$ be a graph with 4 vertices and a subgraph isomorphic to $C_{3}$, and let $\overline{G}$ be a linear embedding of $G$, then the image of $C_{3}$ under the embedding is a boundary of a face. To prove this, we consider the embedding of the subgraph isomorphic to $C_{3}$ and then use a similar argument to show that for the drawing to be an embedding then the fourth vertex and all edges incident with it must lie at the complement of one of the faces, if they lie at the complement of the outer face then the drawing of $C_{3}$ is a boundary of the outer face and if they lie at the complement of the inner face then $C_{3}$ is the boundary of an inner face.

In fact, a stronger result is true:

**Theorem**: Let $G$ be a graph with $n$ vertices with a cycle subgraph isomorphic to $C_{n-1}$, then for every planar embedding $\phi: \text{geom}(G) \to \mathbb{R}^{2}$, the image of the embedding of the subgraph bounds a face.

Consider the image of the cycle, clearly the embedding is a polygon so by JCT it bounds a face and splits the plane to two path-connected components, the inner face and the outer face. Let $\phi$ be a planar embedding of the graph, then the embedding of the only vertex not in the cycle and all the edges incident with it (which are also not in the cycle) must not cross any of the edges of the polygon, so by the same argument as before the point must lie either in the inner face of the polygon, in which case the polygon is the boundary of the outer face, or on the outer face, in which case the polygon is the boundary of the inner face. In any case, it is the boundary of a face.

## Outerplanarity

A graph is called **outplanar** if there exists a planar embedding of the graph such that all the vertices of the graph lie on the outer face. For example, cycles are outplanar, since they are taken to a single polygon so all the vertices lie on the outer face.

**Theorem**: An acyclic graph is outerplanar.

Let $G$ be acyclic, then $G$ has no cycles, then no planar embedding $\phi$ of $G$ contains a polygon, so every two points in $\mathbb{R}^{2} \setminus \text{Im}{\phi}$ are path-connected, so there is only one path-connected component in embedding, which is the outer face, thus every vertex is embeddded on the outer face, so $G$ is outerplanar.

**Theorem**: $K_{4}$ is not outerplanar.

$K_{4}$ has 4 $C_{3}$ subgraphs (since all vertices are connected so we have $\binom{4}{3}=4$ $C_{3} subgraphs), and each subgraph can be extended to $K_{4}$ by introducing another vertex incident with all vertices of the $C_{3}$ subgraph (via connecting edges). $K_{4}$ has 4 vertices, so by a previous result every $C_{3}$ subgraph is taken to a face with the fourth vertex being either in the interior or the exterior of the face, but this argument is true for every 3 vertices of $C_{3}$, such there does not exist a set of 4 vertices of $C_{3}$ that all lie on the same boundary, so there does not exist an embedding in which all 4 vertices of $C_{3}$ lie on the outer face, thus $K_{4}$ is not outerplanar.

TODO $K_{4}$ planar drawing

**Theorem**: $K_{2, 3}$ is not outerplanar.

A cycle must visit every vertex once except for the first and the last vertex. $K_{2, 3}$ is a complete bipartite graph, so it consists of 2 groups of vertices $U, |U|=2$ and $W, |W|=3$ such that any vertex of $u$ is connected to all vertices in $w$ and only those, and vice versa. A cycle subgraph must begin and end with the same vertex and must not use the same edge twice. Since we need to start and end at the same vertex, and the graph is bipartite, the cycle must be of even length (because every edge we add to the path take us from one vertex set to the other and we wish to begin and and at the same set). Since vetices and edges must be unique, the maximal cycle is that which visits all vertices of the subset that has the smaller cardinality, so in $K_{2, 3}$ a maximal cycle is a subgraph of $C_{4}$. These cycles can start and end at any vertex of the larger subset, so in total we have 3 $C_{4}$ subgraphs (we can, of course, start from the group with smaller cardinality, but these cycles are isomorphic and only differ in the choice of 2 vertices from the larger subset of vertices, which again gives $\binom{3}{2}=3$ such subgraphs), and introducing the last vertex not in $K_{2, 3}$ completes the subgraph to $K_{2, 3}$. By a previous result, we know that each such $C_{4}$ sugraph is taken to a face under any planar embedding of the graph, with the last vertex either inside or outside the face, and this vertex must belong to $W$. However, since $|W|=3$ and there are 3 such subgraphs, each with a unique vertex $w \in W$ s.t. $w$ is not in the subgraph, we have that there does not exist an embedding of $K_{2, 3}$ in which all vertices of $W$ bound the same face by the same argument as before, thus $K_{2, 3}$ is not outerplanar.

TODO $K_{2, 3}$ planar drawing

Outplanarity deals with an embedding and faces, so it is a *topological* property as well as a graph property, so it makes sense to expect that it will be a topologicla invariant. Indeed, if $\text{geom}(G) \cong \text{geom}(H)$ under some homeomorphism $\psi$ and $\phi$ is an outplanar embedding of $G$, we can compose $\psi^{-1}: \text{geom}(H) \to \text{geom}(G)$ and $\phi$ and get $\phi \circ \psi^{-1}: \text{geom}(H) \to \mathbb{R}^{2}$ an embedding that puts all vertices of $H$ on the outer face, so $H$ is outerplanar, meaning outplanarity is a topological invariant. However, recall that if $G$ is a subdivision of $H$ then the geometric realizations of the graphs are homeomorphic, so we have

*Theorem**: If $G$ is a subdivision of $H$ and $G$ is outerplanar, then $H$ is outerplanar.

From this, it immediately follows that if $G$ is a graph that contains a $K_{4}$ or a $K_{2, 3}$ topological minor, then it is not outerplanar (because as we have shown these graphs are not outerplanar and if $G$ contains a them as a topological minor then they are a subdivision of $G$ so $G$ is also not outerplanar), so if $G$ is outplanar then it does not contain a $K_{4}$ or $K_{2, 3}$ topological minor, which begs the question - is the converse also true?

Consider a graph $G$ which does not contain a $K_{4}$ or $K_{2, 3}$ topological minor, we will later prove that this implies that $G$ is planar. Assume $G$ is not outerplanar. Since it is not outerplanr, there exists no planar embedding of $G$ in which all vertices lie on the outer face. Recall that faces are bound by cycles, and since $G$ is not outerplanar by a previous result it is not acyclic and must bound at least 1 inner face. Consider a planar embedding $\phi$ which maximes the number of vertices $U \subset G(V)$ in $G$ s.t. $\phi(U)$ that lie on the outer face, thus we have a subset of $Z \subseteq U$ that is a cycle graph that bounds the inner face. Let $v$ be a vertex in $G(V) \setminus U$ such that $v$ is in the inner face in the embedding. Consider the connectivity between $Z$ and $v$. We have 4 cases, illustrated here and detailed below:

TODO 4 cases outerplanar characteristic

1. $v$ is not connected to $Z$ via any path, but then $v$ belongs to a different connected component $C \subset G(V)$ that lies in the interior of the face bound by $Z$, so we can move $C$ to the outer face and have a new embedding with more vertices on the outer face, contradicting that this is a maximal embedding, so this case is not possible.
2. $v$ is connected to a vertex of $Z$ via a single path, but again this means that $v$ is not connected to any other vertex of $Z$ through the path so no vertex in the path has an edge which connects to any other vertex of $Z$ so we can simply move the path to the outer face, contradicting that this is a maximal embedding, so this case is also not possible.
3. $v$ has two disjoint paths to $Z$, so it is connected to two vertices $u, w \in Z$, but then if $\{u, w \}$ is an edge in the cycle that bounds the face, we can simply move the path to the other side of the face and get an embedding with more vertices on the outer face, but since this is a maximal embedding that can't be the case, so a $u, w$ must not be consecutive, but since they both belong to a cycle they must be connected by two internally disjoint paths, so there must exist two other vertices $a, b$ such that both are members of the two internally disjoint $u, w$ paths. But now we have 5 vertices $v, u, w, a, b$ such that $v, a, b$ are each connected to $u, w$ via a path, and no two vertices of each group is internally connected to another vertex of the same grup via a path that does not contain a vertex from the other group. Consider the subgraph that consists of all these paths: clearly it is a subdivision of $K_{2, 3}$, which contradicts the fact that $G$ does not contain a $K_{4}$ or $K_{2, 3}$ subgraph, so $G$ must be outerplanar.
4. $v$ has three or more disjoint paths to $Z$, so it is connected to at least three vertices $a, b, c \in Z$, but if we consider the subgraph which contains these three paths, clearly it is a subdivision of $K_{4}$ since $a, b, c$ are all connected to each other via paths in the boundary and are also all connected to $v$, which means that $G$ has $K_{4}$ as a topological minor, which is a contradiction, so $G$ must be outerplanar.

Which proves the converse, and in conclusion we have shown that

**Theorem**: A graph $G$ is outerplanar if and only if it does not contain $K_{4}$ or $K_{2, 3}$ as a topological minor.

## Euler Characteristic

In the setting of planar embeddings, we defined the notion of a face. A face arises from a graph under some embedding, and is a topological object. The same graph can be embedded in different ways which give rise to faces whose boundary consists of the embedding of different vertices and edges of the graph. This motivates a discussion about what properties of a face are topological invariant, i.e. preserved under a homeomorphism.

As a warm up, consider the graph $G=(V, E)$ and the value $|V|-|E|$. As we have seen, $|V|$ and $|E|$ are graph invariants, so they are preserved under a graph isomorphism, which means that the value of $|V|-|E|$ is also a graph invariant. Let $G'$ be the result of an edge subdivision of $G$, so we have $|V'|=|V|+1$ and $|E'|=|E|+1$, which gives $|V'|-|E'|=|V|-|E|$, and in general we can show by induction on the number of subdivisions that if $H$ is a graph subdivision of $G$, $|V_{H}|-|E_{H}|=|V_{G}|-|E_{G}|$. Recall that a graph subdivision maintains the topological structure since we have $\text{geom}(H) \cong \text{geom}(G)$, so we can say that $|V|-|E|$ is a topological invariant.

Let's see some examples: let $C_{K}$ be a cycle. Indeed we have $n$ vertices and $n$ edges in a cycle, so we have $|V|-|E|=0$ for all cycles graphs. Let $G$ be a tree, then we have $|V|-|E|=1$ for all trees. In fact, we can prove a stronger result for a tree: A connected graph $G$ is a tree iff $|V_{G}|-|E_{G}|=1$. To prove the converse, consider that $|V_{G}|-|E_{G}|=1$ can be rearranged as $|E_{G}|=|V_{G}|-1$, an by the sixth equivalent condition we presented in the section on trees, this is true if and only if $G$ is a tree (since we also assumed that $G$ is connected).

The key idea here was to observe that subdividing an edge, which is a homeomorphism (to be precise, this is a misuse of the term, since a homeomorphism is defined on a topological space, but we often think of a graph as its geometric realization or as the image of a particular embedding, so it is tempting to misuse notations for bravity when what we mean is clear), and also preserves $|V|-|E|$ since it adds one edge (by adding two and substracting one) and one vertex, so it is a topological invariant. What happens when we split a face? Well, splitting a face is possible by adding an edge that connects two vertices on the boundary of the face, which breaks the face to two faces bound, thus adding 1 face to the embedding and 1 edge to the graph. Let $\phi$ be an embedding of a planar graph (it is important that the graph be planar, otherwise we cannot properly define faces). Consider $e(G, \phi) = |V_{G}|-|E_{G}|+|F_{\phi}|$, where  $|F_{\phi}|$ is the number of faces in the (image of the) embedding. By subdividing a face, we create a new graph $G'$ such that:

$$
e(G', \phi) = |V_{G}|-(|E_{G}|+1)+|F_{\phi}|+1 = |V_{G}|-|E_{G}|+|F_{\phi}| = e(G, \phi)
$$

Which means that $e$ is invariant under face subdivision, but it is still dependent on the embedding $\phi$.

Recall that adding an edge either connects two components, or creates a cycle, which means that if $G$ has $k$ components and we add an edge to construct $G'$, then either $G'$ has $k-1$ components, or it has a new cycle not in $G$. Consider the topological implication of adding an edge: consider the embedding of a graph which has $k$ connected components, then the image of planr embedding has $k$ path-connected components as well. When we add an edge to $G$, the edge is taken to a curve in the embedding, whose ends are two points which are the images of two vertices of the graph under the embedding. Recall the lemma we mentioned without proof when presenting the JCT: in a neighborhood of a point that lies on a curve we can always find two paths along the curve on different sides of the curve. Consider such point on the curve that is the image of the added edge under the embedding. The two sides of the edge are either path-connected, or they are not. If they are path-connected, then the by the JCT both lie on the same face and no new face was introduced. Otherwise, again by the JCT, the curve is part of a boundary between two faces, so it split an existing face and thus introduced a new face. The former is a topological interpretation of an edge that connects two components, and the latter is a topological interpretation of an edge that adds a cycle.

**Theorem**: Let $G$ be a planar graph with $k$ connected components, and let $\phi$ be some planar embedding of $G$, then

$$
e(G ,\phi) = |V_{G}| - |E_{G}| + |F_{\phi, G}| = 1 + k
$$

For every planar embedding $\phi$, which means that $e$ is not dependent on $\phi$ and we can actually view $F$ as a topological property of the graph, and not of a particular planar embedding, and instead write:

$$
e(G) = |V| - |E| + |F| = 1 + k
$$

This result is known as the [Euler characteristic](https://en.wikipedia.org/wiki/Euler_characteristic), or Euler's Formula (in the plane), and is a topological invariant: recall that $|V|-|E|$ is a topological invariant, so if the theorem is true then the Euler characteristic can be expressed as $|V| - |E| = 1 + k - |F|$, and since the lhs is a topological invariant the rhs must also be at topological invariant. Since the theorem shows that the number of faces in a planar graphs depends only on the graph, then it is also a graph property and a graph invariant.

We prove the theorem by induction on $|E(G)|$. When $|E(G)|=0$, we have no cycles so no Jordan curves and so only a single face (the outer face) for any embedding, and we have $|V|$ isolated vertices, each a connected component, so we have $|V|=k$ and in general we have $|V|-|E|+|F|=|V|+1=k+1$. We construct the graph incrementally by adding a single edge each time. For some $|E(G)|=n$, the last edge introduced, denoted $e$, resulted in either:

1. Connecting two components and maintaining the number of faces.
2. Creating a cycle and maintaining the number of components, and adding a face.

As we proved earlier. Denote $G'=G \setminus \{e\}$, by the induction hypothesis $e(G')=k_{G'}+1$. In the first case, we have:
$$
e(G)= |V(G')| - (|E(G')| + 1) + |F_{\phi, G'}| = e(G') - 1 = k_{G'} + 1 - 1 = k_{G'}
$$
And also
$$
k_{G} = k_{G'} - 1 \Rightarrow k_{G'} = k_{G} + 1
$$

So we have:
$$
e(G) = 1 + k_{G}
$$

Which completes the induction. In the second case, we have:

$$
e(G) = |V(G')| - (|E(G')| + 1) + (|F_{\phi, G'}| + 1) = |V(G')| - |E(G')| + |F_{\phi, G'}| = e(G') = 1 + k_{G'} \underset{k_{G'}=k_{G}}{=} 1 + k_{G}
$$

Which completes the induction, so in both cases we show that the theorem is true by induction.

Another common form in which the formula is presented is

$$
n - m + f = 1 + k
$$

Where $n=|V|, m=|E|, f=|F|$. If the graph is connected, then $k=1$, and we have

$$
n - m + f = 2
$$

## Maximal Planar Graphs

Using Euler's characteristic, we can find a tight upper bound on the number of edges and number of faces a planar graph with $|V|=n$ can have. This gives us a simple $O(1)$ test that, when a graph fails it, can tell us that a graph is non-planar.

A **maximal planar graph** is a planar graph such that connecting any two vertices in $G$ not already connected will result in a non-planar graph.

A **triangulation** is an embedding of a planar graph in which every face is bound by 3 edges. This also means that the planar graph is *connected*. For example, the following graph is a triangulation of $K_{4}$

TODO K4 triangulation

**Theorem**: If a planar graph $G$ is maximal then its embedding is a triangulation.

*Proof*: Assume that $G$ is a maximal planar graph with an embedding that is not a triangulation. A face is bound by a cycle, so if the embedding is not a triangulation at least one face has to be bound by at least 4 (images under an embedding of) edges. Consider such simple $n$-gonal face in $\mathbb{R}^{2}$, with $n \gt 3$. For every simple polygon in the plane, a triangulation exists (this is a geometric result which we prove in a different entry discussing the art gallery problem) by means of internal diagonals, which when viewed as a graph are edges that connect two vertices on the boundary of the polygon, but since the embedding is maximal we shouldn't be able to add such edges, which means that everty face is a triangle, which means that the embedding of a maximal planar graph is a triangulation.

If an embedding of a graph is a triangulation, then every face consists of 3 edges, but since every edge is shared by two faces (which can also be the outer face), we have $\frac{2|E|}{3}$ faces for such graph, so a maximal planar graph has $\frac{2m}{3}$ faces, where $m$ is the number of edges of the graph. Now, by the Euler characteristic, we have:

$$
\begin{gathered}
n - m + f \underset{G \text{ is connected}}= 2 \\
n - m + \frac{2m}{3} = 2 \\
3n - m = 6 \\
m = 3n - 6 \\
\end{gathered}
$$

Similarly, if we wish to express $f$ in terms of $n$, we get
$$
\begin{gathered}
n - \frac{3f}{2} + f = 2 \\
2n - f = 4 \\
f = 2n - 4
\end{gathered}
$$

Let $G$ be a planar graph on $n$ vertices, not necessarily maximal, then we can add edges to $G$ to make it the maximal graph on $n$ vertices, which has $3n-6$ edges as we have shown, which means that $G$ must not have more than $3n-6$ edges if it is planar. Similarly, a maximal planar graph has maximal faces, so in total we have

**Theorem**: If $G$ is a planar graph, then

$$
\begin{gathered}
m \leq 3n - 6 \\
f \leq 2n - 4
\end{gathered}
$$

**Corollary**: If $G$ is a planar graph, then it must have a vertex with degree strictly less than 6 (otherwise we have $m \geq 3n$ which contradicts the theorem).

Using this result, we can easily verify that $K_{5}$ is non-planar, which would be more difficult to prove constructively and would require careful use of the JCT.

**Theorem**: $K_{5}$ is non-planar.

**Proof**: $K_{5}$ has 5 vertices and $\binom{5}{2}=10$ edges, but the upper bound on the number of edges a planar graph with 5 vertices is $3 \cdot 5 - 6 = 9$, so $K_{5}$ is non-planar.

We can also talk about the connectivity of a maximal planar graph $G$ with at least 4 vertices: since we know that the image of $G$ under a planar embedding is a triangulation, and we have $f=2n-4$ and $3n-6$ which means that adding a vertex to a maximal planar graph (that has at least 3 vertices) adds 2 faces and 3 edges, so we can build a maximal planar graph on $n$ vertices incrementally by adding vertices and 3 edges connected to other vertices in the graph. Consider the maximal planar graph on 3 vertices, which is a triangle $K_{3}$. Next, we add a vertex while maintaining the maximal property of the graph, which as we have seen means connecting the vertex to 3 existing vertices in the graph, which in this case means connecting it to every vertex of $K_{3}$. Since all vertices of $K_{3}$ are connected to each other, and are also each connected to the newly added vertex, we have that the maximal planar graph on 4 vertices is 3-connected. Assume that this holds for a maximal planar graph with $n-1$ vertices, and add a vertex to get the maximal planar graph on $n$ vertices. It is connected to the rest of the graph via 3 distinct vertices, and since the rest of the graph is 3-connected (by the induction hypothesis), we can remove 2 such vertices and still find a path between the new vertex and every other vertex of the graph, which means that the maximal planar graph on $n$ vertices is (at least) 3-connected by induction, so we have

**Theorem**: If $G$ is a maximal planar graph, and $|V(G)| \gt 3$, then $G$ is 3-connected.

**Corollary**: If $G$ is a planar graph, then it must have at least 4 vertices with degree strictly less than 6.

**Proof**: By the handshake lemma we have that the sum of degrees is $2m$. We also have $m \leq 3n-6$, which means that the sum of degrees cannot be greater than $6n-12$. By the last theorem, we have $G$ is 3-connected so by a previous result we have $\delta G \geq 3$, so the lower bound on the sum of vertices is $3n$. If $G$ has at most 3 vertices with degree 5 or less, then we have a lower bound on the sum of degrees of $6(n-3)+3 \delta 6 \geq 6(n-3) + 3 \cdot 3$, which is $6n-9$, which is greater than the upper bound of $6n-12$, which is a contradiction.

# Planar Graphs

## Well-Connected Planar Graphs

A graph is planar if it has an injective drawing $\phi: \text{geom}(G) \to \mathbb{R}^{2}$. In the last section, we presented a few necessary (but not sufficient) conditions that a graph must meet if it is planar. In planar embeddings, we can discuss the faces of a graph that arise from the image of a planar embedding, and have shown that the number of faces is a topological invariant. We have also seen that a cycle graph is taken to a boundary of a face, and if a graph $G$ has cycle subgraphs such that only one vertex of the graph is not a part of the cycle then the cycle is taken to the boundary of a face, inner or outer, in the image of the embedding. However in the general case, it is not necessarily true that a cycle is taken to the boundary of a face. Consider for example this embedding of a graph on 5 vertices:

TODO NoFaceC3

Clearly $\{1, 2, 3 \}$ form a subgraph of $C_{3}$, and its image is a Jordan curve in $\mathbb{R}^{2}$, but it is not the boundary of a face in the embedding - clearly any point along the image of the embedding of the edge $\{1, 5 \}$ is also not in $\mathbb{R}^{2} \setminus \text{Im}(\phi)$, so the actual boundary of the inner face of the graph is $\{1, 2, 3, 1, 5 \}$, which is a tour but not a cycle since it visits vertex $1$ twice. However, if we were to move the image of $\{1, 5\}$ to the outer face, then the image of this $C_{3}$ subgraph would be the boundary of an inner face.

This is to be expected, since the proper setting to talk about faces is in the image of the embedding, and it depends on the embedding, but as we know from Euler's characteristic it sometimes makes sense to talk about faces in the context of a graph, which motivates us to ask if there exist certain restrictions on a graph that, if a graph satisfies, lets us talk about properties related to the faces of a planar embedding as a graph property.

Let $G$ be a 2-connected graph, and let $\phi$ be a planar embedding of $G$. Consider a face of $G$ in the embedding, and suppose some face is not bounded by an embedding of a cycle. Let $\partial F$ be the boundary of the face. Since $\partial F$ bounds a face, we can walk along it on either side and eventually get to the starting point since the two sides should be path-connected components. As we walk along the boundary, we keep track of every point that is the image of a vertex of the graph. Eventually, we will have reached the starting point. Consider the sequence of vertices we accumulated - if no vertex is repeated, then the boundary is the image of a cycle, contradicting our assumption, so this case is not possible. If the boundary is not the image of a cycle, then it must be the image of a tour, so a vertex must be visited more than once. Consider each subpath that starts and ends with the same vertex recursively until you find such subpath that does not have any such subpaths of its own. We are guaranteed to find one such subpath, because we know that the boundary is connected so eventually the path must connect back to the starting vertex (since we are dealing with finite graphs). This subpath is connected to the rest of the image of the embedding via that vertex, but since it is a closed curve by the JCT is separates the plane to two distinct path-connected components, which means that this vertex is a cut vertex, which means that $G$ is not 2-connected, which is a contradiction. Similarly, if $\phi$ is a planar embedding of a graph $G$ such that every face in $\text{Im}(\phi)$ is bounded by a cycle, then we assume by contradiction that $G$ is not 2-connected, so there exists two sets of vertices $U, W \subset V(G)$ such that $U \cap W = \{v \}$ for a single $v \in V(G)$, which means that the image of the subgraphs imbued by $U, W$ under the embedding meet at $\phi(v)$, but that means that there exists a boundary walk in $\Im(\phi)$ that walks which passes through $v$ twice, which is a contradiction, so $G$ must be 2-connected.

**Theorem**: $G$ is a 2-connected planar graph if and only if for any embedding $\phi$ of $G$, the faces of $\text{Im}(\phi)$ are bound by cycles of $G$.

However, if $G$ is a 2-connected planar graph, it is still not clear *which* cycles of $G$ bound faces of the image of the embedding. Consider the following example of two embeddings of the same graph

TODO two embeddings of same graph with different cycles bounding each face, Well Connected Planar Graphs 15:46

Observe that while $G$ is 2-connected and while all faces of each embedding are bound by cycles of $G$ and $|F|$ is invariant as expected, the cycles that bound each face are not the same, and in fact are not even of the same length. We are interested in determining when a cycle bounds a face.

A subgraph $S \subseteq G$ is **not-separating** if $G \setminus S$ is connected. A cycle subgraph $C \subseteq G$ is an **induced cycle** if $\forall u, v \in C$, $\nexists e = \{u, v \}$ such that $e \in E(G) \land e \notin E(C)$, i.e. no edges between two non-consecutive vertices of the cycle exist in the graph (we call such edges *diagonals* or *chords*, so we may also define an induced cycle as a chordless cycle).

**Theorem**: Let $G$ be 3-connected and planar, and let $\phi$ be an embedding of $G$ such that $\underline{G}=\text{Im}(\phi)$. A cycle $C$ of $G$ bounds a face in $\underline{G}$ if and only if it is a non-separting induced cycle of $G$.

To prove the theorem, we require the following lemmas:

**Lemma 1**: If $G$ is a 3-connected planar graph and a cycle of $G$ bounds a face, then it is an induced cycle.

**Proof**: Assume not, then there exists two non-consecutive vertices $u, v \in V(C)$ such that they are adjacent in $G$, which also means that $|V(C)| \gt 3$ because $C_{3} \cong K_{3}$ which is the complete graph on 3 vertices so no edges can be added without making it not-simple, so there also exists two vertices $a, b \in V(C)$. Consider an $(a, b)$-path in $G$. Since $G$ is 3-connected, by Megner's we can find 3 such paths so by the pigeonhole principle at least one of those paths does not pass through $u$ or $v$, but then we consider the vertices $a, b, u, v$: $u$ and $v$ are adjacent by assumption and the Megner's we have a path from $a$ to $b$ which does not go through $u, v$. Since $C$ is a cycle and $a, b, u, v$ all lie on the cycle we can find w path from $u$ to $a$ which does not pass through $b$ and from $u$ to $b$ which does not pass through $a$, and we can find similar paths for $v$, but that would mean we have $K_{4}$ as a topological minor, and since all vertices bound the same face that would imply that $K_{4}$ is outerplanar, which is a contradiction, so the cycle must be induced. This proof is illustrated below:

TODO show this has K4 as topological minor

**Lemma 2**: If $G$ is a 3-connected planar graph that has a cycle $C$ that bounds a face, then the cycle is non-separating.

**Proof**: Let $u, v$ be two vertices of $G$ not in the cycle. By Megner's theorem, there exist three internally disjoint paths from $u$ to $v$. If one of these paths does not pass through a vertex of the cycle, then $u, v$ are connected in $G \setminus C$. Assume that all 3 paths pass through $C$. Let $a, b, c$ be three distinct vertices in $C$ such that each appears in an internally disjoint $(u, v)$-path $p_{1}, p_{2}, p_{3}$. But now we have each of $a, b, c$ connected via an internally disjoint path to each of $u, v$, so we have a $K_{2, 3}$ topological minor as illustrated below, but then $C$ can't be a face, which is a contradiction.

TODO show this has K2,3 as a topological minor

**Lemma 3**: If $G$ is a 3-connected planar graph that has a cycle $C$ that is non-separating and induced, then it bounds a face in any planar embedding of $G$.

**Proof sketch**: If $C$ is non-separating and induced, then we can find an embedding such that all vertices of $G$ are either inside or ourside of the image of $C$ under the embedding, which means that either the interior of $\phi(C)$ or the exterior of $\phi(C)$ has no points of $\text{Im}(\phi)$, so $C$ bounds a face.

**Proof of the theorem**: Lemma 3 proves the *only if* direction. To prove the *if* direction, let $G$ be 3-connected and planar with a cycle $C$ that bounds a face in a planar embedding of $G$. By Lemma 1, it is an induced cycle. By lemma 2, it is also non-separating, which completes the proof. 

This means that for 3-connected planar graphs, we can identify the edges that bound the faces in the image of the embedding just by detecting induced cycles in the graph, which is a graph property and in fact a graph invariant as we have seen, which lets us think of a face as a graph property and not just as a property of the image of an embedding.

**Theorem**: $K_{3, 3} is non-planar.

**Proof**: First, observe that by removing any two vertices from $K_{3, 3}$ we end up with eiher $K_{1, 3}$ or $K_{2, 2}$, both complete bipartite so they are connected, so $K_{3, 3}$ is 3-connected. Assume $K_{3, 3}$ is planar, then any non-separating and induced cycle of $K_{3, 3}$ bounds a face. $K_{3, 3}$ has 9 such cycles (one for each $K_{2, 2}$ subgraph which is non-separating and isomorphic to $C_{4}$), so $K_{3, 3}$ has 9 faces if it is planar, but by Euler's formula we have an uuper limit of the number of faces $f \leq 2n -4=2 \cdot 6 - 4 = 8$, so $K_{3, 3}$ is non-planar.

## Crossing Number

Recall that a planar graph is a graph which can be drawn in the plane without any (images of) edges crossing, i.e. via an injective drawing. If a graph is non-planar, it is still desirable to consider the minimal number of crossing needed for a planar drawing of the graph, since such drawings are tidier and more pleasing. Consider the following drawing of $K_{5}$:

TODO K5 with one crossing

This is a linear drawing of $K_{5}$ with a single crossing, and as we have proven $K_{5}$ is non-planar, so this is a proof without words that the minimal number of crossings required for a planar drawing of $K_{5}$ is 1. We wish to study this topological property.

To aid in our study, we define a **non-degenerate drawing** as a drawing $\phi: \text{geom}(G) \to \mathbb{R}^{2}$ as a drawing such that:
$$
\begin{gather}
\forall x \in \mathbb{R}^{2}, | \phi^{-1}(x) | \leq 2 \\
\forall x \in \text{Im}(\phi(V(G))), |\phi ^{-1}(x)| = 1 \\
\end{gather}
$$

$(2)$ means that $\phi$ with the restriction to $V(G)$ is injective, and $(1)$ means that no more than 2 points of $\text{geom}(G)$ are mapped to the same point in the drawing. $(1)$ combined with $(2)$ mean that at most 2 edges of $G$ are allowed to cross in under $\phi$, and no crossing on vertices is allowed. Any degenerate drawing can be mapped to a non-degenerate drawing (we will not prove this claim, but you should intuitively be able to believe that this can be achieved by slightly bending the curves the edges are taken to to avoid crossings which violate these conditions, or by slightly moving the edges in case of a linear drawing until no condition is violated).

We define a **crossing** in a non-degenerate drawing as a point $x \in \mathbb{R}^{2}$ such that $|\phi^{-1}(x)|=2$. The **crossing number** of a graph $G$, denoted $cr(G)$, is the minimal number of crossings in a non-degenerate drawing of $G$. We denote it by $\text{cr}(G)$. By defining the crossing number as the minimal number of crossings, we give ourselves the freedom of not having to discuss the crossing number of a particular embedding and so this is a graph property and not a topological property of a particular embedding. For example, the crossing number of a planar graph is $0$.

**Lemma**: If $G \subseteq H$ then $\text{cr}(G) \leq \text{cr}(H)$.

**Proof**: Let $phi: \text{geom}(H) \to \mathbb{R}^{2}$ be the non-degenerate drawing whose number of crossings is $\text{cr}(H)$. Since $G$ is a subgraph of $H$, there exists an injective homomorphism $f: G \to H$, whose geometric realization is given by $\text{geom}(f): \text{geom}(G) \to \text{geom}(H)$ and is also injective (we discussed the geometric realization of a homomorphism in the section on geometric realizations). Consider $\phi \circ \text{geom}(f): \text{geom}(G) \to \mathbb{R}^{2}$, which is a composition of continous functions and thus continous so it is a drawing. Furthermore, we have

$$
\begin{gathered}
|(\phi \circ \text{geom}(f))^{-1}(x)| = |\text{geom}(f)^{-1}(\phi^{-1}(x))| \underset{(*)}{\leq} |\phi^{-1}(x)| \underset{(**)}{\leq} 2 \\\\
(*) \quad \text{geom}(f) \text{ is injective} \\
(**) \quad \phi \text{ is non-degenerate}
\end{gathered}
$$

and

$$
\begin{gathered}
\text{Im}(\phi \circ \text{geom}(f))_{V(G)} = \phi(\text{Im}(\text{geom}(f)_{V(G)})) \underset{(*)}{\subseteq} \text{Im}(\phi)_{V_{H}} \\\\
(*) \quad \text{geom$(f)$ takes geometric realization of vertices of $G$ to vertices of $H$}
\end{gathered}
$$

So $\psi = \phi \circ \text{geom}(f)$ is a non-degenerate drawing of $G$. Let $y$ be a crosing of $\psi$, then we have $\psi^{-1}(y) = 2$, and from the first result we have $\psi^{-1}(y) \leq \phi^{-1}(y)$, so $y$ is also a crossing of $\phi$, so the number of crossings in $\psi$ is less than or equal to the number of crossings in $\phi$, so we have a non-degenerate drawing of $G$ such that it has a less or equal number of crossings to that of the crossing number of $H$, and this number must be greater or equal to the crossing number of $G$ since the crossing number of $G$ is minimal, so we have $\text{cr}(G) \leq \text{cr}(H)$, which completes the proof.

**Corollary**: If $G \subseteq H$ and $G$ is non-planar then $H$ is non-planar. This is because $\text{cr}(G)=0$ iff $G$ is planar, so if $G$ is non-planar $\text{cr}(G) \gt 0$, but we also have $\text{cr}(H) \geq \text{cr}(G)$ so it is also greater than 0 and so $H$ is also non-planar.

**Theorem**: Let $H$ be a graph, then $\text{cr}(H)$ is both a graph invariant and a topological invariant.

**Proof**: First we prove that the crossing number is a graph invariant. Suppose $G \cong H$, then we have an injective homomorphism $f: G \to H$, and by the lemma we have $\text{cr}(G) \leq \text{cr}(H)$, but we also have an injective homomorphism $g: H \to G$ so by the lemma $\text{cr}(H) \leq \text{cr}(G)$, so we have $\text{cr}(G) = \text{cr}(H)$, so $\text{cr}(H)$ is a graph invariant. 

To prove that it is also a topological invariant, suppose we have two graphs $G, H$ such that $\text{geom}(G) \cong \text{geom}(H)$ under an homeomorphism $f$, and w.l.o.g assume that $|V(G)| \geq |V(H)|$. Let $\phi: \text{geom}(G) \to \mathbb{R}^{2}$ be a non-degenerate drawing of $G$ with $\text{cr}(G)$ crossings. Since the geometric realizations are homeomorphic, the drawing is also a drawing of $H$ that maps vertices of $H$ of degree other than 2 to vertices of $G$ by a previous result, and vertices of degree 2 to paths with internal degree 2 of $G$, however since these paths have internal degree 2, they can be drawn as a straight line so in a non-degenerate drawing with minimal crossings they can not be crossed, so all crossings must happen on edges which do not correspond to these paths, but those edges correspond to edges of $H$, so the number of crossings in the drawing of $G$ is the same as the number of crossings in the drawing of $H$, so $\text{cr}(G) = \text{cr}(H)$, so the crossing number is a topological invariant.

**Corollary**: If $H$ is a subdivision of $G$, then $\text{cr}(H) = \text{cr}(G)$. (since by a previous result we have that $H$ is homeomorphic to $G$ and by the last theorem we have that the crossing number is a topological invariant)

**Theorem**: If $H$ has a topological minor of a non-planar graph, then $H$ is non-planar.

**Proof**: Let $G$ be a topological minor of $H$ such that $G$ is non-planar, then $H$ has a subgraph isomorphic to a subdivision of $G$. By the last corollary, we have that the crossing number of all subdivisions of $G$ is the same, and since $G$ is non-planar that crossing number is greater than zero. By a previous result, we have that the crossing number of a subgraph is less than or equal to the crossing number of the graph, so the crossing number of $H$ is also greater than zero, so $H$ is non-planar.

**Corollary**: If $K_{5}$ is a topological minor of $H$, then $H$ is non-planar.

**Corollary 2** If $K_{3, 3}$ is a topological minor of $H$, then $H$ is non-planar.

Both results immediately follow from the theorem and the fact that $K_{5}$ and $K_{3, 3}$ are non-planar.

## Bounds on Crossing Number

Now that we have seen that a crossing number is a graph and a topological invariant, we are interested in finding an upper and lower bound on the number of crossings of a graph. A trivial lower bound is $n^{4}$, where $n$ is the number of vertices.

**Theorem**: Let $G$ be a graph with $n$ vertices, then $\text{cr}(G) \lt n^{4}$.

**Proof**: Let $\phi: \text{geom}(G) \to \mathbb{R}^{2}$ be a linear drawing of $G$ such that no 3 vertices are collinear. The restriction of a such drawing to the vertices of $G$ is injective, and no more than two edges may be incident with a point (since that would mean that there exists three edges $\vec{u}, \vec{v}, \vec[w]$ such that $\alpha u + \beta v + \gamma u = 0$ for nonzero scalars $\alpha, \beta, \gamma$, which means that they share collinear ends, which is a contradiction to the fact that we choose a drawing such that no 3 vertices are collinear), so this is a non-degenerate drawing. Because no more than two edges may cross at a point, the maximal number of crossings is realized when every pair of edges cross exactly once. If $G$ has $m$ edges, then this number is $\binom{m}{2}$, but recall that a complete graph has $\binom{n}{2}$ edges so $m$ must not be greater than that, so we have

$$
\text{cr}(G) \leq \binom{m}{2} = \binom{\binom{n}{2}}{2} = \frac{\binom{n}{2}^{2} - \binom{n}{2}}{2} = \frac{n^{4} - n^{2}}{2} \lt n^{4}
$$

But is this a tight upper bound? In other words, can we find a graph $G$ such that the number of crossings in $G$ really is of order $n^{4}$? To do this, we consider some lower bounds on graphs.

First, we know that if $G$ is non-planar, then $\text{cr}(G) \geq 1$, but can we do better? Recall that the upper limit on edges for a planar graph is $3n-6$ where $n=|V(G)|$, which means that any edge added after the first $3n-6$ edges must introduce at least one crossing, otherwise we can take a maximal graph with $3n-6$ edges and this edge that can be added to the drawing without introducing a crossng and get a planar graph with more than $3n-6$ edges, which is a violation of Euler's formula, so we have:

**Theorem**: Let $G$ be a graph with $n$ vertices and $m$ edges, then $\text{cr}(G) \geq \min(0,m - 3n + 6)$.

If we take a graph $G$ with at least $4n$ edges (assuming $4n \leq \binom{n}{2}$ which is an upper bound on the number of edges in a simple graph), we have $\text{cr}(G) \geq \Omega(n)$, and in the extreme case where we take a complete graph we get $m=\binom{n}{2}$ which is in the order of $n^{2}$ so we have a lower bound in the order of $\Omega(n^{2})$, but this is still very far from an order of $n^{4}$.

To construct a graph such that it has a crossing number of that order, we will use a probabilistic method, which is common in modern graph theory. The proof itself is quite elegant and surprising, and considered a [book proof](https://en.wikipedia.org/wiki/Proofs_from_THE_BOOK).

**Theorem** - **Crossing Number Inequality**: If $G$ is such that $m \gt 4n$ with $m$ being the number of edges and $n$ the number of vertices, then $\text{cr}(G) \geq \frac{m^{3}}{64n^2}$.

**Corollary**: If $m$ is in order of $n^{2}$, then this gives a lower bound of $\frac{O(n^6)}{O(n^2)}=O(n^4)$, which means that the upper bound is tight. 

**Proof**: Consider a graph $G$. We have $\text{cr}(G) \geq \min(0, m -3n + 6)$ so we have $\text{cr}(G) \geq m - 3n$, which we derived from the Euler formula but this is not a tight lower bound. Consider a random subgraph $H$ of $G$ constructed as follows: each vertex of $G$ has an independent probability $p \in (0, 1)$ to be in $H$, and for such subgraph $H$ we define $E(H)$ to be the set of all edges of vertices $v, u \in V(H)$ such that $\{u, v\} \in E(G)$. Since $H$ is also a graph, we have

$$
\text{cr}(H) \geq m_{H} - 3n_{H}
$$

Taking expectations (taking the expected value of each side), we get

$$
\begin{gathered}
\mu (\text{cr}(H)) \geq \mu(m_{H}) - \mu(3n_{H}) \\
\end{gathered}
$$

And now we have $\mu(3n_{H}) = 3 \mu(n_{H})=3np$ (since we have $n$ vertices of $G$ each with a probability of $p$ of being in $V(H)$). Similarly, the probability of an edge of $G$ being in $H$ is the probability that both its ends are in $H$ which is $p^{2}$, and there are $m$ edges, so we have $\mu(m_{H})=p^2 m$, so we have

$$
\mu (\text{cr}(H)) \geq p^{2}m - 3np
$$

Finally, consider a crossing of $G$ under some non-degenerate drawing $\phi$. The crossing is realized by exactly 2 curves under the drawing since it is non-degenerate. Similarly, consider a crossing of $H$ under the same drawing $\phi$. By a previous result, every crossing of $H$ is a crossing of $G$, so the probability that some crossing of $G$ is in $H$ (under $\phi$) is the probability that the crossing curves of the image of the drawing of $G$ are also in the image of the drawing of $H$, which is only possible if both edges are in $H$, so the probability that a crossing of $G$ is in $H$ is $p^{4}$, and there are $\text{cr}(G)$ such crossings, so we have

$$
p^4 \text{cr}(G) \leq \mu (\text{cr}(H)) \geq p^{2}m - 3np \overset{p \gt 0}{\Rightarrow} \text{cr}(G) \geq \frac{p^{2}m - 3np}{p^{4}}
$$

If we set $p=\frac{4n}{m}$, which is less than one for $m \gt 4n$, we get

$$
\text{cr}(G) \geq \frac{m^{3}}{64n^2}
$$

Which completes the proof.

# Fary's Theorem

While we mostly focused on linear drawings and planar embeddings (that is, drawings such that the geometric realization of edges are taken to straight line segments on the plane), and while we are able to find non-degenerate planar linear drawings for every (simple) graph, we haven't considered the question of whether every *planar graph* has a linear planar embedding, i.e. if given a simple planar graph, it can be drawn on the plane so that its edges are drawn as straight line segments. [Fary's theorem](https://en.wikipedia.org/wiki/F%C3%A1ry%27s_theorem) is a result which states just that.

**Fary's theorem**: If $G$ is a simple planar graph, then there exists a linear planar embedding.

To prove this theorem, we will use the following lemma:

**Lemma**: If $G$ is a maximal planar graph, then there exists a linear planar embedding of $G$.

**Proof of Fary's theorem**: Let $G$ be a simple planar graph, then we can add edges to $G$ until it is maximal. Then, by the lemma, there exists a linear planar embdding $\phi$, and the maximal graph has $G$ as a subgraph. Consider $\phi$ restricted to $G$ -it is a linear drawing, and by a previous result the number of crossing in the image of a drawing of a subgraph is not greater than the number of crossings in the image of a drawing of the graph, so the image of $G$ under $\phi$ cannot have more crossings that the image of the maximal graph under $\phi$, but that number if zero, so $\phi$ is also a linear planar embedding of $G$, and its image is simply that of the maximal graph with the images of the added edges removed.

**Proof of the lemma**: $G$ is maximal planar so by a previous result its embedding is a triangulation, or it has less than 3 vertices in which case the proof is trivial. We prove by induction on the number of vertices in $G$. If $n=3$, then $G$ can be embedded as a triangle and we are done. By a previous result, since $G$ is maximal planar then it has at least 4 vertices with degree strictly less than 6, one of which must not be on the unbounded face. Consider such interval vertex $v$. By removing this vertex, we are left with a face $f$ that is bound by a cycle consisting of at most $5$ vertices. We now have a graph $G'$ such that $|V(G')|=|V(G)|-1$, so by the induction hypothesis we can take the embedding to a linear embedding, and now the face $f$ is a polygon with at most 5 vertices. To make this a linear embedding of $G$, we need to reintroduce $v$. $v$ is incident with all the vertices that define $f$, so to maintain the embedding we need to add $v$ and edges from $v$ to the vertices of the polygon such that no edges cross the boundary of the polygon or each other. This can be modeled as an [art gallery problem](https://en.wikipedia.org/wiki/Art_gallery_problem), which we discuss in detail in a different entry. By the art gallery theorem, we need at most $\lfloor \frac{n}{3} \rfloor$ points so that all points of a simple $n$-gon will be visible from these points, where visibility is defined as the existence of a straight line between the points such that the line doesn't cross the boundary of the $n$-gon. Since the polygon has at most 5 vertices, we have $\lfloor \frac{5}{3} \rfloor = 1$, so we only need one such point, so we set it as the image of $v$ under the embedding and draw the edges accordingly, which completes the proof by induction. This process is illustrated below:

TODO sketch fary's theorem from wikipedia or maybe gif?

**Corollary**: Let $G$ be a maximal planar graph, and let $C$ be a cycle which bounds a face of $G$, then there exists a linear planar embedding of $G$ such that the image of $C$ bounds the outer face.

**Proof**: In our proof of the lemma, we can take the face $f$ to be the outer face by induction, without making any other changes to the proof.

Fary's theorem shows that every planar graph has a linear embedding, which means that if we allow for generalized curves in a planar embedding we do not increase the size of the family of graphs that can be embedded in the plane, so moving forward we no longer need to concern ourselves with non-linear planar embeddings.


# Coloring and Duality

TODO

# simplicial Complexes

A graph $G=(V, E)$ is a pair of sets such that every member of $E$ is a pair of members of $V$, so we have $E \subseteq \binom{V}{2}$. Consider a more general structure, such that $E$ is not limited to $\binom{V}{2}$, but rather to the powerset of the vertices $\text{pow}(V)$. Such a structure, with the added condition that it is closed under taking subsets, is an abstract simplicial complex.

An **abstract simplicial complex** consists of a set of vertices $V$ and a set $S \subseteq \text{pow}(V)$, such that $S$ is closed under taking subsets, i.e. if $K$ is a member of a member of $S$ then $K$ is a member of $S$ (for example, if $S=\{\emptyset, \{a, b\}, \{a\}, \{b\}\}$ then consider the member $\{a, b \}$, $S$ must include both $\{a\}$ and $\{b\}$ and indeed this holds for the given $S$), which immediately leads to the fact that $\emptyset$ is a member of $S$ for all complexes. We call the members of $S$ **simplices** (singular: **simplex**), and denote a simplicial complex by $K = (V, S)$. 

The **dimension** of a simplex is one minus its cardinality (i.e. the dimension of a simplex with two members is 1, and the dimension of the empty simplex is defined as negative one). A 0-dimensional simplex is called a *vetex*, 1-dimensional an *edge*, 2-dimensional a *triangle*, 3-dimensional a *tetrahedron*, and so on.

Every graph can b mapped to a simplicial complex such that $V(G)=V(K)$ and $S=\emptyset \cup \{v | v \in V(G) \} \cup E(G)$. Let us check that this is really a simplicial complex: every member of $S$ is a member of the powerset of $V$, and $S$ is also closed under taking subsets - for some $A \in S$, $A$ is either the emptyset, which does not have any subsets, or it is a set of a single member so its only subset are itself and the empty set, both already in $S$, or $A$ is an edge in $G$, but then both its members are in $V(G)$, so all its subsets are also in $S$, which shows that $S$ is closed under subsets. A simplicial complex of a graph has dimension of at most 1. The dimension of a simplicial complex is the maximal dimension of its simplices.

Analogous to graph homomorphism, we are interested in defining maps between two simplicial complexes. Let $K, L$ be simplicial complexes. A **simplicial map** $f: K \to V$ is a pair of functions $f_{V}: V(K) \to V(L)$ and $f_{S}: S(K) \to S(L)$ such that $f_{S}(k) = \{ f_{V}(v) | v \in k \}$ for all $k \in S(K)$. A simplicial map from one graph complex to another graph complex resembles a graph homomorphism, and indeed graph homomorphisms can be expressed as simplicial maps, however simplicial maps can describe operations which cannot be describe via a homomorphism. For example, consider the following graphs $G$

TODO graph G \{ a -- b -- c -- a; \}

and $K$

TODO graph G \{1 -- 2\}

Consider the map $f_{V}: G \to K$ such that $a, b \mapsto 1, c \mapsto 2$. Clearly we cannot define a homomorphism since the edge $\{a, b\}$ is not taken to an edge in $K$. However, consider the representation of $G$ as an abstract simplicial complex:

$$
\text{simp}(G)=\{V(G), \{\emptyset, \{a\}, \{b\}, \{c\}, \{a,b \}, \{b, c \}, \{c, a \}\}\}
$$

Under $f_{V}$, the simplices are taken to

$$
\emptyset, \{1\}, \{1\}, \{2\}, \{1\}, \{1, 2\}, \{1, 2\}
$$

All of which are in $S(\text{simp}(K))$, and we can observe that this set is also closed under subsetting. Simplicial maps of graph complexes let us define functions that take edges to point, such as the simplicial map we just examined. In that sense, they provide a better framework for thinking about edge contractions, which are the operation of mapping an edge of a graph to a vertex. We will discuss contractions in more detail soon.

The **image** of a simplicial map $f: K \to L$ is $\text{Im}(f) = (\text{Im}(f_{V}), \text{Im}(f_{S}))$. In the example provided above, we have

$$
\text{Im}(f) = (\{1, 2 \}, \quad \{\emptyset, \{1\}, \{1\}, \{2\}, \{1\}, \{1, 2\}, \{1, 2\}\})
$$

The image of a simplicial map is itself a subcomplex of the co-domain complex $L$, which also means that its dimensions is less than or equal to the dimension of the co-domain, which means that the image of a graph complex under a simplicial map is a graph complex.

The **preimage** of a simplicial map $f$ is denoted $f^{-1}(\text{Im}(f))$ (where $\text{Im}(f)$ is a subcomplex of the co-domain) and defined as $(f^{-1}_{V}(\text{Im}(f)), f^{-1}_{S}(\text{Im}(f)))$, and it can be verified that the preimage of a subcomplex is a subcomplex of the domain complex. A **minimal preimage** is a minimal subcomplex of the domain $G' \subseteq G$ such that $\text{Im}(f)(G')=\text{Im}(f)$. If $f$ is injective then the minimal preimage of $f$ is the entire complex $G$. 

Given a graph homomorphism $f: G \to H$, we can define its *simplicial map* $\text{simp}(f)$ as a set of function $(f_{V}, f_{S})$, where $f_{V}$ is the map between vertices defined in the homomorphism and $f_{S}$ is a map $f_{S}: S(\text{simp}(G)) \to S(\text{simp}(K)), s_{G} \mapsto s_{K}$ defined as

$$
f_{S}(s_{G}) = \{ f_{V}(v) | v \in s_{G} \}
$$

By definition the image of $f_{S}$ is a set of simplices in $S(\text{simp}(K))$. To show that it is indeed closed under subsetting, consider a member $s_{K}$ (that is not the empty set) of the image and a subset $a \subseteq s_{K}$. Since it is a simplicial complex of graphs, we have $\text{dim}(\text{Im}(f_{S})) = 2$, so $s_{K}$ is either a vertex or an edge. If it a vertex, then it is in $\text{Im}(f_{S})$ as the image of a vertex simplex of $\text{simp}(G)$, and if it is an edge then it must consist of two vertices which are also in the image of all vertex simplices, so it is closed.

Simplicial maps are also nice in how they behave with identity and composition. We define the identity simplicial map as a map $K \to K$ such that $f_{V}=\text{id}_{V}$ and $f_{S}=\text{id}_{S}$. Consider simplicial maps $f: K \to L$ and $g: L \to M$, then we have $g \circ f: K \to M$ such that it is a simplicial map from $K$ to $M$, which is simple to verify. In particular, for simplicial maps induced by a homomorphism, we have

$$
\begin{gathered}
\text{simp}(\text{id}_{G}) = \text{id}_{\text{simp}(G)} \\
\text{simp}(g \circ f) = \text{simp}(g) \circ \text{simp}(f)
\end{gathered}
$$

Two abstract simplicial complexes $K, L$ are **isomorphic** $K \cong L$ if there exist simplicial maps $f: K \to L, g: L \to K$ such that $g \circ f = \text{id}_{K}$ and $f \circ g = \text{id}_{L}$.

## Clique Complex

Let $G$ be a graph. We can define an abstract simplicial complex induced by the graph as we have seen in the last section, but by letting the dimension of simplices be greater than 2 we can define other interesting simplicial complexes that arise from a graph. Consider all cliques (i.e. complete subgraphs) of $G$. Each clique is itself a simplex of dimension $k-1$ with $k$ being the number of vertices in the clique subgraph, so we can define the following structure

$$
\text{clique}(G) = (V_{G}, \{C | C \subseteq G, C \cong K_{n}\})
$$

To show that it is an abstract simplicial complex, we need to verify that $S(\text{clique}(G))$ ($S$ for bravity) is close under subsets. To do that, we first need to verify that $\emptyset \in S$, so we extend our definition of a clique to include the empty clique $K_{0}=\{\emptyset, \emptyset\}$ the graph with no vertices nor edges, which is vacously complete. Every graph has $K_{0}$ as a subgraph, so clearly $K_{0} \in S$. Consider $\sigma \in S$, $\sigma$ is a subset of vertices of $V(G)$ such that the graph induced by them is a clique in $G$, which means that every pair of vertices in $\sigma$ is connected via an edge. Consider $\tau \subseteq \sigma$. As a subset of the vertices of a clique, it must also induce a subgraph isomorphic to a complete graph, but that subgraph is also a subgraph of $G$, so it is also a clique of $G$, so it is in $S$, so $S$ is close under subsets, so $\text{clique}(G)$ is a simplicial complex. We call it the **clique complex** of $G$.

Consider a simplicial map $f: \text{simp}(G) \to \text{simp}(H)$. We claim that the simplicial map

$$
g=(f_{V}, \{f_{V}(x) | x \in \sigma \})
$$

Is a simplicial map $g: \text{clique}(G) \to \text{clique}(H)$. To prove that, we need to show that $\{f_{V}(x) | x \in \sigma \}$ takes a clique complex of $G$ to a clique complex of $H$. Let $\sigma$ be a clique in $G$, then for every two distinct vertices $u, v \in \sigma$, we have $\{u, v\} \in E(G)$. Consider the image of $u, v$ under $g_{V}=f_{V}$: there are two cases, either they get mapped to a set $\{g_{V}(u), g_{V}(v) \} \in S$, which is an edge in $S$ and so corresponds to an edge in $V(H)$, or they get mapped to a vertex, so a clique consisting of $n$ vertices and $\binom{n}{2}$ edges is taken to $n'$ vertices and $\binom{n'}{2}$ edges, which is also a clique, so $g$ takes cliques to cliques, so $g$ is a simplicial map. We can also think of $g$ as the clique complex of the simplicial map $f$, so we may write $\text{clique}(f): \text{clique}(G) \to \text{clique}(H)$.

Clique complex maps interact nicely with identity and composition, and we have $\text{clique}(f \circ g) = \text{clique}(f) \circ \text{clique}(g)$ and $\text{clique}(\text{id}_{G}) = \text{id}_{\text{clique}(G)}$. From this we can also show that if $A, B$ are abstract simplicial complexes such that $A \cong B$, then $\text{clique}(A) \cong \text{clique}(B)$ by taking the clique of the simplicial maps governing the isomorphism.

## Minors

In our introductory to simplicial complexes we have seen an example of a simplicial map that takes one graph complex to another graph complex by contracting an edge of the graph. Contractions are a graph operation we have not yet discussed, and they provide a new way for us to find graphs inside other graphs. Just as subdivisions paved the way for defining topological minors, contractions pave the way for defining minors. As we will see, topological minors are also minors, so minors can be viewed as a generalization of topological minors, and edge smoothing is a special case of an edge contraction.

### Edge Contractions

Consider the following graphs $G$ and $H$:

TODO $G$ such that $H$ is an edge contraction of an edge uv in $G$

Hopefully the drawing makes it appearant that $H$ can be formed from $G$ by collapsing the edge $\{u, v\}$ to a single vertex $w$. This operation is called an **edge contraction**. A more descriptive and accurate definition is that an edge contraction of an edge $\{u, v \}$ removes the edge and the vertices incident with it from the graph, and instead adds edges between the neighbors of $u$ and $v$ to a new vertex $w$. Formally, we define an edge contraction of the edge $\{u, v \} \in E(G)$ ad a graph $G'$ such that

$$
\begin{gathered}
G' = (V(G'), E(G')) \\
V(G') = V(G) \setminus \{u, v \} \cup \{w\} \\
E(G') = E(G) \setminus \{e \in E(G) | u \in e \lor v \in e \} \cup \{\{w, x\} | \{u, x\} \in E(G) \oplus \{v, x\} \in E(G)\} \\
\end{gathered}
$$

Since a contraction takes an edge (or a pair of vertices) to a vertex, both are simplices, it would perhaps be easier to define an edge contraction in terms of simplicial maps between graph complexes. We define a **contraction** as a *surjective* simplicial map $f: G \to H$ (where $G$ and $H$ is an abuse of notation meant to signify that the domain and codomain are compelxes induced by graphs $G$ and $H$) such that for every subgraph $H' \subseteq H$, if $H'$ is connected then its preimage is connected. The image of a contraction of $G$ is a complex of a graph that can be obtained by a sequence of edge contractions of $G$. More concisely: a contraction is a surjective simplicial map where the preimages of connected subgraphs are connected.

Let us sketch a proof to show that this is the case: consider a contraction $f: G \to H$ and a subgraph $H' \subseteq H$ such that $H'$ is connected and $f^{-1}(H')$ is connected, we wish to show that the image of $f$ corresponds to a series of edge contractions. First, we know that $f$ is surjective, so every subset of vertices has a preimage $f_{V}^{-1} \in V(G)$. If $H'$ is connected, then consider a vertex $v \in H'$ such that its preimage consists of more than one vertex. If none exists, then $H$ and $G$ are isomorphic and if we allow a contraction sequence of length zero then $H$ is a contraction and we are done. Otherwise, take the preimage of $H'$ which is connected by assumption, and consider the preimage of $v$. Since $f^{-1}(H')$ is connected, then the preimage of $v$ is also connected. If $|f^{-1}(v)|=2$, then clearly this is a contraction of a single edge. Otherwise, we can realize the image as a sequence of contractions, each can be viewed as its own simplicial map, so the following fact should come as no surprise:

**Fact**: The composition of contractions is a contraction.

**Proof**: Let $f: A \to B$ and $g: B \to C$ be contractions, and consider $g \circ f: A \to C$. Since the composition of simplicial maps is a simplicial maps then it $g \circ f$ is a simplicial map, furthermore it is surjective as the composition of two surjections. Consider a connected subgraph $C' \subseteq C$. Since $g$ is a contraction, $g^{-1}(C')$ is also connected, however since $f$ is a surjection then $g^{-1}(C') \subseteq B = \text{Im}(f)$, so we have $f^{-1}(g^{-1}(C'))$ is also connected since $f$ is a contraction, but this is a composition of $(g \circ f)^{-1}$, so $g \circ f$ is a contraction.

Informally an edge contraction takes an edge to a vertex. We have already seen this operation when discussing an edge subdivision - an edge subdivision takes an edge into a path of length 2. A smoothing takes this path and turns it back to an edge. If we subdivide the edge $uv$ to $uw, wv$, then a smoothing takes $uw, wv$ into $uv$ while removing $w$. Viewed as a contraction, we can also define a smoothing as a contraction of the edge $uw$ into the edge $u$, so we see that a smoothing is realized via an edge contraction, which leads to the following result

**Theorem**: If $G$ is a subdivision of $H$, there exists a contraction $f: G \to H$.

**Proof**: $G$ is realized by a sequence of edge subdivisions, which can be undone by a sequence of edge smoothings, which can be realized via edge contractions, which is a contraction.

More generally, as we have shown graph subdivisions take an edge to a path, and the inverse of that is taking a path to an edge, so $f$ is a contration that takes paths to edges, and only paths, which makes it a special case of the more general notion of a contraction, which does not specify a restriction on an edge or on a sequence.

### Minors

Recall our definition of a topological minor: We say that $H$ is a topological minor of $G$ if a subdivision of $H$ is isomorphic to a subgraph of $G$. Let's revisit this defintion through the lens of contractions: consider the subdivision of $H$, denote it $K$. By the last theorem we have $f: K \to H$ under some contraction map $f$ that takes paths to edges, so another way to define a topological minor is to say that $H$ is a topological minor of $G$ if there exists a contraction $f: K \to H$ limited to paths, such that $H$ is isomorphic to a subgraph of $G$. If we lift the restriction on paths, we can define a new operation, called a **minor**.

A garph $H$ is a **minor** of a graph $G$ if there exists a contraction $f: K \to H$ such that $H$ is isomorphic to a subgraph of $G$. Less formally, $H$ is a minor of $G$ if we can construct (a graph isomorphic to) $H$ from a subgraph of $G$ via a sequence of edge contractions. We denote this relation by $H \preceq_{M} G$. From this definition it is clear that every topological minor is a minor, but not every minor is a topological minor. We denote a topological minor $H$ of $G$ by $H \preceq_{T} G$.

**Theorem**: The property of being a minor is *transitive*, i.e. if $A \preceq_{M} B \preceq_{M} C$ then $A \preceq_{M} C$.

**Proof**: We have $A \preceq_{M} B$ so there exists a contraction $f: B \to A$, similarly we have $B \preceq_{M} C$ so $\exists g: C \to B$. Consider a connected subgraph $B' \subseteq B$, since $g$ is a contraction its preimage $X=g^{-1}(B')$ is complete, and is a subgraph of $C$. Consider the function $g$ restricted to $X$, we have $g_{X}: X \to B'$ which is a contraction. Consider $f: B \to A$, which is also a contraction when restricted to $B'$, so we have that $f_{B'}: B' \to \text{Im}(f(B'))$ is a contraction, but now we can compose these contractions to get a contraction from $X \to \text{Im}(f(B'))$ (surjectivity is guaranteed by the restriction on the domains of the maps) which gives $A \preceq_{M} C$.

Since we define a contraction with sequence length 0 to be a valid contraction, we get that every graph is its own minor, so the minor relation is *reflexive*. Similarly, it is easy to check that it is *anti-symmetric*, and we have just shown that it is *transitive*, so we have $\preceq_{M}$ is a *partial order* on the set of graphs.

### Degree 3 Minors

Let's revisit our definition of a minimal preimage of a simplicial map, in the context of a contraction. We define a minimal preimage as a subcomplex of the domain complex such that its image is the same as the image of the entire complex. IN the context of a contration, this is equivalent to saying that given a contraction $f: G \to H$, a minimal preimage is a subgraph $G' \subseteq G$ such that it is the minimal subgraph of $G$ such that $f$ restricted to $G'$ is a contraction.

**Lemma 1**: The minimal preimage of a vertex under a contraction is a tree.

**Proof**: Consider a $v$ vetex in $H$. Since $f$ is a contraction then $v$ is in the image of $f$ so its preimage $f^{-1}(v)$ is a subgraph of $G$. Recall that $f$ is a contraction, so the preimage of $v$ is a connected subgraph of $G$ (because $f$ is a contraction), denote it $G'$. If $G'$ is acyclic, then $G'$ is a tree. If $G'$ is not acyclic, then consider a spanning tree of $G'$ (which exists since $G'$ is connected), denote it $T$. Sine $T \subseteq G'$ and $G'$ is taken to a single vertex under $f$, then $T$ is also taken to a single vertex, so it is also a preimage of $v$. If we were to remove an edge from $T$ then it would no longer be connected, so $f_{T}$ is not a contraction, so $T$ is a minimal preimage.

**Lemma 2**: The minimal preimage of an edge under a contraction is a (single) edge.

**Proof**: An edge in the image of a contraction can only appear if it corresponds to at least one edge in the original graph, because contactions do not introduce new edges. However, it can be that two edges are collapsed to the same edge via a sequence of contractions. In that case, we take only one of those edges, which is a minimal preimage.

**Theorem**: The minimal preimage of a connected contraction is a tree.

**Proof**: By lemma 1, the minimal preimage of a vertex is a tree, and by lemma 2, the minimal preimage of an edge is an edge. The images of two vertices must be disconnected, otherwise we would have a subgraph of a tree mapped to two distinct vertices and then the map would not be well defined, so the minimal preimage of a contraction must be a forest with the preimages of edges connecting trees which are the preimages of vertices, and if $G$ is connected then its preimage is connected since $f$ is a contraction so the preimage must be a tree.

**Theorem**: Let $G$ be a connected graph with maximum degree 3, and let $H$ be a graph. If $G \preceq_{M} H$, then $G \preceq_{T} H$.

**Proof**: Since $G \preceq_{M} H$, there exists a contraction $f: H \to G$. The minimal preimage of each vertex is a tree, and the minimal preimage of the contraction can be viewed as a tree whoes vertices are also trees, connected via edges such that the correspondence to $E(G)$ is injective. Each vertex of $v$ has at most 3 edges so it is homeomorphic to $S_{3}$ and the preimage of its neighborhood has a subgraph which is a tree with at most 3 leaves which is a subdivision of $S_{3}$ by a previous result (and if it has less than 3 leaves then it is simply a path which easily maps to a subdivision), and if we take the preimage of all the neighborhoods of all the edges we would get a subdivision of $G$, so we have $G \preceq_{T} H$.

**Corollary**: If $K_{3, 3} \preceq_{M} G$, then $G$ is non-planar.

**Proof**: By the theorem, we also have $K_{3, 3} \preceq_{T} G$, and by a previous result this means that $G$ is non-planar.

Using the results and methods discussed in this section, we can prove the following result:

**Theorem**: Let $G$ be a graph. If $K_{5} \preceq_{M} G$, then either $K_{5} \preceq_{T} G$ or $K_{3, 3} \preceq_{T} G$.

**Proof**: We have $f: G \to K_{5}$ such that the minimal preimage is a tree whose nodes are trees corresponding to vertices in $K_{5}$ and edges have a one-to-one correspondence to edges in $K_{5}$. All vertices of $K_{5}$ have degree 4, so the minimal preimage corresponding to the neighborhood of each vertex is a tree with 4 leaves, which by a previous result is either a subdivision of $S_{4}$ or a subdivision of the graph $H$ which consists of two $P_{3}$ subgraphs connected by an edge between their vertices of degree 2. In the former case (where every neighborhood is a subdivision of $S_{4}$), by a similar argument to the one presented in the proof of the last theorem that $K_{5} \preceq_{T} G$. In the latter, some vertex must have 2 degree 3 neighbors in its preimage (convince yourself that this is the case by examining the general shape of he neighborhood of $v$ in the latter case), denote the neighbors of this vertex $u, w$ and assign $w$ the color blue and $u$ the color red. Each of the two remaining edges of each vertex belongs to a path to a neighbor of each vertex in $K_{5}$. Color the two ends which are realized by following the edges from $w$ with red and the two ends realized by followign $u$ with blue. Identify that this is a 2-coloring so it is a subdivision of a complete bipartite graph with 3 vertices in each group, so we have $K_{3, 3} \preceq_{T} G$. The sketch below illustrates the part of the proof regarding a $K_{3, 3}$ topological minor.

TODO proof sketch for K3,3 subgraph

**Corollary**: $K_{5} \preceq_{M} G$ or $K_{3, 3} \preceq_{M}$ if and only if $K_{5} \preceq_{T} G$ or $K_{3, 3} \preceq_{T} G$.

**Proof**: the only if direction is easy, since we have seen that $H \preceq_{T} G$ implies $H \preceq_{M} G$. For the if direction, if $K_{5}\preceq_{M}G$ then by the last result the corollary holds. If $K_{3, 3} \preceq_{M}$ then by a previous result we have $K_{3, 3} \preceq_{T} G$ and again the corollary holds, completing the proof.

## Connectivity and Contractions

In this section we will see some interesting relations between well-connected graphs and contractions which will help us prove an important theorem about planar graphs soon.

**Theorem**: If $G$ is a (1-)connected graph with at least 2 vertices, then for any edge contraction the resulting graph is still connected.

**Proof**: Let $u, v$ be two vertices of $G'$ which results from the contraction $f: G \to G'$ of some edge $e$. Since it is a contraction the preimage of $u, v$ is not empty (since it is a surjective map). Take one of the vertices of each preimage $u' \in f^{-1}_{V}(u), v' \in f^{-1}_{V}(v)$. Since $G$ is connected, there exists a $(u', v')$-walk in $G$, which is a homomorphism $w: P_{K} \to G$. The homomorphism can be realized as a simplicial map $\text{simp}(w)$. Consider $f \circ \text{simp}(w)$, it is a $(u, v)$-walk in $G'$, which completes the proof.

**Theorem**: If $G$ is 2-connected and $|V(G)| \geq 4$, then $\exists e \in E(G)$ such that the contraction of $e$ given by the map $f: G \to G'$ results in a graph $G'$ that is also 2-connected.

**Proof**: Suppose not, then $\forall e \in E(G)$ the graph $G'$ resulting from the contraction of $e$ is not 2-connected, so by Menger's it has a separating set of 1 vertex. Let $e=\{u, v\}$ for $u, v \in V(G)$. Since we contracted $e$, then the vertex $w$ formed by the contraction must be a cut vertex (otherwise $G$ would not be 2-connected), so it must separate $G'$ to two disconnected subgraphs $A$ and $B$ such that $A \cup B = \emptyset$ (this is the same as taking $G$ and deleting $u$ and $v$ and all edges incident with either vertex). Since by our assumption doing this for any edge will result in two disconnected subgraphs, we choose an edge $e$ such that it maximizes the size of the larger component, w.l.o.g let $A$ be that component. Since $w$ is a cut vertex, $S=\{u, v\}$ is a separating set of $G$ so by Megner's we must have 2 internally-disjoint paths between $A$ and $B$ that pass through $S$, each passing through a different vertex of $S$. This means that $u$ must have a neighbor not in $A$, call it $b$. But then we can take $A \cup \{v \}$, and consider the graph $G \setminus \{u, b\}$, which must also be disconnected by a similar argument (since it the result of contracting $\{u, b \}$ then deleting the resulting vertex which must be a cut vertex if our assumption is currect). $A \cup \{v \}$ is a connected component of this graph, but it is strictly larger than $A$, which is a contradiction to $A$ being maximal, so our assumption that the theorem is false is incorrect.

The last result can be generalized, although we will not present the argument here since it is very similar to the last one, for 3-connected graphs:

**Theorem**: If $G$ be 3-connected with $|V(G) \geq 5$, then $\exists e \in E(G)$ such that the contraction of $e$ results in a 3-connected graph.

We use the last result to prove a useful result on planarity:

**Theorem**: If $G$ is 3-connected and has no $K_{3, 3}$ or $K_{5}$ minor, then it is planar.

**Proof (incomplete)**: Prove by induction on $|V(G)|$. For $G$ to be 3-connected and simple we must have $|V(G)| \geq 5$, so the base case is $|V(G)|=5$. Since in this case we have only 5 vertices, we cannot have a $K_{3, 3}$ minor and the only way to have a $K_{5}$ minor is if $G$ is itself $K_{5}$, so the base case holds. For $|V(G) \gt 5$, by the last theorem there exists an edge $e=\{u, v\}$ such that the contraction of the edge results in another 3-connected graph $G'$, which has less that $|V(G)|$ vertices. If $G$ does not have a $K_{3, 3}$ or $K_{5}$ minor then so does $G'$ so by induction $G'$ is planar. From here we consider a linear planar embedding of $G \setminus \{u, v \}$ and attempt to use that embedding to reintroduce $u, v$ into the graph to get a planar embedding of $G$ by considering the face $u, v$ used to lie inside and attempting to fit $u, v$ inside the face without crossings. All neighbors of $u, v$ must be on the boundary of the face. If $u, v$ have more than 2 neighbors in common then we can find a $K_{5}$ minor in $G$, which we assumed to not exist. Let $a$ be a neighbor of $u$ (both $u$ and $v$ are guaranteed to have a neighbor since the graph is 3-connected). Walk along the boundary of the face in an arbitrary direction until we reach back to $u$. As we walk along the boundary, we take note of vertices that are neighbors of $u$ or $v$. If the last vertex we took note of does is not a neighbor of the same vertex (i.e. one is a neighbor of $u$ and the other is a neighbor of $v$ disregarding the order), we say that $u$ and $v$ *alternate* on that vertex. If $u$ and $v$ alternate more than twice, then we claim without proof that we can find a $K_{3, 3}$ minor, which is forbidden by our assumption. So we have that $u, v$ must have at most 2 common neighbors and cannot alternative more than twice, so we can form a linear planar embedding of $G$ from the existing embedding via a triangle fan, as shown in the sketch

TODO sketch of fanning

### Minimal Non-Planar Graphs

We say that $G$ is a **minimal non-planar graph** if every minor of $G$ is planar. We will now show that every minimal non-planar graph is 3-connected.

**Theorem**: Minimal non-planar graphs are 3-connected.

**Proof**: Let $G$ be minimal non-planar. Suppose $G$ is not 3-connected, so it is either disconnected, connected or 2-connected. We will show that in each case we can find a planar embedding of $G$ using the fact that its minors are connected, which would prove the theorem. 

Case 1: If $G$ is disconnected, then consider its connected components - each connected component is a subgraph of $G$ so it is also a minor of $G$ so it is planar since $G$ is minimal non-planar, but then we can take the embedding of each connected component and put them together to get an embedding of $G$, so $G$ is planar, so this case is impossible.

Case 2: If $G$ is connected, then it has at least one cut vertx $v$ which separates $G$ into to connected components $A$ and $B$. Consider $A'=A \cup \{v\}$ and $B'=B \cup \{v\}$. Both are minors of $G$ that are not equal to $G$ so they are planar so by Fary's theorem we have an embedding such that $v$ is on the outer face, but now we can take the two images of the embeddings and put them side by side such that they touch only at $v$ (which is possible since $v$ is a vertex on the outer face of each image), and this is an embedding of $G$, in contradition to $G$ being non-planar.

Case 3: If $G$ is 2-connected, then consider a separating set $u, v$, which must be connected via an edge $\{u, v\}$ otherwise it is non-separating. By the same argument as before, we can take two connected minors $A \cup \{u, v \}$ and $B \cup \{u, v \}$ and by Fary's embed them linearly such that $\{u, v \}$ is an edge which bounds the outer face, and then we can put the two images side by side such that they touch only at $\{u, v \}$, which is an embedding of $G$, in contradiction to $G$ being non-planar.

Since all 3 cases lead to contradictions, we conclude that non-planar graphs are 3-connected.

## Kuratowski-Wagner Theorem

[Kuratowski's theorem](https://en.wikipedia.org/wiki/Kuratowski%27s_theorem) and [Wagner's theorem](https://en.wikipedia.org/wiki/Wagner%27s_theorem) are theorems that characterize planar graphs in terms of forbidden minors/subdivisions.

**Kuratowski's theorem**: $G$ is planar if and only if it does not have $K_{5}$ or $K_{3, 3}$ as topological minors.

**Wagner's theorem**: $G$ is planar if and only if it does not have $K_{5}$ or $K_{3, 3}$ as minors.

**Corollary**: Kuratowski's theorem and Wagner's theorem are equivalent.

**Proof of the corollary**: Recall that we have seen that a graph has $K_{5}$ or $K_{3, 3}$ as topological minors if and only if it has either as a minor, so Wagner's theorem is true if and only if Kuratowski's theorem is true, so they are equivalent.

**Proof of Wagner's theorem**: To prove the only if direction, we recall that we have already proven the inverse - if $G$ has $K_{5}$ or $K_{3, 3}$, then $G$ is non-planar (we have proven each part of the statement separately), which proves this direction. For the if direction, again recall that we have already proven this statement, so we have in fact already proven the theorem.

Proof for Kuratowski's follows from the equivalance shown in the corollary.

# Algebraic Graph Theory

So far we have discussed graphs either as a topological object (when dealing with geometric realizations), geometric object (when dealing with linear embeddings), or combinatorial object (when dealing with a graph as a pair of finite sets of vertices and edges where the edges are themselves sets of pairs of vertices). We have also discussed simplicial complexes which we have also examined through all these lenses to realize operations such an edge contractions, which provided a nice setting for the discussion of minors. In this section, we will consider graphs as algebraic objects, and we will see how vector spaces and linear maps can be used to study graphs and their drawings.

## Vector Space of a Set

Consider the [minimal finite field](https://en.wikipedia.org/wiki/GF(2)) $\text{GF}(2)$, whose members can be identified as $0$ and $1$. In this field, addition behaves as a logical XOR (e.g. $0+1=1$ but $1+1=0$), or equivalently as addition modulo 2, and multiplication behaves as a logical AND (e.g. $0\times1=0$ but $1 \times 1 = 1$), which again can be identified with multiplication modulo 2. This field can also be identified with the possible value of a bit in computing and boolean algebra.

Let $S$ be a set. Consider the powerset of $S$, $P_{S}$. Consider the algebraic structure $V_{S}=(P_{S}, \text{GF}(2), \oplus)$. If we take the members of $P_{S}$ to be vectors, members of $\text{GF}(2)$ to be scalars, and $\oplus$ (the symmetric difference) to be the addition operation, then we can see (by checking that this structure satisfies the axioms of a vector space) that $V_{S}$ is a vector space with $\emptyset$ being the zero vector. Since addition in this vector space is the symmetric difference, we can construct every vector of $V_{S}$ by taking the linear combination of singletons of $P_{S}$ (i.e. member of $P_{S}$ that have only 1 member, which are in one-to-one correspondence to members of $S$) with scalars $\lambda_{i}$ such that

$$
\forall v \in V_{S}, v = \bigoplus_{s \in S} \lambda_{s} \{s\}, \lambda_{s} = \begin{cases} 1 & s \in v \\ 0 & \text{otherwise} \end{cases}
$$

So the set of singletons spans $V_{S}$, and it is also a mininal spanning set (we can show this by removing a singleton and checking that the remaining set has no linear combination which results in that singleton), so the set of singletons is a basis (and in fact we take it as the standard basis) of $V_{S}$ and $\text{dim}(V_{S})=|S|$.

Consider $v \in V_{S}$, and the standard basis $b$, then the coordinate vector $[v]_{b}$ is an $|S|$-dimensional vector whose $i$-th entry is 1 if the member of $S$ corresponding to the singleton $b_{i}$ is also a member of $v$, and 0 otherwise. This coordinate vector is a vector in $\text{GF}(2)^{|S|}$.

Since a graph is a pair of sets, we naturally have two vector spaces associated with the graph.

## Edge and Vertex Space

Consider the graph $G=(V, E)$. The **vertex space** of $G$ is given by $\mathcal{V}=(V, \text{GF}(2), \oplus)$, and the **edge space** of $G$ is given by $\mathcal{E}=(E, \text{GF}(2), \oplus)$. Since $E$ and $V$ are closely related, we would like to construct meaningful maps between the vector spaces. One such map is a *cut*.

## Cut Space

Combinatorically, a **cut** (more specifically, an edge cut) of a subset of vertices $U \subseteq V$ is the subset of edges in $E$ such that they are incident with exactly one point in $U$

$$
\text{cut}{U} = \{e \in E | |e \cap U| = 1\}
$$

A cut is an operation on a subset of vertices that results in a subset of vertices, so it is a map $\text{cut}: P_{V} \to P_{E}$. Combinatorically if we take a cut and remove the edges in it from $G$, we get two separated subgraphs $G_{1}, G_{2}$ such that $V(G_{1})=U$ and $V(G_{2})=\overline{U}$.

**Theorem**: A cut is a linear map $\text{cut}: \mathcal{V} \to \mathcal{E}$.

**Proof**: We already have $\text{cut}: P_{v} \to P_{E}$ so we to prove that it's a linear map from $\mathcal{V}$ to $\mathcal{E}$ we only need to show that the map is linear. To do this, take an ordering of $V(G)$ and $E(G)$ such that $v_{i}$ corresponds to the i-th standard basis vector of $\mathcal{V}$ and $e_{i}$ corresponds to the $i$-th standard basis vector of $\mathcal{E}$, so $U$ can be expressed via some coordinate vector $[U]_{b}$. To show that a cut is a linear map, we need to find a matrix $M$ such that $\text{cut}(U)=MU$. Consider the combinatorical meaning of a cut - an edge belongs to the cut if and only if it is incident with exactly one vertex in $U$. Since an edge is a pair of vertices from $V$, then it is also a member of the powerset of $V$ so we can identify edges with vectors of the vector space. Consider an $m \times n$ ($n$ rows and $m$ columns) matrix $B$ such that its columns vectors (which have size $n$) are the coordinate vectors of the vectors in $\mathcal{V}$ associated with $e_{i}$ such that the $i$-th column vector corresponds to $e_{i}$. We call this matrix the **incidence matrix** and denote it $B$.

As an example, consider the graph $P_{4}$, with the following ordering of vertices and edges:

$$
\begin{gathered}
V = \{0, 1, 2, 3 \} \\
E = \{ \{0, 1\}, \{1, 2\}, \{2, 3 \} \}
\end{gathered}
$$

Then we have:

$$
B = 
\left(
\begin{array}{ccc}
\vert & \vert & \vert \\
[e_{0}] & [e_{1}] & [e_{2}] \\
\vert & \vert & \vert
\end{array}\right)=
\begin{pmatrix}
1 & 0 & 0 \\
1 & 1 & 0 \\
0 & 1 & 1 \\
0 & 0 & 1
\end{pmatrix}
$$

Now consider the function

$$
f(U) = B^{T}U
$$

Since this is matrix multiplication of matrices with dimensions $m \times n$ and $n \times 1$ with symmetric differene as vector addition and $\text{GF}(2)$ scalars, the result of this vector multiplication would be an $m$ dimensional vector in $\mathcal{E}$ such that

$$
f(U)_{i} = \begin{cases} 1 & \text{col}(B, i) \cdot U = 1 \\ 0 & \text{otherwise} \end{cases}
$$

Where $\cdot$ means the inner product, but this is true only if the $i$-th column of $B$ has only one $k$ for which $\text{col}(B, i)_{k}=U_{k}$ (since the scalars are from $\text{GF}(2)$), which corresponds to our combinatorical definition of a cut, which completes the proof.

**Corollary**: Edge cut is distributive over symmetric difference, i.e. given a graph $G$ and subsets of vertices $A, B \subseteq V(G)$, $\text{cut}(A \oplus B) = \text{cut}(A) \oplus \text{cut}(B)$.

**Proof**: $A \oplus B$ corresponds to vector addition in $\mathcal{V}$, and since $\text{cut}$ is a linear map we have $\text{cut}(u+v)=\text{cut}(u)+\text{cut}(v)$.

**Corollary**: Consider $f(e)=Be$ for $e \in \mathcal{E}$, then it is a linear map $f: \mathcal{E} \to \mathcal{V}$.

**Proof sketch**: Intuitively this is true since we constructed $B$ by thinking of what the image of an edge would look like and since the edges correspond to singletons which are the standard basis of $\mathcal{E}$, we can rewrite a vector $e \in \mathcal{E}$ as a linear combination of basis vectors and since $B$ takes a basis vector to its corresponding vector in $\mathcal{V}$, we have that $B$ takes $e$ to its corresponding vector in $\mathcal{V}$. 

Since a cut can be realized as a linear map, its image is a subspace of the co-domain. We denote it by $C_{G}^{\star}=\text{Im}(\text{cut})$ and call it the **cut space**. Every vector in the cut space is a subset of edges incident with one of the vertices its preimage, which means that the vertices of the graph span $C_{G}^{\star}$. However, this is not an independent set: consider the vertices of the graph and some subset $U \subseteq V(G)$, we have $\text{cut}(U)=\text{cut}(\overline{U})$ purely by a combinatorical argument (if $e \in \text{cut}(U)$ then it is incident with exactly one vertex of $U$, but then means it must have its other end at $\overline{U}$ so by symmetry we have $\text{cut}(U)=\text{cut}(\overline{U})$), so a minimal spanning set would have $n-c$ vertices where $C$ is the number of connected components, to summarize:

$$
\text{dim}(C_{G}^{\star}) = n - c
$$

The dimension of the cut space of a graph is $n-c$, where $c$ is the number of connected components and $n$ is the number of vertices. TODO

## Cycle Space

In the last section we presented the vertex cut, which is a linear map represented by the transpose of the incidence matrix $B$. By a classic result in linear algebra, the image and kernel of a linear map are both vector subspaces. We called the image of the map the cut space. We have also seen that the incidence matrix $B$ represents a linear map $\mathcal{E} \to \mathcal{V}$. In this section, we shall consider the kernel of that map.

The kernel of the map $B$ is a vector subspace of $\mathcal{E}$ which consists of all vectors $x \in \mathcal{E}$ such that $Bx=0$ (where $0$ in this vector space is the empty set). Consider a member of the standard bais of $\mathcal{E}$, $e_{i}$, whose corresponding edge is $uv$ (we use vector notation instead of set notation here for bravity and to prevent ambiguity). We have seen that

$$
Be_{i}=u+v
$$

Where $u$ and $v$ are the singletons corresponding to the vertices $u, v$, and the addition here is a symmetric difference.

Consider a graph with the following cycle $C=\{a, b, c, a\}$, and consider the corresponding member of $\mathcal{E}$ which describes the edge set of the cycle, then we have $x_{C}=\{ab, bc, ca\}$, and under $B$ we have

$$
Bx_{C} \underset{\text{linear}}{=}B(ab)+B(bc+B(ca)) = (a + b) + (b + c) + (c + a) \underset{\text{vector space}}{=} (a + a) + (b + b) + (c + c) = 0
$$

So $x_{C} \in \text{ker}(B)$. We can extend this argument to any cycle, since in a a cycle each vertex appears twice. However, not every member of $\text{ker}(B)$ is a cycle. To show this, consider the following graph

TODO G a -- b -- c -- a; d -- e -- f -- g -- d; g -- a;

Indetify the cycle subgraphs $\{a, b, c, a\}$ and $\{d, e, f, g\}$. Both are in the kernel of $B$, which is a vector space so their addition should also be a vector in the kernel of $B$, but now we have a member of $\text{ker}(B)$ that clearly does not correspond to a single cycle in the graph. However, it does correspond to an even degree subgraph, so each vertex ends up being counted an even number of times, so the vector is in the kernel of $B$, which leads to the following definition/result:

The **cycle space** $C_{G}$ of a graph $G$ is defined as $C_{G}=\text{ker}(B)$ where $B$ is the incidence matrix of the graph. Each member of the cycle space corresponds to a subgraph of $G$ where all vertices are of even degree.

**Lemma**: If $u, v \in C_{G}$ and the subgraphs corresponding to $u, v$ share an edge, then $u+v$ corresponds to a cycle subgraph of $G$ which consists of all the vertices in $u$ or $v$ without the shared edge.

**Proof**: The sum of the vectors is a member of $C_{G}$ because $C_G{}$ is a vector space and a shared edge is counted twice so it is not an edge in the sum.

### Basis of the Cycle Space

Recall that each connected graph has a spanning tree such that every other edge in the graph not in the spanning tree creates a cycle. Similarly, every graph has a spanning forest such that every other edge in the graph either creates a cycle (it cannot connect two disconnected components since if there were a path between the components in the graph they would be connected in a tree component of the spannig forest). These cycles have all their edges in the spanning forest except for the one edge which was added to close the cycle. We call these the *fundamental cycles* of the graph.

**Theorem**: The fundamental cycles of a graph are a (standard) basis of $C_{G}$.

**Proof**: We shall prove that fundamental cycles span the cycle space. Consider a member of $x$ the cycle space. It is either a cycle of the graph or it is a union of cycles of the graph. Since the latter generalizes the former, we only consider that case. Consider a spanning forest $F$ of $G$, and identify the subgraph corresponding to the member of the cycle space, denote it $H$. Consider the fundamental cycles of $G$, each is the single cycle subgraph of $T'$ which is $T$ with a single edge from $E(G) \setminus E(F)$. There are $m-(n-c)$ such fundamental cycles, where $c$ is the number of connected components (this is because the spanning forest is a union of $c$ trees such that the union of all trees have $n$ vertices and each tree has $n-1$ edges). Pick an ordering for these fundamental cycles and identify their corresponding vectors in $C_{G}$ as $c_{i}$.

Consider $x+c_{0}$. Since both are members of $C_{G}$ the resulting vector must correspond to a union of cycles. Now, if the edge which formed $c_{0}$ was in $x$, then $x+c_{i}$ must not contain the edge, but then it must not be equal to the spanning forest because then it would not be a cycle. Next, we take $x+c_{1}$. By a similar argument $x+c_{2}$ must not contain the edge which formed $c_{1}$ but must also not be equal to $T$. Repeat this argument until you exhaust all fundamental cycles. The remaining vector must be in $C_{G}$, but it must have no fundamental cycle of $T$, so it must not have any edge not in the spanning forest, but then if it has any edges remaining it cannot be a cycle, so it must be the empty set, so it must be zero, so we have that $x$ is a linear combination of fundamental cycles.

To prove that they are a basis, remove a vector corresponding to a fundamental cycle $c_{k}$ from the set of vectors. Then consider a member $x \in C_{G}$ such that $x$ corresponds to $c_{k}$. Clearly we cannot form the cycle by a combination of the remaining cycles, since we cannot introduce the edge that forms $c_{k}$, so the set we found must be a basis.

**Corollary**: $\text{dim}(C_{G}) = m - (n - c)$

**Proof**: Follows immediately from the set of fundamental cycles being a basis of $C_{G}$, which has cardinality $m - (n-c)$ as we have seen.

**Corollary**: $\text{dim}(C_{G}) + \text{dim}(C_{G}^{\star}) = \text{dim}(\mathcal{E}_{G})$

**Proof**:

$$
\text{dim}(C_{G}) + \text{dim}(C_{G}^{\star}) = m - (n - c) + (n - c) = m = \text{dim}(\mathcal{E}_{G})
$$

## Adjacency Matrix of a Graph

Consider a graph $G=(V, E)$ with some ordering on the vertices. We define the **adjacency matrix** $A$ of a simple graph as an $n \times n$ matrix ($n=|V|$) such that the $i$-th column (or row, as we will see $A$ is symmetric) corresponds to a vector in $\mathcal{V}$ which corresponds to the set of all vertices incident with $v_{i}$ under the ordering:

$$
A_{ij}=\begin{cases}
1 & \{v_{i}, v_{j} \} \in E \\
0 & \text{otherwise}
\end{cases}
$$

From this definition it follows immediately that the adjacency matrix is symmetric.

Let $n_{v} \in \mathcal{V}$ be a vector which corresponds to the set of all neighbors of the vertex $v$. Consider some vector $x \in \mathcal{V}$, it can be expressed as a linear combination of basis vectors $\sum_{i=0}^{n-1} \lambda_{i}b_{i}=\lambda b$. The product $Ax$ is an $n$-dimensional vector such that

$$
[Ax]_{i} = \lambda^{T} \cdot [n_{v}]
$$

Clearly, this result is a linear combination of vectors in $\mathcal{V}$, so we have that $A$ defines a linear map $A: \mathcal{V} \to \mathcal{V}$. The image of a vector $v$ under $A$ is a vector whose $i$-th entry is the sum of the subset of coefficients $\lambda$ of $v$ which correspond to the neighbors of the vertex corresponding to the basis vector $v_{i}$. In $\text{GF}(2)$ this is not particularly interesting, but as we will soon see if we let vertices correspond to vectors in $\mathbb{R}^{n}$ this map becomes useful.

## Cycles Cuts Planarity

TODO

## Towards Euclidean spaces

In our treatment of graphs as vector spaces so far we had vector spaces isomorphic to $\text{GF}(2)^{k}$ where $k$ is the dimension of the vector space. This setting, while helpful, is limiting. As a motivating example, consider that our object of interest is an electronic circuit. A natural way to represent an electric circuit using a graph is to take points (nodes) on the circuit to vertices on the graph and conductors connecting nodes to edges. This graph corresponds to the two vector spaces $\mathcal{V}$ and $\mathcal{E}$ which are isomorphic to $\text{GF}(2)^{n}$ and $\text{GF}(2)^{m}$ respectively. However, in an electric circuit the nodes and the conductors also have a numerical value associated to them - for example, at each point we can measure the potential and each conductor conducts some current. We would like to capture this information about the vertices and edges as well.

To do that, we define a new vertex space $\mathcal{V}$ which is isomorphic to $\mathbb{R}^{n}$ and a new edge space $\mathcal{E}$ which is isomorphic to $\mathbb{R}^{m}$. In these spaces, an edge or vertex in the graph is represnted by a vector which is a scaled basis vector, i.e. $\lambda_{i}b_{i}$ where $\lambda_{i}$ is the scalar corresponding to the vertex/edge (perhaps a mure intutive way to think of this value would be as a *label* or some *data* on the vertex/edge) and $b_{i}$ is the associated basis.

As an example, consider the following graph with labels written inside each vertex with the ordering $\{a, b, c, d \}$

TODO graph a -- b, c, d; c --d; a=0 b=1 c=2 d=3;

Consider the adjacency matrix of the graph

$$
A = \begin{pmatrix}
0 & 1 & 1 & 1 \\
1 & 0 & 0 & 0 \\
1 & 0 & 0 & 1 \\
1 & 0 & 1 & 0
\end{pmatrix}
$$

Let $x$ be a vector in $\mathcal{V}$ corresponding to the subset $\{a, b, c, d \}$ with the labels seen in the graph, so we have

$$
x = \begin{pmatrix}
0 \\ 1 \\ 2 \\ 3
\end{pmatrix}
$$

Recall that $Ax$ takes $x$ to a vector such that $[Ax]_{i}$ is the sum of the coefficients in $x$ of the neighbors of $v_{i}$, so we have

$$
Ax = \begin{pmatrix}
1 + 2 + 3 \\
0 \\
0 + 3 \\
0 + 2
\end{pmatrix} = \begin{pmatrix}
6 \\ 0 \\ 3 \\ 2
\end{pmatrix}
$$

Now, consider the incidence matrix $B$ which we have defined earlier. Recall that given a basis vector $e \in \mathcal{E}$ corresponding to the edge $\{u, v\}$, we had $Be = u + v$, which in $\text{GF}(2)$ also corresponds to $Be = u - v$ (we abuse notation here because the addition is in fact the symmetric difference, but if we were to perform the operation on the coordinate vectors of $u$ and $v$ this result would hold). Continuing our analogy to electronic circuits, if we think of the labels on the vertices as potential, it would make sense to associate a *voltage* to an edge, but a voltage is a difference in potential, so when extending the incidence matrix to real Euclidean space we would like to have the result of multiplication of an edge vector by that matrix be a difference of vertex vectors and not a sum. This also requires us to pick an arbitary orientation for each edge, which should correspond to the direction of electron flow along the corresponding conductor, which should be encoded in this new matrix. We call this matrix the **boundary matrix**.

The **boundary matrix** $\partial$ of a graph is a matrix where every column corresponds to an edge of the graph written as a vector in $\mathcal{V}$ with some arbitrary orientation, such that

$$
\partial_{ij} = \begin{cases}
1 & \text{if edge $j$ is oriented from $v_{i}$ to $v_{j}$} \\
-1 & \text{if edge $j$ is oriented from $v_{j}$ to $v_{i}$} \\
0 & \text{otherwise}
\end{cases}
$$

In our example, if we were to direct all edges incident with $a$ towards $a$, and the edge from $c$ to $d$ towards $d$, and choose the ordering $(ab, ac, ad, cd)$, then the boundary matrix would be

$$
\partial = \begin{pmatrix}
1 & 1 & 1 & 0 \\
-1 & 0 & 0 & 0 \\
0 & -1 & 0 & -1 \\
0 & 0 & -1 & 1 \\
\end{pmatrix}
$$

We can check and verify that this is a map $\partial: \mathcal{E} \to \mathcal{V}$ such that given an $m$-dimensional vector corresponding labeled edges, its image would be the labels for the vertices whose differences along edges correspond to the labeling of the edges (to convince yourself that this is true, try it yourself!)

Similarly, we can check that $\text{ker}(\partial)$ corresponds to the cycle space $C_{G}$, and that $\partial^{T}$ is also a map whose image corresponds to the cut space $C_{G}^{\star}$. It is easy to verify that $\partial^{T}$ takes a vector of labeled vertices and returns a vector of labeled edges such that each edge is assigned to the difference of the labels of the vertices it connects. In that sense, $\partial^{T}$ is a discrete derivative operator.

Consider the map $\partial \partial^{T}: \mathcal{V} \to \mathcal{V}$. Since it is a composition of linear transformations it is also a linear transformation. We can calculate $\partial \partial^{T}$ for some ordering on vertices and edges from the definition of the boundary matrix, which will get us (here we state the final result without proof, which should be easy to verify manually):

$$
[\partial \partial^{T}]_{ij} = \begin{cases}
\text{deg}(v_{i}) & i = j \\
-1 & \{v_{i}, v_{j}\} \in E \\
0 & \text{otherwise}
\end{cases}
$$

We call this result the **laplacian** of the graph and we denote it with the letter $L$. Observe that the diagonal is simply the degree of each vertex, so we can write $L$ in terms of matrix difference

$$
L = D_{G} - M
$$

Where $D_{G}$ is a diagonal matrix where $[D_{G}]_{ik} = \begin{cases} 0 & i \neq k \\ \text{deg}(v_{i}) & i = k \end{cases}$ which we call the **degree matrix** and $M$ is a matrix where $[M]_{ij} = \begin{cases} 1 & \{v_{i}, v_{j}\} \in E \\ 0 & \text{otherwise} \end{cases}$, but this is precisely the definition for the adjancy matrix so we have

$$
L_{G} = D_{G} - A_{G}
$$

This matrix will be very useful for us moving forward, so it is worth considering how different orderings of the vertices and edges sets change it. The laplacian is:

1. Symmetric (as the difference of symmetric matrices)
2. The sum of every row and every column of $L_{G}$ is zero. This stems from the fact that for every row and column, the only positive value is the degree of a vetex and the only negative values are $-1$ and they appear once for every neighbor of the vertex, so in total we have $\sum = \text{deg}(v) + (-1)\text{deg}(v) = 0$.
3. $L_{G}$ has $\lambda_{0}=0$ as an eigenvalue with eigenvector $\mathbf{1}$, where $\mathbf{1}$ is the vector of all ones. This is because by $(2)$ the sum of every row and column is zero, so the sum of every row and column of $L_{G}\mathbf{1}$ is zero, so $\mathbf{1}$ is an eigenvector of $L_{G}$ with eigenvalue 0.
4.  $L_{G}$ is singular since it has 0 as an eigenvalue.
7. The laplacian is indepdent of the orientation we pick for the edges in constructing the boundary matrix $\partial$.

## Boundary Matrix Similarity

Recall that when discussing the geometric realization of a graph, we proved that the geometric realization is invariant up to a homeomorphism by considering the permutation matrix which essentially maps a elements of one finite set to another, and when this mapping is surjective and injective this mapping is a bijection, which means that the permutation matrix is invertible. In fact, if a permutation matrix is invertible we have

**Theorem**: Let $P$ be a permutation matrix between two finite sets of equal cardinality, then $PP^{-1}=I$ if and only if $PP^{T}=I$.

**Proof**: The theorem is equivalent to stating that if $P$ is invertible, then it is orthogonal, which is equivalent to saying that $P^{-1}=P^{T}$. We prove this by considering the definition of a permutation matrix. Let $P$ be a permutation matrix and let $f: S \to K$ be the linear map defined by $P$ where $S$ and $K$ are two sets with some ordering, then we have

$$
P_{ij} = \begin{cases} 1 & f(s_{i}) = k_{j} \\ 0 & \text{otherwise} \end{cases}
$$

Similarly, we have $f^{-1}$ defined by $P^{-1}$, which is also a permutation $f^{-1}: K \to S$, so we have

$$
P^{-1}_{ij} = \begin{cases} 1 & f^{-1}(k_{i}) = s_{j} \\ 0 & \text{otherwise} \end{cases}
$$

But now we have

$$
[P^{T}]_{ij}=P_{ji} = \begin{cases} 1 & f(s_{j}) = k_{i} \\ 0 & \text{otherwise} \end{cases}
$$

Which is the same as $P^{-1}$, which completes the proof.

**Corollary**: The cycle space $C_{G}$ and the cut space $C_{G}^{\star}$ of a graph are isomorphic under orderings.

**Proof**: In the definition of the boundary matrix, we picked two orderings - an ordering of the vertices and an ordering of the edges. Let $P_{n}$ be a permutation matrix which reorders the vertices, and let $P_{m}$ be a permutation matrix which reorders the vertices. Consider some boundary matrix $\partial$ with one arbitary ordering on the vertices and the edges. Since the rows of the boundary matrix correspond to vertices and the columns to edges, in order to properly apply the permutations we need to consider the matrix $P_{n} \partial P_{m}$. Similarly for $\partial^{T}$ (which we use to define the cut space) we need to consider the matrix $P_{m} \partial^{T} P_{n}$. We show that $\text{ker}(\partial)$ is isomorphic to $\text{ker}(P_{n} \partial P_{m})$ by composing isomorphisms:

First, $\forall x \in \text{ker}(\partial)$, we have $P_{n}\partial x = P_{n} (\partial x) = P_{n} 0 = 0$, so $\partial \cong P_{n} \partial$. Next, consider $P_{n} \partial P_{m}x$ for some $x \in \mathcal{E}$. Since $P_{m}$ is a permutation of $\mathcal{E}$, we have an isomorphism between two bases of $\mathcal{E}$ via $P_{m}$ and $P_{m}^{-1}=P_{m}^{T}$, so by composition we have $\text{ker}(\partial) \cong \text{ker}(P_{n} \partial P_{m})$. A similar proof follows for the cycle space.

**Theorem**: The laplacian of a graph is invariant under edge reordering and a vertex reordering is an isomorphism on the laplacian.

**Proof**: We have $L_{G}=\partial \partial^{T}$. Permuate the vertices and the edges with $P_{n}$ and $P_{m}$ respectively, then we have

$$
L'_{G} = (P_{n} \partial P_{m}) (P_{n} \partial P_{m})^{T} = P_{n} \partial P_{m}P_{m}^{T} \partial^{T} P_{n}^{T} = P_{n} \partial \partial^{T} P_{n}^{T} = P_{n} L_{G} P_{n}^{T}
$$

But since $P_{n}^{T}=P_{n}^{-1}$ we have $L'_{G}$ written in the form of $AL_{G}A^{-1}$, which is an isomorphism via matrix similarity, and indepdent of the ordering of the edges, which completes the proof.

**Corollary**: For any ordering of the vertices and edges of the graph, if $L_{G}$ is the laplacian of the graph for that ordering, then the following are invariant:

1. $\text{tr}(L_{G})$
2. $\text{det}(L_{G})$
3. Eigenvalues of $L_{G}$.

**Proof**: All 3 immediately follow from the fact that the laplacian matrices of different orderings of the graph are similar so they have the same trace, determinant, and eigenvalues. Furthermore, since we have that the diagonal of $L_{G}$ is the degree matrix for some ordering, we have that $\text{tr}(L_{G})$ is the sum of degrees of the vertices of the graph, which is a graph invariant so this result is expected regardless of the matrix similarity. Similarly, since the laplacian is singular we always have $\text{det}(L_{G})=0$. 

# Laplacian Systems

Recall the electronic circuit analogy we used when introducing the boundary matrix which led to the introduction of the laplacian. By Ohm's law, for any two points on a conductor, we have

$$
V = RI
$$

Where $V$ is the voltage across the two points, which is the difference in the potential of the two points, $R$ is the resistance of the conductor and $I$ is the current through the conductor. An electronic circuit consists of many such conductors, each satisfying Ohm's law where $V$ is the difference of potential between its ends.

TODO example circuit digraph a -> b -> c -> d -> e -> f; e -> c; a=10, b=5, c=3, d=-4, e=3, f=-10

Assume you wanted to calculate the voltage at each point, given the potential at each point. One way would be to explicitly calculate Ohm's law for each conductor, but this is not as efficient computetionally compared to matrix multiplication, which can be parallalized and optimized. If we represent the circuit as a graph with an ordering on the vertices and on the edges and assign label the vertices with their potentials and label each edge with the voltage of the conductor it represents, then we have that the label of each edge is given by the difference of labels of each vertex, but this is 
*precisely* the result of multiplying the co-boundary (transpose of the boundary) matrix with the vector represnting all the potentials (in the ordering we chose), so we have

$$
\partial^{T} \vec{p} = \vec{v}
$$

Where $\vec{p}$ is the potential vector and $\vec{v}$ is the voltage vector.

Similarly, if we have a label vector $\vec{i} \in \mathcal{E} \cong \mathbb{R}^{m}$ such that $i_{j}$ corresponds to the current through the $j$-th conductor, then we have that the vector of *net current* at each vertex (i.e. the sum of currents through all conductors incident with the vertex, or the *flow* of the vertex) is given by $\partial\vec{i}$.

Assume that we know have a net current or a flow vector, and wish to solve for potential. Both vectors are in $\mathcal{V} \cong \mathbb{R}^{n}$, so we need a matrix which maps a vector in $\mathcal{V}$ to another vector in $\mathcal{V}$. We have one such matrix - the laplacian. We will see that it naturally appears when attempting to solve for the potential using Ohm's law. If we consider Ohm's law on every conductor, we have the following system of equations

$$
\vec{v} = R\vec{i}
$$

Where $\vec{v}$ and $\vec{i}$ are the potential vector and current vector respectively, and $R$ is a diagonal matrix where $R_{ii}$ is the resistance of the $i$-th conductor (again in correspondence with the ordering of the edges). For now let us assume that the resistance is equals across the edegs of the circuit, so we can take $R$ to be the identity matrix and scale the $\vec{i}$ later to account for the resistance. We can rewrite the system of equations as

$$
\vec{v} = \vec{i}
$$

But recall that we have $\vec{v} = \partial^{T} \vec{p}$, so we have

$$
\partial^{T} \vec{p} = \vec{i}
$$

Now, recall that we have seen that the net current is given by $\partial\vec{i}$. Denote the net current by $\vec{c}$. We have

$$
\vec{c} = \partial\vec{i} = \partial \partial^{T} \vec{p} = L\vec{p}
$$

Which gives a system of linear equations $L\vec{p}=\vec{c}$ where $\vec{c}$ and $L$ are known and we wish to solve for $\vec{p}$. This is a **laplacian system**. Were $L$ invertible, the system would have a single solution in $\vec{p}=L^{-1}\vec{c}$, but since $L$ is singular we either have infinitely many solutions or none. Luckily, we *can* always find a solution if $G$ is connected.

**Theorem**: Given a graph $G$, we have $\forall x \in \mathcal{V} \cong \mathbb{R}^{n}, (Lx)^{T} \mathbb{1} = 0$ where $\mathbb{1}$ is a vector in $\mathcal{V}$ whose every entry is 1.

**Proof**: Let $y=Lx$, then this expression is equivalent to $y \cdot \mathbb{1}$, which is the same as the sum of all entries of $y$. Now, we have $L=D-A$, and we have seen that $Ax$ is a vector whose $i$-th entry is the sum of all values in $x$ at indices corresponding to neighbors of the $i$-th vertex in the graph. Similarly, we have $Dx$ as a vector where the $i$-th entry is the degree of the $i$-th vertex times its corresponding value in $x$. So we have

$$
[Lx]_{i} = [(D-A)x]_{i} = \text{deg}(v_{i})x_{i} - \sum_{j \in N(v_{i})} x_{j}
$$

Consider the following combinatorical argument: each vertex $v_{i}$ is the neighbor of $\text{deg}(v_{i})$ vertices, so in the sum of all such $[Lx]_{i}$ we expect it to appear exactly $\text{deg}(v_{i})$ times with a negative sign and exactly 1 time with a positive sign but multiplied by $\text{deg}(v_{i})$, but this means that the sum of all entries related to $v_{i}$ is zero, but since $v_{i}$ is any vertex we have $\sum_{i=0}^{n-1}[Lx]_{i}=0$, which completes the proof.

**Corollary**: Given a vector $b \in \mathbb{R}^{n}$ and a laplacian $L$ such that $x \cdot \mathbb{1} = 0$, then the system of equations $Lx=b$ has a solution.

**Proof**: By the theorem we have that every vector of the form $Lx$ must satisfy $Lx \cdot \mathbb{1} = 0$, but this is also the only restriction on a vector of the form $Lx$ so if some vector satisfies this restriction then it can be rewritten as $Lx$ for some $x$ which is the solution of $Lx=b$.

**Corollary 2**: In this theorem hides a proof of Kirchhoff's current law: given an internal node in an electronic circuit, the sum of currents in and out of the node is zero.

**Proof**: This lemma is directly proven in the theorem.

Back to our original problem, if we wish to solve a laplacian system which is described as a connected graph, then we can "inject" one unit of current to one vertex and "extract" it at another vertex, and then we would have

$$
\vec{c}_{i} = \begin{cases} 1 & i \text{ the injected vertex} \\ -1 & i \text{ the extracted vertex} \\ 0 & \text{otherwise} \end{cases}
$$

It is easy to see that $\vec{c} \cdot \mathbb{1} = 0$ so by the theorem the system $Lp=c$ has a solution. If we find one such solution, we can find an entire subspace of solutions by taking the solution $p_{0}$ and adding the $\mathbb{1}$ vector to it, which results in $L(p_{0}+\mathbb{1})=Lp_{0}+L\mathbb{1}=c+0=c$ thus $p_{0}+\mathbb{1}$ is also a solution. One way to get such solution for this system is to use the [pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) of $L$.

Now, let's consider the general case again where $R \neq I$. In that case, $R$ is a diagonal matrix where $R_{ii}$ is the resistance of the $i$-th conductor, and we have

$$
\partial^{T} \vec{p} = R\vec{i}
$$

Since $R$ is a non-singular diagonal matrix it is invertible so we can rewrite this As

$$
R^{-1} \partial^{T} \vec{p} = \vec{i}
$$


And agan we have the net current vector such that

$$
\vec{c} = \partial \vec{i} = \partial R^{-1} \partial^{T} \vec{p}
$$

Next, we denote $\tilde{L}=\partial R^{-1} \partial^{T}$, which gives the following linear system of equations

$$
\tilde{L}\vec{p} = \vec{c}
$$

Where $\tilde{L}$ is called the **weighted laplacian** of the graph (if $R=I$ then $\tilde{L}=L$ which is to be expected if all the weights are one). This system can be solved in the same way we solved $Lp=c$.

# Sub-Laplacian Systems

Let $G$ be a graph with laplacian $L$. In the last section we have seen that in general it is difficult to solve a laplacian system and there isn't always a solution (and if one exists it is not unique) because $L$ is singular.

Recall that the laplacian for some vertex ordering is given by $L_{G}=D_{G}-A_{G}$, where $A_{G}$ is the adjacency matrix and $D_{G}$ is the degree matrix. Consider some partitioning of the laplacian into blocks

$$
L_{G} = \left(\begin{array}{c|c}
L_{1}^{T} & Q^{T} \\
\hline
Q & L_{1}
\end{array}\right)
$$

such that all blocks are square matrices and $Q$ is strictly below the diagonal, which means it corresponds to some square block in $A$ and hence why the corresponding block diagonal to $Q$ is $Q^{T}$ (since $A$ is symmetric). Similarly $L_{1}$ is symmetric by the same argument (since $L$ is symmetric). We call such matrices $L_{1}^{T}$ and $L_{1}$ **sub-laplacians**.

Consider $L_{1}$. It corresponds to the sum of the blocks $D_{1}$ and $A_{1}$ of $D$ and $A$ respectively. However, since $A_{1}$ is a square block of $A$ it is also the adjacency matrix of a subgraph $H$ of $G$ which is the induced subgraph of the vertices whose adjacency is described by $A_{1}$, and $D_{1}$ is the degree matrix of the vertices $V(H)$ with respect to their degrees in $G$, such that $D_{1}$ is a nonnegative diagonal matrix. Since we have $\forall v \in V(H), \text{deg}_{H}(v) \leq \text{deg}_{G}(v)$, we can instead write

$$
L_{1} = L_{H} + X
$$

Where $L_{H}$ is the laplacian of the subgraph $H$ and $X$ is a nonnegative diagonal matrix which is equal to $D_{1}-D_{H}$.

**Theorem**: If $G$ is connected and $L_{1}$ is a sub-laplacian of $G$, then $L_{1}$ is invertible.

**Proof**: Recall from linear algebra that if $M$ is a positive definite matrix, then it is invertible. A matrix is positive definite if

$$
\forall x \neq 0, x^{T}Mx \gt 0
$$

Here we have $M=L_{1}=L_{H}+X$, which gives

$$
x^{T}L_{H}x + x^{T}Xx
$$

Since $X$ is a diagonal matrix, we have that $x^{T}Xx$ is equal to $\sum_{i=0}^{n-1} x_{i}^{2}X_{ii}$, which is a sum of nonnegative values so it is nonnegative. Next, $x^{T}L_{H}x$ will be greater than zero unless $x$ is a constant vector (because then the positive and negative values associated with each vertex will be equally weighted and cancel each other out), but in this case $x^{T}Xx$ must be strictly positive because then we would have $\forall i, x_{i} \gt 0$ and since $G$ is connected $X$ must be nonzero so there exists some $i$ for which both $x_{i}$ and $X_{ii}$ are positive, so $x^{T}Xx$ is strictly positive. This completes the proof.

**Corollary**: all eigenvalues of a sub-laplacian are strictly positive. This is a classical result in linear algebra for positive definite matrices.

Sub-laplacians are used to prove Kirchhoff's [matrix-tree theorem](https://en.wikipedia.org/wiki/Kirchhoff%27s_theorem), which states that given a connected graph $G$ with laplacian $L$, the number of spanning trees of $G$ is given by the determinant of any sub-laplacian of $G$.

## Electricity again

Consider a circuit with some battery with known voltage $V$, which corresponds to the label on some edge in the graph representation of the circuit. Let $a$ and $b$ be the vertices corresponding to the ends of the edge representing the battery, then we know that $p_{b}-p_{a}=V$, where $p_{a}$ is the potential at point $a$ and is the label of the vertex $a$. We can pick arbitary values for $p_{a}$ and $p_{b}$ so long as their difference is preserved, so for simplictly lets choose $p_{a}=0$ and $p_{b}=V$. Assume the net current $c$ is known and we wish to solve for the potentials vector $p$, then we have a laplacian system

$$
Lp=c
$$

Which as we have seen before may not have a solution. However, since we know $p_{a}$ and $p_{b}$, we can choose an ordering on the vertices such that $a, b$ correspond to the first two vertices.  Now, by Kirchhoff's current law we know that the sum of currents in and out of a node is zero, so we expect that $c_{i}$ will be zero other than for $c_{0}$ and $c_{1}$ which correspond to the net current along $a$ and $b$. Putting this all together, we can rewrite this system as

$$
\left(\begin{array}{c|c}
L_{1}^{T} & Q^{T} \\
\hline
Q & L_{1}
\end{array}\right)
\begin{pmatrix}
0 \\ V \\ \hline p_{\text{rest}}
\end{pmatrix}
=
\begin{pmatrix}
c_{0} \\ c_{1} \\ \hline 0
\end{pmatrix}
$$

By expanding the block which involves $L_{1}$, we get

$$
Q\begin{pmatrix} 0 \\ V \end{pmatrix} + L_{1} p_{\text{rest}} = 0
$$

Which has a single solution iff $L_{1}$ is invertible, and since $L_{1}$ is a sub-laplacian and the all conductors in the circuit are connected, it is, (and if it weren't we would have started out from the laplacian of a connected component) so this is a sub-laplacian system with a *unique* solution which Is

$$
p_{\text{rest}} = -L_{1}^{-1}Q\begin{pmatrix} 0 \\ V \end{pmatrix}
$$

# Algebraic Drawings of a Graph

In this section, we show how the algebraic treatment of graphs as vector spaces provides new ways to calculate the image of a planar drawing of a graph. We will see that these images can be found by solving a system of linear equations, and we will see that we can also find a linear planar embedding using this method for every planar graph.

## Spectral Embeddings

TODO

## Tutte Embedding

TODO

statement of algorithm in python, prove that solution exists, show that it is an embedding